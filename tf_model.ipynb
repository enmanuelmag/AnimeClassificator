{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from absl import logging\n",
    "from notifier import notify\n",
    "from alive_progress import alive_bar\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import (\n",
    "  ReduceLROnPlateau,\n",
    "  EarlyStopping,\n",
    "  ModelCheckpoint,\n",
    "  TensorBoard\n",
    ")\n",
    "from tensorflow.keras import mixed_precision\n",
    "# Equivalent to the two lines above\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import pickle as pkl\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "SEED=42\n",
    "DATASET_PATH='./data/animes'\n",
    "DATASET_JSON_PATH='./data/anime_data.json'\n",
    "AMOUNT_TABLE_PATH='./data/anime_amount.pkl'\n",
    "DATASET_JSON_RANK='./data/anime_rank.json'\n",
    "TFRECORD_PATH='./data/anime_data.tfrecord'\n",
    "TG_ID=\"293701727\"\n",
    "TG_TOKEN=\"1878628343:AAEFVRsqDz63ycmaLOFS7gvsG969wdAsJ0w\"\n",
    "WEBHOOK_URL=\"https://discord.com/api/webhooks/796406472459288616/PAkiGGwqe0_PwtBxXYQvOzbk78B4RQP6VWRkvpBtw6Av0sc_mDa3saaIlwVPFjOIeIbt\"\n",
    "\n",
    "#seed random seed to 42 for reproducibility\n",
    "rd.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowload_image(url, anime_name, idx):\n",
    "  #download image from url\n",
    "  file_path = f'./data/animes/{anime_name}____{idx}.jpg' \n",
    "  if os.path.exists(file_path):\n",
    "    return\n",
    "\n",
    "  img_data = requests.get(url).content\n",
    "  with open(file_path, 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Anime images',\n",
    "  msg='Finished downloading anime images'\n",
    ")\n",
    "def get_images(data):\n",
    "  #with alive_bar(len(data)) as bar:\n",
    "  for idx_a, anime_name in enumerate(data):\n",
    "    urls = data[anime_name]\n",
    "    for idx, url in enumerate(urls):\n",
    "      if idx >= 400:\n",
    "        break\n",
    "      name_clean = re.sub(r'_+', r'_', re.sub(r'[\\W\\s]', r'_', anime_name))\n",
    "      try:\n",
    "        dowload_image(url['image'], name_clean, idx)\n",
    "      except Exception as e:\n",
    "        print(f'Error on download image {idx + 1} of {anime_name}')\n",
    "        pass\n",
    "    #bar()\n",
    "    print(f'Progress: {idx_a + 1}/{len(data)} - {round((idx_a + 1)/len(data)*100, 2)}%')\n",
    "\n",
    "def get_classes_anime(path):\n",
    "  classes = set()\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    classes.add(class_name)\n",
    "  return list(classes)\n",
    "\n",
    "def wait_for_it(driver, xpath, timeout=3):\n",
    "  try:\n",
    "    return WebDriverWait(driver, timeout).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath))\n",
    "    )\n",
    "  except Exception as e:\n",
    "    return None\n",
    "\n",
    "def iter_post(driver):\n",
    "  anime_data = []\n",
    "\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = True\n",
    "\n",
    "  while next_button is not None:\n",
    "    if len(anime_data) > 400:\n",
    "      break\n",
    "    ul_element = wait_for_it(driver, '//ul[@id=\"post-list-posts\"]')\n",
    "    if ul_element is None:\n",
    "      next_button = wait_for_it(driver, xpath_next)\n",
    "      if next_button is not None:\n",
    "        next_button.click()\n",
    "        time.sleep(1)\n",
    "      continue\n",
    "    for i, li_element in enumerate(ul_element.find_elements(By.TAG_NAME, 'li')):\n",
    "      a_video = li_element.find_element(By.XPATH, './a').get_attribute('href')\n",
    "      a_image = li_element.find_element(By.XPATH, './div/a/img').get_attribute('src')\n",
    "      anime_data.append({\n",
    "        'video': a_video,\n",
    "        'image': a_image\n",
    "      })\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "    if next_button is not None:\n",
    "      next_button.click()\n",
    "      time.sleep(rd.randint(1, 2))\n",
    "  return anime_data\n",
    "\n",
    "def get_images(url, driver, anime_name):\n",
    "  url_search = url + anime_name\n",
    "  driver.get(url_search)\n",
    "  return iter_post(driver)\n",
    "\n",
    "def get_names(driver):\n",
    "  names = []\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = wait_for_it(driver, xpath_next)\n",
    "  \n",
    "  while next_button is not None:\n",
    "    for tr_element in driver.find_elements(By.XPATH, '//table[@class=\"highlightable\"]/tbody/tr'):\n",
    "      try:\n",
    "        amount_post = tr_element.find_element(By.XPATH, './td[1]').text\n",
    "        amount_post = int(amount_post)\n",
    "        if amount_post >= 10:\n",
    "          a_name = tr_element.find_element(By.XPATH, './td[2]/a[2]' ).text\n",
    "          names.append(a_name)\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    next_button.click()\n",
    "    time.sleep(rd.randint(1, 2))\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "  return names\n",
    "\n",
    "def get_score(anime_name, driver):\n",
    "  url_search = f'https://myanimelist.net/anime.php?cat=anime&q={anime_name}'\n",
    "  driver.get(url_search)\n",
    "  score = 0\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    score += 1\n",
    "  return score\n",
    "\n",
    "def relevant_anime(anime_name, df_anime, amount_table):\n",
    "  \n",
    "  if amount_table.get(anime_name, 0) <= 320:\n",
    "    return False\n",
    "\n",
    "  anime_name = re.sub(r'_', r' ', anime_name)\n",
    "  df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "\n",
    "  if df_result.empty:\n",
    "    anime_name = ' '.join(anime_name.split(' ')[:3])\n",
    "    df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "  return not df_result.empty\n",
    "\n",
    "def amount_anime_table(datapath):\n",
    "  dic = {}\n",
    "  for filename in os.listdir(datapath):\n",
    "    class_name, _ = filename.split('____')\n",
    "    dic[class_name] = dic.get(class_name, 0) + 1\n",
    "  return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get anime images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = json.load(open(DATASET_JSON_PATH))\n",
    "get_images(anime_data)\n",
    "\n",
    "amount = amount_anime_table(DATASET_PATH)\n",
    "pkl.dump(amount, open(AMOUNT_TABLE_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/df_anime_rank.pkl')\n",
    "\n",
    "amount_table = pkl.load(open(AMOUNT_TABLE_PATH, 'rb'))\n",
    "all_class_array = get_classes_anime(DATASET_PATH)\n",
    "\n",
    "class_array = set()\n",
    "for anime_name in all_class_array:\n",
    "  if relevant_anime(anime_name, df, amount_table):\n",
    "    class_array.add(anime_name)\n",
    "\n",
    "class_array = list(class_array)\n",
    "class_array = class_array[:8]\n",
    "print(f'All classes: {len(all_class_array)} - Filtered {len(class_array)}')\n",
    "del all_class_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_id(class_name):\n",
    "  return class_array.index(class_name)\n",
    "\n",
    "def build_example(path_file, class_name):\n",
    "  img_array = open(path_file, 'rb').read()\n",
    "  \n",
    "  #img = load_img(path_file, target_size=(SIZE_IMG, SIZE_IMG))\n",
    "  #img_array = np.array(img)\n",
    "  #img_array = preprocess_input(img_array, mode='tf')\n",
    "  #key = hashlib.sha256(img_array).hexdigest()\n",
    "  example = tf.train.Example(\n",
    "    features=tf.train.Features(feature={\n",
    "    #'key': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf-8')])),\n",
    "    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array])),\n",
    "    #'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array.tobytes()])),\n",
    "    'class_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[get_class_id(class_name)])),\n",
    "    #'class_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode('utf-8')])),\n",
    "    #'filepath': tf.train.Feature(bytes_list=tf.train.BytesList(value=[path_file.encode('utf-8')]))\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "def create_tfrecord(data_path, withe_list):\n",
    "  files = os.listdir(data_path)\n",
    "  writer = tf.io.TFRecordWriter(TFRECORD_PATH)\n",
    "  \n",
    "  print('Started creating tfrecord')\n",
    "  for idx, filename in enumerate(files):\n",
    "    class_name, _ = filename.split('____')\n",
    "  \n",
    "    if class_name in withe_list:\n",
    "      path_file = os.path.join(data_path, filename)\n",
    "      tf_example = build_example(path_file, class_name)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "  print('Finished creating tfrecord')\n",
    "  writer.close()\n",
    "\n",
    "def parse_tfrecord(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  #class_id = tf.sparse.to_dense(x['class_id'], default_value=-1)\n",
    "  class_id = x['class_id']\n",
    "  if class_id is None:\n",
    "    class_id = -1\n",
    "\n",
    "  labels = tf.cast(class_id, tf.int64)\n",
    "  y_train = labels\n",
    "  #y_train = tf.stack([ labels ], axis=1)\n",
    "  return x_train, y_train\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, size):\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  return dataset.map(lambda x: parse_tfrecord(x, size))\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "  'image': tf.io.FixedLenFeature([], tf.string),\n",
    "  'class_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "if True:\n",
    "  os.remove(TFRECORD_PATH)\n",
    "  create_tfrecord(DATASET_PATH, class_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, input_shape, units, type_extractor = 'vgg') -> tf.keras.Model:\n",
    "  if type_extractor == 'vgg':\n",
    "    feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'inception':\n",
    "    feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'resnet':\n",
    "    feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  else:\n",
    "    raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  #model.add(tf.keras.layers.Input(input_shape, name='input'))\n",
    "  model.add(feature_extractor)\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  #new\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
    "  return model\n",
    "\n",
    "class AnimeClassifier(tf.keras.Model):\n",
    "  def __init__(self, num_classes, input_shape, units=512, inner_layers=12, type_extractor='vgg'):\n",
    "    assert type_extractor in ['vgg', 'inception', 'resnet']\n",
    "    assert inner_layers >= 1\n",
    "    assert num_classes >= 2\n",
    "    assert len(input_shape) == 3\n",
    "    assert units >= 64\n",
    "\n",
    "    super(AnimeClassifier, self).__init__()\n",
    "    if type_extractor == 'vgg':\n",
    "      feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif type_extractor == 'inception':\n",
    "      feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif type_extractor == 'resnet':\n",
    "      feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "      raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "\n",
    "    self.units = units\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.hidden_mlp = []\n",
    "    for i in range(inner_layers):\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    self.out_layer = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs, training=None, mask=None):\n",
    "    x = self.feature_extractor(inputs)\n",
    "    x = self.flatten(x)\n",
    "    for layer in self.hidden_mlp:\n",
    "      x = layer(x)\n",
    "    return self.out_layer(x)\n",
    "\n",
    "  def predict(self, x):\n",
    "    return self(x)\n",
    "\n",
    "  def predict_classes(self, x):\n",
    "    return tf.argmax(self(x), axis=1)\n",
    "\n",
    "  def vectorize(self, x, flatten=True):\n",
    "    x = self.feature_extractor(x)\n",
    "    if flatten:\n",
    "      return self.flatten(x)\n",
    "    return x\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Train model',\n",
    "  msg='Training has finished'\n",
    ")\n",
    "def train(model, train_ds, val_ds, units, epochs=15, mode='fit', type_model='vgg', save_weights_only=False):\n",
    "  logdir = \"logs/scalars/\" + time.strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "  #logdir = \"logs/scalars/\" + \"test_replicated_seed_5\"\n",
    "  if mode == 'eager_tf':\n",
    "    avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "    avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "      for batch, (images, labels) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "          outputs = model(images, training=True)\n",
    "          regularization_loss = tf.reduce_sum(model.losses)\n",
    "          pred_loss = []\n",
    "          for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "          total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        print(\"{}_train_{}, {}, {}\".format(\n",
    "          epoch, batch, total_loss.numpy(),\n",
    "          list(map(lambda x: np.sum(x.numpy()), pred_loss))\n",
    "        ))\n",
    "        avg_loss.update_state(total_loss)\n",
    "  elif mode == 'fit':\n",
    "    callbacks = [\n",
    "      ReduceLROnPlateau(verbose=1),\n",
    "      #EarlyStopping(patience=8, verbose=1),\n",
    "      ModelCheckpoint(\n",
    "        f'checkpoints/{type_model}_{units}_units.h5', \n",
    "        verbose=1,\n",
    "        monitor='accuracy',\n",
    "        save_freq='epoch',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=save_weights_only,\n",
    "      ),\n",
    "      TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(\n",
    "      train_ds,\n",
    "      epochs=epochs,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=val_ds\n",
    "    )\n",
    "    end_time = time.time() - start_time\n",
    "    print(f'Total Training Time: {end_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_IMG=224#224#416\n",
    "tf_record = load_tfrecord_dataset(TFRECORD_PATH, SIZE_IMG)\n",
    "all_ds_len = sum(1 for _ in tf_record)\n",
    "print(f'Total number of images: {all_ds_len}')\n",
    "\n",
    "#len_mini = all_ds_len\n",
    "#mini_tf_record = tf_record.take(len_mini)\n",
    "\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_valid = int(all_ds_len * 0.1)\n",
    "n_test = all_ds_len - n_train - n_valid\n",
    "\n",
    "tf_record = tf_record.shuffle(n_train + n_valid + n_test, seed=SEED)\n",
    "train_ds = tf_record.take(n_train)\n",
    "valid_ds = tf_record.skip(n_train).take(n_valid)\n",
    "test_ds = tf_record.skip(n_train + n_valid).take(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00002, clipnorm=1.0)\n",
    "#0.00002 - 150 epochs - 32 - batch - 512 units (12 layers) - 8 class - current\n",
    "#0.00001 - 150 epochs - 32 - batch - 512 units (12 layers) - 8 class - best\n",
    "#0.00005 - 150 epochs - 32 - batch - 512 units (12 layers) - 8 class - bad\n",
    "#0.0001 - 150 epochs - 32 - batch - 512 units (12 layers) - 8 class - bad\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "UNITS = 512 #128 #256 #512\n",
    "model = None\n",
    "vanilla_model=False\n",
    "\n",
    "if vanilla_model:\n",
    "  model = create_model(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor='vgg',\n",
    "    units=UNITS\n",
    "  )\n",
    "else:\n",
    "  model = AnimeClassifier(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor='vgg',\n",
    "    units=UNITS,\n",
    "    inner_layers=12\n",
    "  )\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "  model=model,\n",
    "  epochs=300,\n",
    "  units=UNITS,\n",
    "  val_ds=valid_ds.batch(32),\n",
    "  train_ds=train_ds.batch(32),\n",
    "  save_weights_only=True,\n",
    "  mode='fit', type_model='vgg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnimeClassifier(\n",
    "  num_classes=len(class_array),\n",
    "  input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "  type_extractor='vgg',\n",
    "  units=UNITS,\n",
    "  inner_layers=12\n",
    ")\n",
    "PATH_BEST = ''\n",
    "model.load_weights(PATH_BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'models/{type_model}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852bc408046ca7dfc5c8f91ce764d8630d2287ca09c7fe9d1b4d9cd156705bcb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tfenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
