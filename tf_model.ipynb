{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import numba\n",
    "import hashlib\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from absl import logging\n",
    "from numba import vectorize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics as sk_metrics\n",
    "from alive_progress import alive_bar\n",
    "from notifier import Notifier, notify\n",
    "from tensorflow.keras import mixed_precision\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import pickle as pkl\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Ti, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "SIZE_IMG = 224 #224#224#416\n",
    "UNITS = 1024 #2048 1024 128 256 512-seq\n",
    "MAX_CLASS = 32 #1024 32 16 8\n",
    "\n",
    "DATASET_PATH = './data/animes'\n",
    "DATASET_FACES_PATH = './data/faces'\n",
    "CLASS_ARRAY_PATH = f'./data/class_array_{MAX_CLASS}.pkl'\n",
    "CLASS_ARRAY_FACES_PATH = f'./data/class_array_faces_{MAX_CLASS}.pkl'\n",
    "CLASS_ARRAY_VEC_PATH = f'./data/class_array_vec_{MAX_CLASS}.pkl'\n",
    "\n",
    "DATASET_JSON_PATH = './data/anime_data.json'\n",
    "\n",
    "AMOUNT_TABLE_PATH = './data/anime_amount.pkl'\n",
    "AMOUNT_FACES_TABLE_PATH = './data/faces_amount.pkl'\n",
    "\n",
    "DATASET_JSON_RANK = './data/anime_rank.json'\n",
    "\n",
    "TFRECORD_PATH = f'./data/anime_data_{MAX_CLASS}.tfrecord'\n",
    "TFRECORD_FACES_PATH = f'./data/anime_faces_data_{MAX_CLASS}.tfrecord'\n",
    "\n",
    "TG_ID = \"293701727\"\n",
    "TG_TOKEN = \"1878628343:AAEFVRsqDz63ycmaLOFS7gvsG969wdAsJ0w\"\n",
    "WEBHOOK_URL = \"https://discord.com/api/webhooks/796406472459288616/PAkiGGwqe0_PwtBxXYQvOzbk78B4RQP6VWRkvpBtw6Av0sc_mDa3saaIlwVPFjOIeIbt\"\n",
    "\n",
    "#seed random seed to 42 for reproducibility\n",
    "rd.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if False:\n",
    "  #DATASET_PATH = DATASET_FACES_PATH\n",
    "  CLASS_ARRAY_PATH = CLASS_ARRAY_FACES_PATH\n",
    "  TFRECORD_PATH = TFRECORD_FACES_PATH\n",
    "  AMOUNT_TABLE_PATH = AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowload_image(url, anime_name, idx):\n",
    "  #download image from url\n",
    "  file_path = f'./data/animes/{anime_name}____{idx}.jpg' \n",
    "  if os.path.exists(file_path):\n",
    "    return\n",
    "\n",
    "  img_data = requests.get(url).content\n",
    "  with open(file_path, 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Anime images',\n",
    "  msg='Finished downloading anime images'\n",
    ")\n",
    "def get_images(data):\n",
    "  #with alive_bar(len(data)) as bar:\n",
    "  for idx_a, anime_name in enumerate(data):\n",
    "    urls = data[anime_name]\n",
    "    for idx, url in enumerate(urls):\n",
    "      if idx >= 400:\n",
    "        break\n",
    "      name_clean = re.sub(r'_+', r'_', re.sub(r'[\\W\\s]', r'_', anime_name))\n",
    "      try:\n",
    "        dowload_image(url['image'], name_clean, idx)\n",
    "      except Exception as e:\n",
    "        print(f'Error on download image {idx + 1} of {anime_name}')\n",
    "        pass\n",
    "    #bar()\n",
    "    print(f'Progress: {idx_a + 1}/{len(data)} - {round((idx_a + 1)/len(data)*100, 2)}%')\n",
    "\n",
    "def get_classes_anime(path):\n",
    "  classes = set()\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    classes.add(class_name)\n",
    "  return list(classes)\n",
    "\n",
    "def wait_for_it(driver, xpath, timeout=3):\n",
    "  try:\n",
    "    return WebDriverWait(driver, timeout).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath))\n",
    "    )\n",
    "  except Exception as e:\n",
    "    return None\n",
    "\n",
    "def iter_post(driver):\n",
    "  anime_data = []\n",
    "\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = True\n",
    "\n",
    "  while next_button is not None:\n",
    "    if len(anime_data) > 400:\n",
    "      break\n",
    "    ul_element = wait_for_it(driver, '//ul[@id=\"post-list-posts\"]')\n",
    "    if ul_element is None:\n",
    "      next_button = wait_for_it(driver, xpath_next)\n",
    "      if next_button is not None:\n",
    "        next_button.click()\n",
    "        time.sleep(1)\n",
    "      continue\n",
    "    for i, li_element in enumerate(ul_element.find_elements(By.TAG_NAME, 'li')):\n",
    "      a_video = li_element.find_element(By.XPATH, './a').get_attribute('href')\n",
    "      a_image = li_element.find_element(By.XPATH, './div/a/img').get_attribute('src')\n",
    "      anime_data.append({\n",
    "        'video': a_video,\n",
    "        'image': a_image\n",
    "      })\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "    if next_button is not None:\n",
    "      next_button.click()\n",
    "      time.sleep(rd.randint(1, 2))\n",
    "  return anime_data\n",
    "\n",
    "def get_images_links(url, driver, anime_name):\n",
    "  url_search = url + anime_name\n",
    "  driver.get(url_search)\n",
    "  return iter_post(driver)\n",
    "\n",
    "def get_names(driver):\n",
    "  names = []\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = wait_for_it(driver, xpath_next)\n",
    "  \n",
    "  while next_button is not None:\n",
    "    for tr_element in driver.find_elements(By.XPATH, '//table[@class=\"highlightable\"]/tbody/tr'):\n",
    "      try:\n",
    "        amount_post = tr_element.find_element(By.XPATH, './td[1]').text\n",
    "        amount_post = int(amount_post)\n",
    "        if amount_post >= 10:\n",
    "          a_name = tr_element.find_element(By.XPATH, './td[2]/a[2]' ).text\n",
    "          names.append(a_name)\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    next_button.click()\n",
    "    time.sleep(rd.randint(1, 2))\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "  return names\n",
    "\n",
    "def get_score(anime_name, driver):\n",
    "  url_search = f'https://myanimelist.net/anime.php?cat=anime&q={anime_name}'\n",
    "  driver.get(url_search)\n",
    "  score = 0\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    score += 1\n",
    "  return score\n",
    "\n",
    "def relevant_anime(anime_name, df_anime, amount_table, threshold=350, rank=True):\n",
    "  \n",
    "  if amount_table.get(anime_name, 0) <= threshold:\n",
    "    return False\n",
    "\n",
    "  if not rank:\n",
    "    return True\n",
    "\n",
    "  anime_name = re.sub(r'_', r' ', anime_name)\n",
    "  df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "\n",
    "  if df_result.empty:\n",
    "    anime_name = ' '.join(anime_name.split(' ')[:3])\n",
    "    df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "  return not df_result.empty\n",
    "\n",
    "def amount_anime_table(datapath):\n",
    "  dic = {}\n",
    "  for filename in os.listdir(datapath):\n",
    "    class_name, _ = filename.split('____')\n",
    "    dic[class_name] = dic.get(class_name, 0) + 1\n",
    "  return dic\n",
    "\n",
    "def detect(filename, cascade_file):\n",
    "  if not os.path.isfile(cascade_file):\n",
    "    raise RuntimeError(\"%s: not found\" % cascade_file)\n",
    "\n",
    "  cascade = cv2.CascadeClassifier(cascade_file)\n",
    "  image = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "  #src = cv2.cuda_GpuMat()\n",
    "  #src.upload(image)\n",
    "\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.equalizeHist(gray)\n",
    "\n",
    "  faces = cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor = 1.1,\n",
    "    minNeighbors = 5,\n",
    "    minSize = (24, 24)\n",
    "  )\n",
    "\n",
    "  new_images = []\n",
    "  for (x, y, w, h) in faces:\n",
    "    new_images.append(image[y:y+h, x:x+w])\n",
    "  #clahe = cv2.cuda.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "  #dst = clahe.apply(src, cv2.cuda_Stream.Null())\n",
    "  #result = dst.download()\n",
    "  return new_images\n",
    "\n",
    "def extract_faces(datapath):\n",
    "  faces_amount = 0\n",
    "  for filename in os.listdir(datapath):\n",
    "    class_name, _ = filename.split('____')\n",
    "    new_images = []\n",
    "    try:\n",
    "      new_images = detect(datapath + '/' + filename, './data/haar/lbpcascade_animeface.xml')\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      pass\n",
    "    if len(new_images) > 0:\n",
    "      for idx, img in enumerate(new_images):\n",
    "        new_face_name = f'./data/faces/{class_name}____{idx}.jpg'\n",
    "        try:\n",
    "          if not os.path.exists(new_face_name):\n",
    "            cv2.imwrite(new_face_name, img)\n",
    "            faces_amount += 1\n",
    "        except:\n",
    "          pass\n",
    "  print(f'Faces amount: {faces_amount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anime images\n",
    "anime_data = json.load(open(DATASET_JSON_PATH))\n",
    "get_images(anime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only faces\n",
    "extract_faces(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amount of images per anime\n",
    "amount = amount_anime_table(DATASET_PATH) #DATASET_PATH #DATASET_FACES_PATH\n",
    "pkl.dump(amount, open(AMOUNT_TABLE_PATH, 'wb')) #AMOUNT_TABLE_PATH #AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FACES Calculate the amount of images per anime\n",
    "amount = amount_anime_table(DATASET_FACES_PATH) #DATASET_PATH #DATASET_FACES_PATH\n",
    "pkl.dump(amount, open(AMOUNT_TABLE_PATH, 'wb')) #AMOUNT_TABLE_PATH #AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/df_anime_rank.pkl')\n",
    "\n",
    "amount_table = pkl.load(open(AMOUNT_TABLE_PATH, 'rb'))\n",
    "all_class_array = get_classes_anime(DATASET_PATH)\n",
    "\n",
    "class_array = set()\n",
    "for anime_name in all_class_array:\n",
    "  if relevant_anime(anime_name, df, amount_table, threshold=100, rank=True):\n",
    "    class_array.add((anime_name, amount_table[anime_name]))\n",
    "\n",
    "class_array = list(class_array)\n",
    "class_array.sort(key=lambda x: x[1], reverse=True)\n",
    "class_array = class_array[:MAX_CLASS]\n",
    "class_array = [x[0] for x in class_array]\n",
    "\n",
    "mean_keyframes = np.mean([amount_table[x] for x in class_array])\n",
    "pkl.dump(class_array, open(CLASS_ARRAY_PATH, 'wb'))\n",
    "print(f'All classes: {len(all_class_array)} - Filtered {len(class_array)} - Mean keyframes: {int(mean_keyframes)}')\n",
    "\n",
    "del all_class_array\n",
    "del mean_keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for faces\n",
    "all_class_array = get_classes_anime(DATASET_FACES_PATH)\n",
    "amount_table = pkl.load(open(AMOUNT_TABLE_PATH, 'rb'))\n",
    "\n",
    "class_array = set()\n",
    "for name in all_class_array:\n",
    "  class_array.add((name, amount_table[name]))\n",
    "\n",
    "class_array = list(class_array)\n",
    "class_array.sort(key=lambda x: x[1], reverse=True)\n",
    "class_array = class_array[:MAX_CLASS]\n",
    "\n",
    "class_array = list(class_array)\n",
    "print(f'All classes: {len(all_class_array)} - Filtered {len(class_array)}')\n",
    "del all_class_array\n",
    "\n",
    "class_array = [x[0] for x in class_array]\n",
    "pkl.dump(class_array, open(CLASS_ARRAY_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_id(class_name):\n",
    "  return class_array.index(class_name)\n",
    "\n",
    "def build_example(path_file, class_name):\n",
    "  img_array = open(path_file, 'rb').read()\n",
    "  \n",
    "  #img = load_img(path_file, target_size=(SIZE_IMG, SIZE_IMG))\n",
    "  #img_array = np.array(img)\n",
    "  #img_array = preprocess_input(img_array, mode='tf')\n",
    "  #key = hashlib.sha256(img_array).hexdigest()\n",
    "  example = tf.train.Example(\n",
    "    features=tf.train.Features(feature={\n",
    "    #'key': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf-8')])),\n",
    "    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array])),\n",
    "    #'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array.tobytes()])),\n",
    "    'class_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[get_class_id(class_name)])),\n",
    "    'class_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode('utf-8')])),\n",
    "    'filepath': tf.train.Feature(bytes_list=tf.train.BytesList(value=[path_file.encode('utf-8')]))\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "def create_tfrecord(data_path, withe_list, path_tfrecord):\n",
    "  files = os.listdir(data_path)\n",
    "  writer = tf.io.TFRecordWriter(path_tfrecord)\n",
    "  \n",
    "  print('Started creating tfrecord')\n",
    "  for idx, filename in enumerate(files):\n",
    "    class_name, _ = filename.split('____')\n",
    "  \n",
    "    if class_name in withe_list:\n",
    "      path_file = os.path.join(data_path, filename)\n",
    "      tf_example = build_example(path_file, class_name)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "  print('Finished creating tfrecord')\n",
    "  writer.close()\n",
    "\n",
    "def parse_tfrecord(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  #class_id = tf.sparse.to_dense(x['class_id'], default_value=-1)\n",
    "  class_id = x['class_id']\n",
    "  if class_id is None:\n",
    "    class_id = -1\n",
    "\n",
    "  labels = tf.cast(class_id, tf.int64)\n",
    "  y_train = labels\n",
    "  #y_train = tf.stack([ labels ], axis=1)\n",
    "  return x_train, y_train\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, size):\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  return dataset.map(lambda x: parse_tfrecord(x, size))\n",
    "\n",
    "def create_model(num_classes, input_shape, units, type_extractor = 'vgg') -> tf.keras.Model:\n",
    "  if type_extractor == 'vgg':\n",
    "    feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'inception':\n",
    "    feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'resnet':\n",
    "    feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  else:\n",
    "    raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  #model.add(tf.keras.layers.Input(input_shape, name='input'))\n",
    "  model.add(feature_extractor)\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  #new\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
    "  return model\n",
    "\n",
    "\n",
    "class AnimeClassifier(tf.keras.Model):\n",
    "  def __init__(self, num_classes, input_shape, units=1024, inner_layers=12, type_extractor='vgg'):\n",
    "    assert type_extractor in ['vgg', 'inception', 'resnet']\n",
    "    assert inner_layers >= 1\n",
    "    assert num_classes >= 8\n",
    "    assert len(input_shape) == 3\n",
    "    assert units >= 64\n",
    "\n",
    "    super(AnimeClassifier, self).__init__(name='AnimeClassifier')\n",
    "\n",
    "    self.units = units\n",
    "    self.in_layer = tf.keras.layers.Input(input_shape, name='input')\n",
    "\n",
    "    if type_extractor == 'vgg':\n",
    "      feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    elif type_extractor == 'inception':\n",
    "      feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    elif type_extractor == 'resnet':\n",
    "      feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    else:\n",
    "      raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.global_average_pooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.hidden_mlp = []\n",
    "    for i in range(inner_layers):\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dropout(0.5, seed=SEED))\n",
    "\n",
    "    self.out_layer = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs, training=None, mask=None):\n",
    "    x = self.feature_extractor(inputs, training=training)\n",
    "    x = self.global_average_pooling(x)\n",
    "    x = self.flatten(x, training=training)\n",
    "    for layer in self.hidden_mlp:\n",
    "      x = layer(x, training=training)\n",
    "    return self.out_layer(x, training=training)\n",
    "\n",
    "  def predict_classes(self, x):\n",
    "    return tf.argmax(self(x), axis=1)\n",
    "\n",
    "  def vectorize(self, x, flatten=True):\n",
    "    x = self.feature_extractor(x)\n",
    "    x = self.global_average_pooling(x)\n",
    "    if flatten:\n",
    "      return self.flatten(x)\n",
    "    return x\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Train model',\n",
    "  msg='Training has finished'\n",
    ")\n",
    "def train(model, train_ds, val_ds, units, epochs=15, mode='fit', type_model='vgg', save_weights_only=False, inner_ly=1):\n",
    "  logdir = \"logs/scalars/\" + time.strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "  if mode == 'eager_tf':\n",
    "    avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "    avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "      for batch, (images, labels) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "          outputs = model(images, training=True)\n",
    "          regularization_loss = tf.reduce_sum(model.losses)\n",
    "          pred_loss = []\n",
    "          for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "          total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        print(\"{}_train_{}, {}, {}\".format(\n",
    "          epoch, batch, total_loss.numpy(),\n",
    "          list(map(lambda x: np.sum(x.numpy()), pred_loss))\n",
    "        ))\n",
    "        avg_loss.update_state(total_loss)\n",
    "  elif mode == 'fit':\n",
    "    callbacks = [\n",
    "      ReduceLROnPlateau(verbose=1),\n",
    "      EarlyStopping(patience=15, verbose=1),\n",
    "      ModelCheckpoint(\n",
    "        f'checkpoints/{type_model}_{MAX_CLASS}class_{units}_units_{inner_ly}_checkpoint.h5', \n",
    "        verbose=1,\n",
    "        monitor='accuracy',\n",
    "        save_freq='epoch',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=save_weights_only,\n",
    "      ),\n",
    "      TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(\n",
    "      train_ds,\n",
    "      epochs=epochs,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=val_ds\n",
    "    )\n",
    "    end_time = time.time() - start_time\n",
    "    print(f'Total Training Time: {end_time} seconds')\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "  'image': tf.io.FixedLenFeature([], tf.string),\n",
    "  'class_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "if False:\n",
    "  class_array = pkl.load(open(CLASS_ARRAY_PATH, 'rb'))\n",
    "  if os.path.exists(TFRECORD_PATH):\n",
    "    os.remove(TFRECORD_PATH)\n",
    "  #DATASET_PATH DATASET_FACES_PATH\n",
    "  create_tfrecord(DATASET_PATH, class_array, TFRECORD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 11753\n"
     ]
    }
   ],
   "source": [
    "tf_record = load_tfrecord_dataset(TFRECORD_PATH, SIZE_IMG) #TFRECORD_PATH\n",
    "# 32: 11753\n",
    "all_ds_len = sum(1 for _ in tf_record)\n",
    "print(f'Total number of images: {all_ds_len}')\n",
    "\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_valid = int(all_ds_len * 0.1)\n",
    "n_test = all_ds_len - n_train - n_valid\n",
    "\n",
    "tf_record = tf_record.shuffle(n_train + n_valid + n_test, seed=SEED)\n",
    "train_ds = tf_record.take(n_train)\n",
    "valid_ds = tf_record.skip(n_train).take(n_valid)\n",
    "test_ds = tf_record.skip(n_train + n_valid).take(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Acc** |  **LR** | **Epochs** | **Batch** | **Units** | **Layers** | **Class** | **Type** | Passed |\n",
    "|:-------:|:-------:|:----------:|:---------:|:---------:|:----------:|:---------:|:---------:|:--------:|\n",
    "|    0.975 | 0.00001 |        300 |        32 |      1024 |          1 |         8 |      VGG | - |\n",
    "|    0.925 | 0.000025|        300 |        32 |      1024 |          1 |        16 |      VGG | x |\n",
    "|    0.903 | 0.000025|        300 |        32 |      1024 |          1 |        32 |      VGG | - |\n",
    "|    FACES |\n",
    "|          | 0.000025|        300 |        32 |      1024 |          1 |        32 |       VGG| Face detector doesn't work |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "    294/Unknown - 56s 134ms/step - loss: 3.5263 - accuracy: 0.0358\n",
      "Epoch 1: accuracy improved from -inf to 0.03584, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 70s 182ms/step - loss: 3.5263 - accuracy: 0.0358 - val_loss: 3.4603 - val_accuracy: 0.0298 - lr: 5.0000e-05\n",
      "Epoch 2/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.4610 - accuracy: 0.0397\n",
      "Epoch 2: accuracy improved from 0.03584 to 0.03967, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 180ms/step - loss: 3.4610 - accuracy: 0.0397 - val_loss: 3.4535 - val_accuracy: 0.0468 - lr: 5.0000e-05\n",
      "Epoch 3/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.4425 - accuracy: 0.0334\n",
      "Epoch 3: accuracy did not improve from 0.03967\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 3.4425 - accuracy: 0.0334 - val_loss: 3.4277 - val_accuracy: 0.0391 - lr: 5.0000e-05\n",
      "Epoch 4/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.3954 - accuracy: 0.0400\n",
      "Epoch 4: accuracy improved from 0.03967 to 0.03999, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 3.3954 - accuracy: 0.0400 - val_loss: 3.3660 - val_accuracy: 0.0570 - lr: 5.0000e-05\n",
      "Epoch 5/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.3496 - accuracy: 0.0444\n",
      "Epoch 5: accuracy improved from 0.03999 to 0.04435, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 3.3496 - accuracy: 0.0444 - val_loss: 3.3403 - val_accuracy: 0.0749 - lr: 5.0000e-05\n",
      "Epoch 6/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.3039 - accuracy: 0.0540\n",
      "Epoch 6: accuracy improved from 0.04435 to 0.05403, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 3.3039 - accuracy: 0.0540 - val_loss: 3.3153 - val_accuracy: 0.0672 - lr: 5.0000e-05\n",
      "Epoch 7/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.2631 - accuracy: 0.0591\n",
      "Epoch 7: accuracy improved from 0.05403 to 0.05914, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 3.2631 - accuracy: 0.0591 - val_loss: 3.2637 - val_accuracy: 0.0689 - lr: 5.0000e-05\n",
      "Epoch 8/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.2279 - accuracy: 0.0648\n",
      "Epoch 8: accuracy improved from 0.05914 to 0.06477, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 3.2279 - accuracy: 0.0648 - val_loss: 3.2405 - val_accuracy: 0.0732 - lr: 5.0000e-05\n",
      "Epoch 9/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.2008 - accuracy: 0.0758\n",
      "Epoch 9: accuracy improved from 0.06477 to 0.07583, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 3.2008 - accuracy: 0.0758 - val_loss: 3.1465 - val_accuracy: 0.0826 - lr: 5.0000e-05\n",
      "Epoch 10/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.1671 - accuracy: 0.0752\n",
      "Epoch 10: accuracy did not improve from 0.07583\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 3.1671 - accuracy: 0.0752 - val_loss: 3.1728 - val_accuracy: 0.0919 - lr: 5.0000e-05\n",
      "Epoch 11/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.1375 - accuracy: 0.0770\n",
      "Epoch 11: accuracy improved from 0.07583 to 0.07700, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 180ms/step - loss: 3.1375 - accuracy: 0.0770 - val_loss: 3.1893 - val_accuracy: 0.1055 - lr: 5.0000e-05\n",
      "Epoch 12/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.0886 - accuracy: 0.0852\n",
      "Epoch 12: accuracy improved from 0.07700 to 0.08519, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 181ms/step - loss: 3.0886 - accuracy: 0.0852 - val_loss: 3.0738 - val_accuracy: 0.1157 - lr: 5.0000e-05\n",
      "Epoch 13/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 3.0024 - accuracy: 0.0932\n",
      "Epoch 13: accuracy improved from 0.08519 to 0.09317, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 180ms/step - loss: 3.0024 - accuracy: 0.0932 - val_loss: 2.9010 - val_accuracy: 0.1183 - lr: 5.0000e-05\n",
      "Epoch 14/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.8995 - accuracy: 0.1146\n",
      "Epoch 14: accuracy improved from 0.09317 to 0.11455, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 180ms/step - loss: 2.8995 - accuracy: 0.1146 - val_loss: 2.8892 - val_accuracy: 0.1396 - lr: 5.0000e-05\n",
      "Epoch 15/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.8279 - accuracy: 0.1230\n",
      "Epoch 15: accuracy improved from 0.11455 to 0.12295, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 2.8279 - accuracy: 0.1230 - val_loss: 2.7400 - val_accuracy: 0.1345 - lr: 5.0000e-05\n",
      "Epoch 16/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.7605 - accuracy: 0.1353\n",
      "Epoch 16: accuracy improved from 0.12295 to 0.13529, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 58s 180ms/step - loss: 2.7605 - accuracy: 0.1353 - val_loss: 2.6492 - val_accuracy: 0.1557 - lr: 5.0000e-05\n",
      "Epoch 17/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.6871 - accuracy: 0.1398\n",
      "Epoch 17: accuracy improved from 0.13529 to 0.13976, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 2.6871 - accuracy: 0.1398 - val_loss: 2.4894 - val_accuracy: 0.1949 - lr: 5.0000e-05\n",
      "Epoch 18/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.6268 - accuracy: 0.1541\n",
      "Epoch 18: accuracy improved from 0.13976 to 0.15412, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 2.6268 - accuracy: 0.1541 - val_loss: 2.4786 - val_accuracy: 0.1932 - lr: 5.0000e-05\n",
      "Epoch 19/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.5573 - accuracy: 0.1728\n",
      "Epoch 19: accuracy improved from 0.15412 to 0.17284, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 2.5573 - accuracy: 0.1728 - val_loss: 2.4865 - val_accuracy: 0.2000 - lr: 5.0000e-05\n",
      "Epoch 20/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.4942 - accuracy: 0.1845\n",
      "Epoch 20: accuracy improved from 0.17284 to 0.18454, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 2.4942 - accuracy: 0.1845 - val_loss: 2.3244 - val_accuracy: 0.2281 - lr: 5.0000e-05\n",
      "Epoch 21/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.4208 - accuracy: 0.1989\n",
      "Epoch 21: accuracy improved from 0.18454 to 0.19889, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 2.4208 - accuracy: 0.1989 - val_loss: 2.3181 - val_accuracy: 0.2349 - lr: 5.0000e-05\n",
      "Epoch 22/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.3440 - accuracy: 0.2160\n",
      "Epoch 22: accuracy improved from 0.19889 to 0.21602, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 2.3440 - accuracy: 0.2160 - val_loss: 2.1745 - val_accuracy: 0.2689 - lr: 5.0000e-05\n",
      "Epoch 23/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.2684 - accuracy: 0.2346\n",
      "Epoch 23: accuracy improved from 0.21602 to 0.23463, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 181ms/step - loss: 2.2684 - accuracy: 0.2346 - val_loss: 2.0876 - val_accuracy: 0.2902 - lr: 5.0000e-05\n",
      "Epoch 24/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.1966 - accuracy: 0.2570\n",
      "Epoch 24: accuracy improved from 0.23463 to 0.25697, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 2.1966 - accuracy: 0.2570 - val_loss: 1.9732 - val_accuracy: 0.3336 - lr: 5.0000e-05\n",
      "Epoch 25/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.1102 - accuracy: 0.2747\n",
      "Epoch 25: accuracy improved from 0.25697 to 0.27473, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 2.1102 - accuracy: 0.2747 - val_loss: 1.9255 - val_accuracy: 0.3319 - lr: 5.0000e-05\n",
      "Epoch 26/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 2.0421 - accuracy: 0.2916\n",
      "Epoch 26: accuracy improved from 0.27473 to 0.29164, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 2.0421 - accuracy: 0.2916 - val_loss: 1.7507 - val_accuracy: 0.3932 - lr: 5.0000e-05\n",
      "Epoch 27/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.9610 - accuracy: 0.3156\n",
      "Epoch 27: accuracy improved from 0.29164 to 0.31557, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.9610 - accuracy: 0.3156 - val_loss: 1.7133 - val_accuracy: 0.3855 - lr: 5.0000e-05\n",
      "Epoch 28/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.8771 - accuracy: 0.3262\n",
      "Epoch 28: accuracy improved from 0.31557 to 0.32621, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.8771 - accuracy: 0.3262 - val_loss: 1.6338 - val_accuracy: 0.4043 - lr: 5.0000e-05\n",
      "Epoch 29/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.7847 - accuracy: 0.3534\n",
      "Epoch 29: accuracy improved from 0.32621 to 0.35344, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.7847 - accuracy: 0.3534 - val_loss: 1.4891 - val_accuracy: 0.4553 - lr: 5.0000e-05\n",
      "Epoch 30/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.7259 - accuracy: 0.3805\n",
      "Epoch 30: accuracy improved from 0.35344 to 0.38045, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.7259 - accuracy: 0.3805 - val_loss: 1.4478 - val_accuracy: 0.4715 - lr: 5.0000e-05\n",
      "Epoch 31/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 0.3934\n",
      "Epoch 31: accuracy improved from 0.38045 to 0.39343, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.6467 - accuracy: 0.3934 - val_loss: 1.3133 - val_accuracy: 0.5166 - lr: 5.0000e-05\n",
      "Epoch 32/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.5747 - accuracy: 0.4159\n",
      "Epoch 32: accuracy improved from 0.39343 to 0.41587, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.5747 - accuracy: 0.4159 - val_loss: 1.2726 - val_accuracy: 0.5379 - lr: 5.0000e-05\n",
      "Epoch 33/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.5075 - accuracy: 0.4405\n",
      "Epoch 33: accuracy improved from 0.41587 to 0.44054, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.5075 - accuracy: 0.4405 - val_loss: 1.1857 - val_accuracy: 0.5549 - lr: 5.0000e-05\n",
      "Epoch 34/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.4240 - accuracy: 0.4662\n",
      "Epoch 34: accuracy improved from 0.44054 to 0.46618, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 1.4240 - accuracy: 0.4662 - val_loss: 1.1053 - val_accuracy: 0.6102 - lr: 5.0000e-05\n",
      "Epoch 35/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.3343 - accuracy: 0.5061\n",
      "Epoch 35: accuracy improved from 0.46618 to 0.50606, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.3343 - accuracy: 0.5061 - val_loss: 1.0391 - val_accuracy: 0.5966 - lr: 5.0000e-05\n",
      "Epoch 36/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.2870 - accuracy: 0.5119\n",
      "Epoch 36: accuracy improved from 0.50606 to 0.51191, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.2870 - accuracy: 0.5119 - val_loss: 0.9255 - val_accuracy: 0.6494 - lr: 5.0000e-05\n",
      "Epoch 37/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.2281 - accuracy: 0.5463\n",
      "Epoch 37: accuracy improved from 0.51191 to 0.54627, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.2281 - accuracy: 0.5463 - val_loss: 0.8786 - val_accuracy: 0.6834 - lr: 5.0000e-05\n",
      "Epoch 38/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.1477 - accuracy: 0.5623\n",
      "Epoch 38: accuracy improved from 0.54627 to 0.56233, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 1.1477 - accuracy: 0.5623 - val_loss: 0.8405 - val_accuracy: 0.6885 - lr: 5.0000e-05\n",
      "Epoch 39/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.5899\n",
      "Epoch 39: accuracy improved from 0.56233 to 0.58987, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 1.0925 - accuracy: 0.5899 - val_loss: 0.7766 - val_accuracy: 0.6902 - lr: 5.0000e-05\n",
      "Epoch 40/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.0409 - accuracy: 0.6004\n",
      "Epoch 40: accuracy improved from 0.58987 to 0.60040, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 1.0409 - accuracy: 0.6004 - val_loss: 0.7193 - val_accuracy: 0.7217 - lr: 5.0000e-05\n",
      "Epoch 41/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.6204\n",
      "Epoch 41: accuracy improved from 0.60040 to 0.62040, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 1.0024 - accuracy: 0.6204 - val_loss: 0.7662 - val_accuracy: 0.6996 - lr: 5.0000e-05\n",
      "Epoch 42/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.6369\n",
      "Epoch 42: accuracy improved from 0.62040 to 0.63689, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.9459 - accuracy: 0.6369 - val_loss: 0.6958 - val_accuracy: 0.7174 - lr: 5.0000e-05\n",
      "Epoch 43/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.6592\n",
      "Epoch 43: accuracy improved from 0.63689 to 0.65922, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.9055 - accuracy: 0.6592 - val_loss: 0.6694 - val_accuracy: 0.7277 - lr: 5.0000e-05\n",
      "Epoch 44/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.6637\n",
      "Epoch 44: accuracy improved from 0.65922 to 0.66369, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 0.8754 - accuracy: 0.6637 - val_loss: 0.6259 - val_accuracy: 0.7464 - lr: 5.0000e-05\n",
      "Epoch 45/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.8204 - accuracy: 0.6789\n",
      "Epoch 45: accuracy improved from 0.66369 to 0.67890, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 0.8204 - accuracy: 0.6789 - val_loss: 0.5545 - val_accuracy: 0.7923 - lr: 5.0000e-05\n",
      "Epoch 46/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.6926\n",
      "Epoch 46: accuracy improved from 0.67890 to 0.69262, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.7991 - accuracy: 0.6926 - val_loss: 0.5837 - val_accuracy: 0.7855 - lr: 5.0000e-05\n",
      "Epoch 47/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7687 - accuracy: 0.7076\n",
      "Epoch 47: accuracy improved from 0.69262 to 0.70762, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.7687 - accuracy: 0.7076 - val_loss: 0.5053 - val_accuracy: 0.7915 - lr: 5.0000e-05\n",
      "Epoch 48/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7161\n",
      "Epoch 48: accuracy improved from 0.70762 to 0.71612, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.7339 - accuracy: 0.7161 - val_loss: 0.4855 - val_accuracy: 0.8026 - lr: 5.0000e-05\n",
      "Epoch 49/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.7288\n",
      "Epoch 49: accuracy improved from 0.71612 to 0.72878, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 0.7078 - accuracy: 0.7288 - val_loss: 0.4440 - val_accuracy: 0.8170 - lr: 5.0000e-05\n",
      "Epoch 50/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6734 - accuracy: 0.7414\n",
      "Epoch 50: accuracy improved from 0.72878 to 0.74144, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.6734 - accuracy: 0.7414 - val_loss: 0.4580 - val_accuracy: 0.8119 - lr: 5.0000e-05\n",
      "Epoch 51/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7510\n",
      "Epoch 51: accuracy improved from 0.74144 to 0.75101, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.6375 - accuracy: 0.7510 - val_loss: 0.4348 - val_accuracy: 0.8094 - lr: 5.0000e-05\n",
      "Epoch 52/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7513\n",
      "Epoch 52: accuracy improved from 0.75101 to 0.75133, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.6445 - accuracy: 0.7513 - val_loss: 0.4345 - val_accuracy: 0.8230 - lr: 5.0000e-05\n",
      "Epoch 53/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.7642\n",
      "Epoch 53: accuracy improved from 0.75133 to 0.76420, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.6198 - accuracy: 0.7642 - val_loss: 0.4120 - val_accuracy: 0.8272 - lr: 5.0000e-05\n",
      "Epoch 54/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.7760\n",
      "Epoch 54: accuracy improved from 0.76420 to 0.77601, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.5774 - accuracy: 0.7760 - val_loss: 0.3806 - val_accuracy: 0.8255 - lr: 5.0000e-05\n",
      "Epoch 55/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.7773\n",
      "Epoch 55: accuracy improved from 0.77601 to 0.77728, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.5604 - accuracy: 0.7773 - val_loss: 0.4522 - val_accuracy: 0.8077 - lr: 5.0000e-05\n",
      "Epoch 56/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.7814\n",
      "Epoch 56: accuracy improved from 0.77728 to 0.78143, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.5596 - accuracy: 0.7814 - val_loss: 0.4032 - val_accuracy: 0.8289 - lr: 5.0000e-05\n",
      "Epoch 57/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.7887\n",
      "Epoch 57: accuracy improved from 0.78143 to 0.78866, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.5356 - accuracy: 0.7887 - val_loss: 0.3478 - val_accuracy: 0.8400 - lr: 5.0000e-05\n",
      "Epoch 58/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7861\n",
      "Epoch 58: accuracy did not improve from 0.78866\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.5371 - accuracy: 0.7861 - val_loss: 0.3673 - val_accuracy: 0.8485 - lr: 5.0000e-05\n",
      "Epoch 59/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8057\n",
      "Epoch 59: accuracy improved from 0.78866 to 0.80568, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.4932 - accuracy: 0.8057 - val_loss: 0.2900 - val_accuracy: 0.8800 - lr: 5.0000e-05\n",
      "Epoch 60/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.8050\n",
      "Epoch 60: accuracy did not improve from 0.80568\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4921 - accuracy: 0.8050 - val_loss: 0.3014 - val_accuracy: 0.8519 - lr: 5.0000e-05\n",
      "Epoch 61/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8047\n",
      "Epoch 61: accuracy did not improve from 0.80568\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4797 - accuracy: 0.8047 - val_loss: 0.3511 - val_accuracy: 0.8417 - lr: 5.0000e-05\n",
      "Epoch 62/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.8114\n",
      "Epoch 62: accuracy improved from 0.80568 to 0.81142, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4556 - accuracy: 0.8114 - val_loss: 0.2817 - val_accuracy: 0.8655 - lr: 5.0000e-05\n",
      "Epoch 63/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8150\n",
      "Epoch 63: accuracy improved from 0.81142 to 0.81504, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.4567 - accuracy: 0.8150 - val_loss: 0.3441 - val_accuracy: 0.8451 - lr: 5.0000e-05\n",
      "Epoch 64/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8189\n",
      "Epoch 64: accuracy improved from 0.81504 to 0.81887, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4500 - accuracy: 0.8189 - val_loss: 0.2823 - val_accuracy: 0.8570 - lr: 5.0000e-05\n",
      "Epoch 65/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8177\n",
      "Epoch 65: accuracy did not improve from 0.81887\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4394 - accuracy: 0.8177 - val_loss: 0.3217 - val_accuracy: 0.8545 - lr: 5.0000e-05\n",
      "Epoch 66/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8288\n",
      "Epoch 66: accuracy improved from 0.81887 to 0.82876, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4324 - accuracy: 0.8288 - val_loss: 0.3143 - val_accuracy: 0.8545 - lr: 5.0000e-05\n",
      "Epoch 67/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.8308\n",
      "Epoch 67: accuracy improved from 0.82876 to 0.83078, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 61s 186ms/step - loss: 0.4118 - accuracy: 0.8308 - val_loss: 0.3376 - val_accuracy: 0.8536 - lr: 5.0000e-05\n",
      "Epoch 68/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8256\n",
      "Epoch 68: accuracy did not improve from 0.83078\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.4173 - accuracy: 0.8256 - val_loss: 0.3125 - val_accuracy: 0.8630 - lr: 5.0000e-05\n",
      "Epoch 69/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8344\n",
      "Epoch 69: accuracy improved from 0.83078 to 0.83440, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.4094 - accuracy: 0.8344 - val_loss: 0.3189 - val_accuracy: 0.8579 - lr: 5.0000e-05\n",
      "Epoch 70/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.8345\n",
      "Epoch 70: accuracy improved from 0.83440 to 0.83450, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.4046 - accuracy: 0.8345 - val_loss: 0.3008 - val_accuracy: 0.8570 - lr: 5.0000e-05\n",
      "Epoch 71/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8323\n",
      "Epoch 71: accuracy did not improve from 0.83450\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.3930 - accuracy: 0.8323 - val_loss: 0.3042 - val_accuracy: 0.8757 - lr: 5.0000e-05\n",
      "Epoch 72/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8378\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 72: accuracy improved from 0.83450 to 0.83780, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.3954 - accuracy: 0.8378 - val_loss: 0.2990 - val_accuracy: 0.8621 - lr: 5.0000e-05\n",
      "Epoch 73/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8459\n",
      "Epoch 73: accuracy improved from 0.83780 to 0.84588, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.3462 - accuracy: 0.8459 - val_loss: 0.2590 - val_accuracy: 0.8613 - lr: 5.0000e-06\n",
      "Epoch 74/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8551\n",
      "Epoch 74: accuracy improved from 0.84588 to 0.85514, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.3170 - accuracy: 0.8551 - val_loss: 0.2527 - val_accuracy: 0.8732 - lr: 5.0000e-06\n",
      "Epoch 75/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8609\n",
      "Epoch 75: accuracy improved from 0.85514 to 0.86088, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.2912 - accuracy: 0.8609 - val_loss: 0.2093 - val_accuracy: 0.8715 - lr: 5.0000e-06\n",
      "Epoch 76/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.8589\n",
      "Epoch 76: accuracy did not improve from 0.86088\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2843 - accuracy: 0.8589 - val_loss: 0.2060 - val_accuracy: 0.8749 - lr: 5.0000e-06\n",
      "Epoch 77/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8635\n",
      "Epoch 77: accuracy improved from 0.86088 to 0.86354, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2696 - accuracy: 0.8635 - val_loss: 0.2264 - val_accuracy: 0.8672 - lr: 5.0000e-06\n",
      "Epoch 78/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.8689\n",
      "Epoch 78: accuracy improved from 0.86354 to 0.86886, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 61s 187ms/step - loss: 0.2620 - accuracy: 0.8689 - val_loss: 0.2090 - val_accuracy: 0.8911 - lr: 5.0000e-06\n",
      "Epoch 79/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.8629\n",
      "Epoch 79: accuracy did not improve from 0.86886\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2631 - accuracy: 0.8629 - val_loss: 0.2041 - val_accuracy: 0.8826 - lr: 5.0000e-06\n",
      "Epoch 80/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.8715\n",
      "Epoch 80: accuracy improved from 0.86886 to 0.87152, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2551 - accuracy: 0.8715 - val_loss: 0.2251 - val_accuracy: 0.8621 - lr: 5.0000e-06\n",
      "Epoch 81/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.8652\n",
      "Epoch 81: accuracy did not improve from 0.87152\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2531 - accuracy: 0.8652 - val_loss: 0.2177 - val_accuracy: 0.8596 - lr: 5.0000e-06\n",
      "Epoch 82/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.8655\n",
      "Epoch 82: accuracy did not improve from 0.87152\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2509 - accuracy: 0.8655 - val_loss: 0.1966 - val_accuracy: 0.8681 - lr: 5.0000e-06\n",
      "Epoch 83/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.8703\n",
      "Epoch 83: accuracy did not improve from 0.87152\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2448 - accuracy: 0.8703 - val_loss: 0.2145 - val_accuracy: 0.8740 - lr: 5.0000e-06\n",
      "Epoch 84/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.8742\n",
      "Epoch 84: accuracy improved from 0.87152 to 0.87418, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2423 - accuracy: 0.8742 - val_loss: 0.2138 - val_accuracy: 0.8698 - lr: 5.0000e-06\n",
      "Epoch 85/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.8735\n",
      "Epoch 85: accuracy did not improve from 0.87418\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2418 - accuracy: 0.8735 - val_loss: 0.2015 - val_accuracy: 0.8877 - lr: 5.0000e-06\n",
      "Epoch 86/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.8679\n",
      "Epoch 86: accuracy did not improve from 0.87418\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2427 - accuracy: 0.8679 - val_loss: 0.2117 - val_accuracy: 0.8732 - lr: 5.0000e-06\n",
      "Epoch 87/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.8669\n",
      "Epoch 87: accuracy did not improve from 0.87418\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2482 - accuracy: 0.8669 - val_loss: 0.2017 - val_accuracy: 0.8860 - lr: 5.0000e-06\n",
      "Epoch 88/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.8723\n",
      "Epoch 88: accuracy did not improve from 0.87418\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2409 - accuracy: 0.8723 - val_loss: 0.2026 - val_accuracy: 0.8834 - lr: 5.0000e-06\n",
      "Epoch 89/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.8708\n",
      "Epoch 89: accuracy did not improve from 0.87418\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2417 - accuracy: 0.8708 - val_loss: 0.1972 - val_accuracy: 0.8800 - lr: 5.0000e-06\n",
      "Epoch 90/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.8756\n",
      "Epoch 90: accuracy improved from 0.87418 to 0.87556, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2322 - accuracy: 0.8756 - val_loss: 0.2181 - val_accuracy: 0.8689 - lr: 5.0000e-06\n",
      "Epoch 91/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.8773\n",
      "Epoch 91: accuracy improved from 0.87556 to 0.87726, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2344 - accuracy: 0.8773 - val_loss: 0.2167 - val_accuracy: 0.8689 - lr: 5.0000e-06\n",
      "Epoch 92/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.8684\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-07.\n",
      "\n",
      "Epoch 92: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2375 - accuracy: 0.8684 - val_loss: 0.2041 - val_accuracy: 0.8749 - lr: 5.0000e-06\n",
      "Epoch 93/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.8762\n",
      "Epoch 93: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2339 - accuracy: 0.8762 - val_loss: 0.1984 - val_accuracy: 0.8834 - lr: 5.0000e-07\n",
      "Epoch 94/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.8674\n",
      "Epoch 94: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2365 - accuracy: 0.8674 - val_loss: 0.1977 - val_accuracy: 0.8809 - lr: 5.0000e-07\n",
      "Epoch 95/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.8727\n",
      "Epoch 95: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2340 - accuracy: 0.8727 - val_loss: 0.2048 - val_accuracy: 0.8843 - lr: 5.0000e-07\n",
      "Epoch 96/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.8724\n",
      "Epoch 96: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2320 - accuracy: 0.8724 - val_loss: 0.1878 - val_accuracy: 0.8843 - lr: 5.0000e-07\n",
      "Epoch 97/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.8694\n",
      "Epoch 97: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2328 - accuracy: 0.8694 - val_loss: 0.2054 - val_accuracy: 0.8817 - lr: 5.0000e-07\n",
      "Epoch 98/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.8744\n",
      "Epoch 98: accuracy did not improve from 0.87726\n",
      "294/294 [==============================] - 59s 182ms/step - loss: 0.2285 - accuracy: 0.8744 - val_loss: 0.2158 - val_accuracy: 0.8791 - lr: 5.0000e-07\n",
      "Epoch 99/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.8796\n",
      "Epoch 99: accuracy improved from 0.87726 to 0.87960, saving model to checkpoints\\resnet_32class_1024_units_6_checkpoint.h5\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2267 - accuracy: 0.8796 - val_loss: 0.1955 - val_accuracy: 0.8919 - lr: 5.0000e-07\n",
      "Epoch 100/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.8752\n",
      "Epoch 100: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 59s 183ms/step - loss: 0.2267 - accuracy: 0.8752 - val_loss: 0.1908 - val_accuracy: 0.8860 - lr: 5.0000e-07\n",
      "Epoch 101/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.8689\n",
      "Epoch 101: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2333 - accuracy: 0.8689 - val_loss: 0.2085 - val_accuracy: 0.8851 - lr: 5.0000e-07\n",
      "Epoch 102/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.8726\n",
      "Epoch 102: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2299 - accuracy: 0.8726 - val_loss: 0.1885 - val_accuracy: 0.8877 - lr: 5.0000e-07\n",
      "Epoch 103/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.8698\n",
      "Epoch 103: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2349 - accuracy: 0.8698 - val_loss: 0.1998 - val_accuracy: 0.8851 - lr: 5.0000e-07\n",
      "Epoch 104/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.8743\n",
      "Epoch 104: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2237 - accuracy: 0.8743 - val_loss: 0.1895 - val_accuracy: 0.8902 - lr: 5.0000e-07\n",
      "Epoch 105/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.8748\n",
      "Epoch 105: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2255 - accuracy: 0.8748 - val_loss: 0.1786 - val_accuracy: 0.8817 - lr: 5.0000e-07\n",
      "Epoch 106/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.8747\n",
      "Epoch 106: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2238 - accuracy: 0.8747 - val_loss: 0.1787 - val_accuracy: 0.8928 - lr: 5.0000e-07\n",
      "Epoch 107/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.8772\n",
      "Epoch 107: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2237 - accuracy: 0.8772 - val_loss: 0.2197 - val_accuracy: 0.8809 - lr: 5.0000e-07\n",
      "Epoch 108/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.8757\n",
      "Epoch 108: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2257 - accuracy: 0.8757 - val_loss: 0.1988 - val_accuracy: 0.8766 - lr: 5.0000e-07\n",
      "Epoch 109/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.8760\n",
      "Epoch 109: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2295 - accuracy: 0.8760 - val_loss: 0.1814 - val_accuracy: 0.8962 - lr: 5.0000e-07\n",
      "Epoch 110/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.8768\n",
      "Epoch 110: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2226 - accuracy: 0.8768 - val_loss: 0.2116 - val_accuracy: 0.8826 - lr: 5.0000e-07\n",
      "Epoch 111/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.8765\n",
      "Epoch 111: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2255 - accuracy: 0.8765 - val_loss: 0.1896 - val_accuracy: 0.8877 - lr: 5.0000e-07\n",
      "Epoch 112/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.8758\n",
      "Epoch 112: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2226 - accuracy: 0.8758 - val_loss: 0.1881 - val_accuracy: 0.8800 - lr: 5.0000e-07\n",
      "Epoch 113/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.8679\n",
      "Epoch 113: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2268 - accuracy: 0.8679 - val_loss: 0.1917 - val_accuracy: 0.8774 - lr: 5.0000e-07\n",
      "Epoch 114/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.8776\n",
      "Epoch 114: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2185 - accuracy: 0.8776 - val_loss: 0.2157 - val_accuracy: 0.8732 - lr: 5.0000e-07\n",
      "Epoch 115/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.8739\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-08.\n",
      "\n",
      "Epoch 115: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2272 - accuracy: 0.8739 - val_loss: 0.1837 - val_accuracy: 0.8800 - lr: 5.0000e-07\n",
      "Epoch 116/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.8759\n",
      "Epoch 116: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2228 - accuracy: 0.8759 - val_loss: 0.2154 - val_accuracy: 0.8596 - lr: 5.0000e-08\n",
      "Epoch 117/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.8761\n",
      "Epoch 117: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 186ms/step - loss: 0.2267 - accuracy: 0.8761 - val_loss: 0.2137 - val_accuracy: 0.8698 - lr: 5.0000e-08\n",
      "Epoch 118/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.8709\n",
      "Epoch 118: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 185ms/step - loss: 0.2284 - accuracy: 0.8709 - val_loss: 0.1988 - val_accuracy: 0.8868 - lr: 5.0000e-08\n",
      "Epoch 119/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.8766\n",
      "Epoch 119: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 184ms/step - loss: 0.2224 - accuracy: 0.8766 - val_loss: 0.1908 - val_accuracy: 0.8809 - lr: 5.0000e-08\n",
      "Epoch 120/200\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.8730\n",
      "Epoch 120: accuracy did not improve from 0.87960\n",
      "294/294 [==============================] - 60s 183ms/step - loss: 0.2279 - accuracy: 0.8730 - val_loss: 0.1796 - val_accuracy: 0.8894 - lr: 5.0000e-08\n",
      "Epoch 120: early stopping\n",
      "Total Training Time: 7173.508592367172 seconds\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000050, clipnorm=1.0) #0.000025 0.00001\n",
    "\n",
    "model = None\n",
    "vanilla_model = False\n",
    "INNER_LY = 6\n",
    "EXTRACTOR_MODEL = 'resnet' #vgg inception resnet\n",
    "class_array = pkl.load(open(CLASS_ARRAY_PATH, 'rb'))\n",
    "\n",
    "if vanilla_model:\n",
    "  model = create_model(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor='vgg',\n",
    "    units=UNITS\n",
    "  )\n",
    "else:\n",
    "  model = AnimeClassifier(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor=EXTRACTOR_MODEL,\n",
    "    units=UNITS,\n",
    "    inner_layers=INNER_LY\n",
    "  )\n",
    "  model.build(input_shape=(None, SIZE_IMG, SIZE_IMG, 3))\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "train(\n",
    "  model=model,\n",
    "  epochs=200,\n",
    "  units=UNITS,\n",
    "  val_ds=valid_ds.batch(32),\n",
    "  train_ds=train_ds.batch(32),\n",
    "  save_weights_only=False if vanilla_model else True,\n",
    "  mode='fit', type_model=EXTRACTOR_MODEL, inner_ly=INNER_LY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVA_INNER = 6\n",
    "EVA_CLASS = 32\n",
    "EVA_UNITS = 1024\n",
    "EVA_TYPE  = 'resnet'\n",
    "EVA_MODEL_CLASS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images or test: 2350\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABPAAAAJOCAYAAAA50/k8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAC8HElEQVR4nOzdeXxU1d3H8e8vG6viRhKQiGjABShWcakbgiLIJhRtrbVWC+JWse6i1vXBqq1tbatFkKp134oiILUiKOIGogLuoAgImbDKTrbz/DGTGHGSgSRz58zN593XvJpZ7ydnJhgO595rzjkBAAAAAAAA8FNGqgMAAAAAAAAA1IwJPAAAAAAAAMBjTOABAAAAAAAAHmMCDwAAAAAAAPAYE3gAAAAAAACAx5jAAwAAAAAAADzGBB4AoEGZWTMze9HMvjWzZ+rxOr80s5cbsi1VzOw4M/ss1R31YWbOzApT3YHwMLPrzOyBVHdsz6c/e8zsZjN7NNUdAAAg9ZjAA4BGyszONLM5ZrbRzFaY2UtmdmwDvPRpkvIk7emcO72uL+Kce8w5d3ID9CTVjkxsOedmOucOSNL2f2dmX5rZejNbbmZ/MbOs2H25ZvZE7PZvzWyWmR2ZjA7suIaYDDWzsWb2mZlVmNk5ce6/zMyKYu/7v8ysSez2JmY23sy+NrMNZva+mZ1SwzZuirWeVJ/WmjjnbnfODY9ta9/YtrKSsa3YNs4ws0/MbJOZLTKz42roSos/ewAAQOPCBB4ANEJmdrmkv0q6XdHJtn0k3Sfp1AZ4+faSPnfOlTXAa6W9ZE5IxLwo6VDn3K6SukjqJmlk7L6WkmZLOkzSHpIeljTZzFomuSktBPDeJNOHki6SNHf7O8ysj6RrJZ0oaV9J+0m6JXZ3lqSlknpIaiXp95KeNrN9t3uN/RWdjF+RlPqAmVlvSXdKOlfSLpKOl/RlSqO248vn0ZcOAADwfUzgAUAjY2atJN0q6WLn3H+cc5ucc6XOuRedc1fFHtPEzP4aW7m1PPZ15QqeE8xsmZldYWbFsdV758buu0XSjZJ+HlvZN2z7XcC2X2ljZufEVpBtMLOvzOyX1W5/o9rzjjaz2bEVRbPN7Ohq980ws9tiK8w2mNnLZrZXDd9/Zf/V1foHm1k/M/vczNaY2XXVHn+Emb1lZutij/2HmeXE7ns99rAPY9/vz6u9/jVmViTpwcrbYs/ZP7aNQ2PX25rZKjM7oS7vp3NukXNuXWWupApJhbH7vnTO/dk5t8I5V+6cGyspR1Lc1YBmlmnR3RoXxcbxPTMriPO4/rGVW+vNbKmZ3VztvqZm9qiZrY6N2Wwzy4vdF/e9jt33m9jqqLVm9l8zax+73Sy6qrA49t7PM7MudRmr2Gfx2VjfeknnmFkri65IW2Fm35jZ/5lZZuzxhWb2Wmy7q8zsqWqv5czsAjP7ItZ8r5nZDnw/P/jM1OV7cc7d65ybJmlrnLt/LWm8c+4j59xaSbdJOif2vE3OuZudc4udcxXOuUmSvlJ0kre6f0i6RlJJbR1mttiqrdCr/vNe7Wf912a2JDaG18d7rKTKcVkXG5ef1Db+dXCLpFudc2/Hvu9vnHPf1PA9bf9nT43vdeVjzexPsfu+smorGhN8vs6x6J9ZfzGzNZJuTvRNmNkz9t3KytfNrHPs9sPNLGLVJt/MbKiZfRD7OsPMro39bK82s6fNbI/YfZXv0zAzWyLp1dp+jgEAQGowgQcAjc9PJDWVNKGWx1wv6ShJhyi6ousISTdUuz9f0dU7e0saJuleM9vdOXeToqv6nnLOtXTOja8txMxaSPqbpFOcc7tIOlrSB3Eet4ekybHH7inpz4quJNuz2sPOVHR1Ta6ik1RX1rLpfEXHYG9FJxzHSTpL0UmM4yTdaGb7xR5bLukySXspOnYnKrrySc6542OP6Rb7fp+q9vp7KLoacUT1DTvnFik6MfKYmTWX9KCkh5xzM2rprZVFd4deL2mVou/X/TU87hBFx2ZhDS91uaRfSOonaVdJv5G0Oc7jNkk6W9JukvpLutDMBsfu+7Win40CRd+rCyRtqe29jj33Okk/ldRa0kxJT8Re72RFV0t1im3v55JW19C/I06V9GzstR5TdFVimaKTnj+ObW947LG3SXpZ0u6S2kn6+3avNUDS4YqO+c8k9Un0/dTymWlInRVdoVfpQ0l52/28KNaap+jYflTtttMllTjnpjRQz7GKThqfqOjP1kFxHlM5LrvFxuUtJR7/HRKbMOsuqbWZLbToBPs/zKzZTrxM3Pc65khJnyn6Z8RdksZXm8yt7fNV+dwvFf1za/QOdLwkqWPs8XMV/QzLOTdb0Z+L3tUee5akR2Jfj5Q0WNGVl20lrZV073av3UPSQbHvLe7P8Q70AQCAJGECDwAanz0lrUqwi+svFV2tUuycW6no6pVfVbu/NHZ/aewv+RtVw6quHVAhqYuZNYutFPsozmP6S/rCOfeIc67MOfeEpE8lDaz2mAedc58757ZIelrRycealEoa7ZwrlfSkon/xvsc5tyG2/Y8k/UiSnHPvxVbtlDnnFis6OdZjB76nm5xz22I93+OcGyfpC0nvSGqj6IRpnTnnHo/tQttJ0hhJke0fY2a7KvqX+Vucc9/W8FLDJd3gnPvMRX3onPvBZJlzboZzbn5sJdM8RSenKsekVNHPWGFs1d97zrn1sftqeq/Pl/QH59wnsc/l7ZIOia1aK1V0l8cDJVnsMfXZrfMt59zzzrkKRScpT5H0u9jKtGJJf5F0RrXvpb2kts65rc65N7Z7rTucc+ucc0skTdd3n7navp8gtJRU/T2u/HqX6g8ys2zFJjGdc5/GbmupaO/vGrDnFufcFufch4pOJnbbweclGv8dlScpW9Fdgo9T9H36sb7/jxKJ1PReS9LXzrlxzrlyRSfs2ig6YZqn2j9fkrTcOff32J8vCSfInHP/iv05tU3RFXvdLLqqWrFtnyVV/aNHH0mPx+47X9L1zrll1Z57mn1/d9mbY51bVPvPMQAASAEm8ACg8VktaS+r/ThHbSV9Xe3617Hbql5juwnAzYpOGuwU59wmRVdUXSBphZlNNrMDd6CnsmnvateLdqJndewv29J3q0qqT3ptqXy+mXUys0mx3dbWKzq5EXf33GpWOufi7dpY3ThFj1n399hfqH/AomfD3Bi7vJTg9eSc+0LRycf7tnudZooeK+9t59wfanmJAkmLEm3HzI40s+lmttLMvlX0/asck0ck/VfSkxbd/fouM8tO8F63l3RPbFe9dZLWKLo78N7OuVcV3Z3zXkkRi568Ydc4TcdVG6t4k8CVllb7ur2iEzsrqm37fkVXN0nS1bGOd83sIzP7zXavVdNnrsbvp5au6t/LR9W+l7gnWkhgo6KTk5Uqv95QbRsZir5XJZJ+W+2xt0h6xDn3VR22W5Od+dmsLtH4S5LMbEy18bouzkMqf8b/Hps4XqXoKt5+O9gh1f49VN3nnKtcsdpSiT9f0vc/j7Wy6C7ud8R2g10vaXHsrsqfvUclDYxNwv5M0sxqk93tJU2o1vGJoquLq+8WW70l7s/xjrYCAICGxwQeADQ+byl63KzBtTxmuaJ/4au0T+y2utgkqXm16/nV73TO/dc511vRVSufKjqxlainsinuMawa2D8V7eoYW+V2naKTCrVxtd0Z+wv2XyWNl3Rz5bGofvAi0bNhtoxd4p4pNI4sSftX21YTSc8rOlbnJ3ju0urPrcXjkiZKKnDOtVJ01Z/Fmkudc7c45w5WdDfZAYrublvbe71U0vnOud2qXZo5596MPe9vzrnDFN01tJOkq7YPctEz/VaOVeda2qu/N0slbZO0V7Xt7lr5fOdckXPuPOdcW0XH7j7bsbPH1vr9JOKc61zte5m5I8/Zzkf6/iq3bpIilaspY7t3jld08mZobCVqpRMljYxNWBcpOqn7tJldU8O2av353gk/+JnZ0fF3zl1Qbbxuj3P/WknL4m0jyWr9fFXm7cTrnanoLuAnKbp7676x2yt/9r5R9M/3IYqumH6k2nOXKrr7evXPZFP3/eMAVrXU9nMMAABSgwk8AGhkXHT3yRsVPW7dYDNrbmbZZnaKmd0Ve9gTkm4ws9YWPRnEjYqu7qiLDyQdb2b7xHb1GlV5h5nlmdmg2PHRtim6cqg8zmtMkdQpdqy3LIse+P9gSZPq2LQzdpG0XtLG2IqxC7e7P6LoWT53xj2S3nPODVf02H5j6hpnZsPNLDf29cGKju+02PVsRY/3tkXS2bHdRmvzgKTbzKyjRf0o3nHTFB2TNc65rWZ2hKITC5U9Pc2sa+y4Y+sV3RWvPMF7PUbSKPvugPytYsdhqzw4/5Gx72WTopPP8T4jOy22OullSXeb2a4WPdD//mbWI7bt082sXezhaxWd4NiRbdf4/cTU5TPzPWaWY2ZNFZ28ybboSQcqf6/7t6RhZnawme2u6K6iD1V7+j8VPdbZwDi7bZ6o6MrQQ2KX5YpOnm1/vLRKH0g6I/ZnSHdFd1Oti5WK7mJdNS71GP94HpR0iZnlxsbkd0rynx+JPl91sIuiPzurFZ00/cFkpaLv/dWSuur7xzkdI2m0fXcyldZmVuNZx2v6Oa5jNwAAaABM4AFAI+Sc+7OiJyy4QdG/OC9VdDe652MP+T9JcyTNkzRf0YOl/18dt/U/SU/FXus9ff8vzRmSrlB0kmCNosdRuyjOa6xWdAXIFYr+5fVqSQNiu8Il25WKTlBtUHTF2PYnHbhZ0sOxXdN+lujFYn9p7qvorqRS9H041KqdkXUnHSNpvpltUnSic4qiqwSl71bOnKzvzu5Z226Zf1b0+IEvK/qX9vGS4h3o/yJJt5rZBkUnd5+udl++opOG6xXdTe81RSd/a3yvnXMTJN2p6O566yUtUPTYYVJ0989xik7gfK3o+/+nHRmYHXS2oif2+Di2jWcVXSEoRU9a8I6ZbVR0xeGlO7JraYLvR9rJz0wNXlZ0YvZoSWNjXx8f2/5URU+mMF3RMfta0k2SFJvAOV/Rybmiap+JX8aeuzq28q3IOVek6KTNWufcxho6fq/oqs21iu5++3gNj6tVbNfT0ZJmxcblKNVx/Gtwm6TZkj5X9HP5vnbspBH1Vdvna2f9W9H38pvY670d5zETFNtdNrbbeqV7FB3Dl2M/t28regKNmtT0cwwAAFLEnAt6bwIAAAAAyWBmixTdhfuVVLcAAICGwwo8AAAAIATMbKiiuxq/muoWAADQsGo7AyEAAACANGBmMxQ9NuivduB4lwAAIM2wCy0AAAAAAADgMXahBQAAAAAAADyW9F1om/34t94s8Vs7+x+pTgAApEBZuTf/KVJWpqU6AQAAACHQNEv8YhlHkPNQW97/R2DvASvwAAAAAAAAAI9xEgsAAAAAAACEg4VzrVo4vysAAAAAAAAgJFiBBwAAAAAAgHCwcB4a0MsVeBf/4gTNeeY6vffs9frtmSdIkq4/v58W/ff/9PaT1+rtJ69Vn2MPDrxr1szXNah/Hw3o21vjx40NfPu0pE+LLx200EJL/RUVrdCIYWdr6Kn9dPqQAXr80X+nrMWXMaGFFlrC1eJLBy200BKuFl86aEFYeDeBd/D+bXTuT4/Wcb/6o474+R90yvFdtP8+rSVJf390uo464w4ddcYd+u8bHwfaVV5erttH36r7xjygCRMna+qUSVq0cGGgDbSkR4svHbTQQkvDyMzM1GVXXKPnXpiihx59Us889Zi+XMSfLbTQQks4WnzpoIUWWsLV4ksHLQgT7ybwDuyQr3fnL9aWraUqL6/QzPcW6tSe3VKdpQXz56mgoL3aFRQoOydHffv114zp02ihxdsOWmihpWG0bp2rgw7uLElq0aKlOnTYX8XFkcA7fBoTWmihJTwtvnTQQgst4WrxpYOWRsoygrsEKOHWzOxAM7vGzP5mZvfEvj4oWUEfLVquYw8t1B6tWqhZ02z1Pbaz2uXvLkm64Izj9e5TozTmpl9qt12aJSshruJIRPlt8quu5+blKRIJ/i9wtPjf4ksHLbTQ0vCWf7NMn376ibp0Df4flnwaE1pooSU8Lb500EILLeFq8aWDFoRJrRN4ZnaNpCclmaR3Jc2Off2EmV1by/NGmNkcM5tTtuqjnQr67KuI7n7of5r0z99q4r0Xa97n36isrFzjnpmpgwferCPPuENFq9brjst/ulOvW19O7ge3WYoOjEhLfL60+NIh0VITWuKjpXabN2/SVZeP1JVXj1LLli0D375PY0JLfLTER0t8vrT40iHRUhNa4qMlPl9afOmQaGmUzIK7BCjRWWiHSersnCutfqOZ/VnSR5LuiPck59xYSWMlqdmPf/vDT2gCDz//lh5+/i1J0i2/HahvIutUvGZD1f3/+s8s/edvF+zsy9ZLXl6+ilYUVV0vjkSUm5sbaAMt6dHiSwcttNDScEpLS3XV5SN1Sv+B6nXSySlp8GlMaKGFlvC0+NJBCy20hKvFlw5aECaJdqGtkNQ2zu1tYvclRevdoysbCvJ316m9uunpqXOUv9euVfef2qubPl60Ilmbj6tzl65asmSxli1bqtKSEk2dMlk9evYKtIGW9GjxpYMWWmhpGM453XbTDerQYX+ddfa5KWmQ/BoTWmihJTwtvnTQQgst4WrxpYOWRiqkx8BLtALvd5KmmdkXkpbGbttHUqGk3yYr6ok/Ddceu7VQaVm5fnfH01q3YYvGX326fnRAOznn9PWKNbrk/55I1ubjysrK0qjrb9SFI4aroqJcg4cMVWFhx0AbaEmPFl86aKGFlobxwftzNXnSCyrs2Em/OH2wJOnikZfp2ON6BNrh05jQQgst4WnxpYMWWmgJV4svHbQgTMy52vdwNbMMSUdI2lvR498tkzTbOVe+Ixuoyy60ybJ29j9SnQAASIGycm/+U6SsTI5zAgAAgPprmiV+sYyj2ZFXBfbL/5Z3/hjYe5BoBZ6ccxWS3g6gBQAAAAAAAMB2Ek7gAQAAAAAAAGkh4GPTBSWc3xUAAAAAAAAQEklfgefTced2P3l0qhOqrH35+lQnAECjwXHnAAAAgEbCwvm7PyvwAAAAAAAAAI9xDDwAAAAAAACEA8fAAwAAAAAAABA0VuABAAAAAAAgHDgGXmrMmvm6BvXvowF9e2v8uLGBb/+S047Qe/8aoTnjz9PDNwxWk+xMdd0vVzP+/mvNfuA8PTv6Z9qleU7gXakeF1rSo4MWWmgJV4svHbTQQku4WnzpoIUWWsLV4ksHLQgLryfwysvLdfvoW3XfmAc0YeJkTZ0ySYsWLgxs+2332kUXDTlcx1zwL3UfNk6ZGabTe3XWP6/srxvGTdfhw8dp4szPdNnPfxJYk5T6caElPTpooYWWcLX40kELLbSEq8WXDlpooSVcLb500IIw8XoCb8H8eSooaK92BQXKzslR3379NWP6tEAbsjIz1KxJljIzTM2aZGvF6g3qWLCn3pi3RJL06ntfavBxBwTa5MO40OJ/By200BKuFl86aKGFlnC1+NJBCy20hKvFlw5aGinLCO4SIK8n8IojEeW3ya+6npuXp0gkEtj2l6/aoL8+/bY+f/ISffXspVq/aZumzflKHy9eqQFHd5Ik/bTHQWqXu2tgTVLqx4WW9OighRZawtXiSwcttNASrhZfOmihhZZwtfjSQQvCpM4TeGZ2bi33jTCzOWY2pz77dDu5eK9d59fbWbu1bKoBx3TSQWfeq/1O/5taNM3WGSd10fl3TdL5gw/TrDG/UcvmTVRSWh5Yk5T6camOFn87JFpqQkt8tMTnS4svHRItNaElPlri86XFlw6JlprQEh8t8fnS4kuHREujZBbcJUD1OQvtLZIejHeHc26spLGStLUszid0B+Xl5atoRVHV9eJIRLm5uXV9uZ3W67B9tXjFOq36drMk6fmZn+mozu305CsLNPDqJyRJhe320ClHFQbWJKV+XGhJjw5aaKElXC2+dNBCCy3havGlgxZaaAlXiy8dtCBMal2BZ2bzarjMl5SX7LjOXbpqyZLFWrZsqUpLSjR1ymT16Nkr2ZutsjSyXkccvLeaNYnOc/Y8dF99tmSVWu/WXFJ0svXas47RuIlzA2uSUj8utKRHBy200BKuFl86aKGFlnC1+NJBCy20hKvFlw5aGqmQHgMv0Qq8PEl9JK3d7naT9GZSiqrJysrSqOtv1IUjhquiolyDhwxVYWHHZG+2yuxPl2vCa5/qrfuHqay8Qh8ujGj8pPd13sBDdf6ph0mSXnjjM/176oeBNUmpHxda0qODFlpoCVeLLx200EJLuFp86aCFFlrC1eJLBy0IE3Ou5j1czWy8pAedc2/Eue9x59yZiTZQn11oG9ruJ49OdUKVtS9fn+oEAAAAAACQpppmiQPoxdGsx62BzUNtee3GwN6DWlfgOeeG1XJfwsk7AAAAAAAAAPVTn5NYAAAAAAAAAP7ICOfCxGCPuAcAAAAAAABgpzSqFXg+HXdu9yMvTXVClbXv3JPqBAAAAAAA4ior9+bQ+srKDOfqrlAJ+OywQQnndwUAAAAAAACERKNagQcAAAAAAIAQs3CukmQFHgAAAAAAAOAxVuABAAAAAAAgHDgGXmrMmvm6BvXvowF9e2v8uLGNuuXiX/TQnKeu1XtPX6vf/qLH9+773a96ast792jP3VoE3pXqcfGxxZcOWmihJVwtvnTQQgst4WrxpYMWWmgJV4svHUVFKzRi2Nkaemo/nT5kgB5/9N8pa5H8GRekH68n8MrLy3X76Ft135gHNGHiZE2dMkmLFi5slC0H799G5w7+iY779d064hd36ZTjOmv/gtaSpHZ5u6nXkQdoyYo1gfVUSvW4+NjiSwcttNASrhZfOmihhZZwtfjSQQsttISrxZcOScrMzNRlV1yj516YoocefVLPPPWYvlzUuN8fpCevJ/AWzJ+ngoL2aldQoOycHPXt118zpk9rlC0HdsjTuwsWa8vWUpWXV2jm3IU6tWdXSdJdlw/R9fdMlHPBn1o71ePiY4svHbTQQku4WnzpoIUWWsLV4ksHLbTQEq4WXzokqXXrXB10cGdJUosWLdWhw/4qLo6kpMWncQk1s+AuAUo4gWdmB5rZiWbWcrvb+yYvK6o4ElF+m/yq67l5eYpEUvODluqWjxau0LE/3l97tGquZk2z1feYg9Uub3f1P76Llq/8VvO/WB5YS3WpHhcfW3zpoIUWWsLV4ksHLbTQEq4WXzpooYWWcLX40rG95d8s06effqIuXbulZPu+jgvSQ60TeGY2UtILki6RtMDMTq129+21PG+Emc0xszn12afb6YcryixFpwNOdctniyO6++FpmnTfRZr49ws07/PlKiuv0DXDeuvWMVMC69heqselOl9afOmQaKkJLfHREp8vLb50SLTUhJb4aInPlxZfOiRaakJLfLTE50uLLx3Vbd68SVddPlJXXj1KLVu2TPyEJPBxXELJMoK7BCjRWWjPk3SYc26jme0r6Vkz29c5d4+kGj9lzrmxksZK0tayOJ/QHZSXl6+iFUVV14sjEeXm5tb15erFh5aHX3hbD7/wtiTplosHqHjNBv38lMP07hNXS5L2zt1Nbz12lY47+25FVm8IpMmHcfGtxZcOWmihJVwtvnTQQgst4WrxpYMWWmgJV4svHZVKS0t11eUjdUr/gep10skp6/BtXJBeEk0XZjrnNkqSc26xpBMknWJmf1YtE3gNpXOXrlqyZLGWLVuq0pISTZ0yWT169kr2Zr1tab179F8JCvJ316m9fqTHJr2r9r1v0IEDb9WBA2/VN8Xr9JNf/jGwyTvJj3HxrcWXDlpooSVcLb500EILLeFq8aWDFlpoCVeLLx2S5JzTbTfdoA4d9tdZZ5+bkoZKPo1LqIX0GHiJVuAVmdkhzrkPJCm2Em+ApH9J6pr0uKwsjbr+Rl04YrgqKso1eMhQFRZ2TPZmvW154o+/0R6tWqi0rFy/u+NZrduwJdDtx+PDuPjW4ksHLbTQEq4WXzpooYWWcLX40kELLbSEq8WXDkn64P25mjzpBRV27KRfnD5YknTxyMt07HE9Am/xaVyQfqy2M5eaWTtJZc65ojj3HeOcm5VoA/XZhTbMdj/y0lQnVFn7zj2pTgAAAAAAIK6ycn+mFbIy/TlmXdOs5O8ZmY6a9f1zYB+YLVMvD+w9qHUFnnNuWS33JZy8AwAAAAAAAFA/iXahBQAAAAAAANJDSM/sG+w5bwEAAAAAAADsFFbgpYhPx51re+7jqU6osvzBM1OdACCEOG4KAABA+uL3J+wUC+datXB+VwAAAAAAAEBIsAIPAAAAAAAA4cAx8AAAAAAAAAAEjRV4AAAAAAAACAeOgZcas2a+rkH9+2hA394aP24sLR60FObvotf+75Sqy9djT9cFfQ5Q5312039vPFlv3N5Pj1/eQ7s0DX5+2Jf3yJcOWmihpf6KilZoxLCzNfTUfjp9yAA9/ui/U9biy5jQQgst4WrxpYMWWmgJV4svHbQgLLyewCsvL9fto2/VfWMe0ISJkzV1yiQtWriQlhS3LCzaoB43vKQeN7yknr+fqs3byjRpzlLdM+xI3fL0Bzr2uimaPGepLul/cGBNUurHxbcOWmihpWFkZmbqsiuu0XMvTNFDjz6pZ556TF8u4s8WWmihJRwtvnTQQgst4WrxpYMWhInXE3gL5s9TQUF7tSsoUHZOjvr2668Z06fR4lFLj855Wly8UctWb1bHNrvqzU+LJUkzFhRp4OEFgbb4Mi6+dNBCCy0No3XrXB10cGdJUosWLdWhw/4qLo4E3uHTmNBCCy3hafGlgxZaaAlXiy8dtDRSlhHcJUAJt2ZmR5jZ4bGvDzazy82sX/LTpOJIRPlt8quu5+blKRIJ/i9NtNTsp0e113NvfS1J+mTZOp1y6N6SpFOP2Edt92geaIsv4+JLBy200NLwln+zTJ9++om6dO0W+LZ9GhNaaKElPC2+dNBCCy3havGlgxaESa0TeGZ2k6S/Sfqnmf1B0j8ktZR0rZldX8vzRpjZHDObU599up1cvNeu8+vVBy0/lJ2Zob6H7q0X3l0iSbpk3DsaflInvXprX7VslqXSsopAe3wZF186JFpqQkt8tNRu8+ZNuurykbry6lFq2bJl4Nv3aUxoiY+W+GiJz5cWXzokWmpCS3y0xOdLiy8dEi2NkllwlwAlOsvAaZIOkdREUpGkds659Wb2R0nvSBod70nOubGSxkrS1rI4n9AdlJeXr6IVRVXXiyMR5ebm1vXl6oWWHzqpWxvNW7xWK9dvlSR9sWK9ht41XZK0f/4u6t1t70B7fBkXXzpooYWWhlNaWqqrLh+pU/oPVK+TTk5Jg09jQgsttISnxZcOWmihJVwtvnTQgjBJtAttmXOu3Dm3WdIi59x6SXLObZGU9OVVnbt01ZIli7Vs2VKVlpRo6pTJ6tGzV7I3S8sOGvqTfat2n5WkvXZtIik6CX3FqV300KtfBNrjy7j40kELLbQ0DOecbrvpBnXosL/OOvvclDRIfo0JLbTQEp4WXzpooYWWcLX40kFLIxXSY+AlWoFXYmbNYxN4h1XeaGatFMAEXlZWlkZdf6MuHDFcFRXlGjxkqAoLOyZ7s7TsgGY5mTqhc74u+9e7VbcNPWpfDTsp2jFpzlI99vqXgTb5MC4+ddBCCy0N44P352rypBdU2LGTfnH6YEnSxSMv07HH9Qi0w6cxoYUWWsLT4ksHLbTQEq4WXzpoQZiYczXv4WpmTZxz2+LcvpekNs65+Yk2UJ9daBGMtuc+nuqEKssfPDPVCQBCqKzcn/8UZWVynBMAAADUX9Ms8YtlHM0Gjw3sl/8tz48I7D2odQVevMm72O2rJK1KShEAAAAAAACAKol2oQUAAAAAAADSQ8DHpgtKOL8rAAAAAAAAICRYgQevjjvXddTUVCdUmf+HvqlOANBAMvjnKgAAAKBxsHAeGpC/0gAAAAAAAAAeYwUeAAAAAAAAQsFYgQcAAAAAAAAgaKzAAwAAAAAAQCiwAi9FZs18XYP699GAvr01ftxYWmj5ng6tW2jiZUdXXd6/7SSdc2x7tWqWrYfO667/XX2cHjqvu3ZtFuxcNe8PLbSEp+XmG65Tr+OP1mmDB6asoZIvY0ILLbSEq8WXDlpooSVcLb500IKw8HoCr7y8XLePvlX3jXlAEyZO1tQpk7Ro4UJaaKny1cpNGvSXNzXoL29q8F/f1JbScr28IKLze3XQmwtXq/ddM/XmwtU6v+d+gTWlekxooYWWhjVw8BDdO2ZcSrZdnU9jQgsttISnxZcOWmihJVwtvnTQgjDxegJvwfx5Kihor3YFBcrOyVHffv01Y/o0WmiJ6+iOe2rJ6s1avm6rTjw4TxPmLJckTZizXCd1zgusw6cxoYUWWurvsO6Hq1WrVinZdnU+jQkttNASnhZfOmihhZZwtfjSQUsjZQFeArTTE3hm9u9khMRTHIkov01+1fXcvDxFIpGgNk9LmrX079ZGk95fIUnaa5ccrdywTZK0csM27dkyJ7AOn8aEFlpoCQ+fxoQWWmgJT4svHbTQQku4WnzpoAVhUuuBwcxs4vY3SeppZrtJknNuUA3PGyFphCT94777Ney8EXWKc3LxXrtOr1VftMTnS0t2pqlX51z96aXPA9/29nwZE4mWmtASHy1+82lMaImPlvhoic+XFl86JFpqQkt8tMTnS4svHRItjVFYxzTRkf3bSfpY0gOSnKITeN0l3V3bk5xzYyWNlaStZXE+oTsoLy9fRSuKqq4XRyLKzc2t68vVCy1+txx/YGt9/M16rd5YIklataFErXdpopUbtqn1Lk2qbg+CL2NCCy20hItPY0ILLbSEp8WXDlpooSVcLb500IIwSbQLbXdJ70m6XtK3zrkZkrY4515zzr2W7LjOXbpqyZLFWrZsqUpLSjR1ymT16Nkr2ZulJQ1bBhzy3e6zkvTqx8Ua0r2tJGlI97aa9nFwy5J9GRNaaKElXHwaE1pooSU8Lb500EILLeFq8aWDlsbJzAK7BKnWFXjOuQpJfzGzZ2L/H0n0nIaUlZWlUdffqAtHDFdFRbkGDxmqwsKOQW2eljRpaZqdoWM67qnfP/dR1W33T/9S95x1iE4/vJ2Wr9uqkY98EFiPD2NCCy20NJxrr7pc782erXXr1qrPiT10wUWXaMjQ0wLv8GlMaKGFlvC0+NJBCy20hKvFlw5aECbm3I7v4Wpm/SUd45y7bkefU59daNH4dB01NdUJVeb/oW+qEwA0kIqd+G9dsmWE9JgcAAAACFbTrKDPg5oedj3j34H98r/+ybMDew92ajWdc26ypMlJagEAAAAAAACwnUTHwAMAAAAAAADSgm/HwDOzy8zsIzNbYGZPmFlTM9vDzP5nZl/E/n/3RK/DBB4AAAAAAADQwMxsb0kjJXV3znWRlCnpDEnXSprmnOsoaVrseq0COyEFsCN8Ou7cgVdMSnWCJOnTuwekOgFIexx3DgAAAGgk/PvVP0tSMzMrldRc0nJJoySdELv/YUkzJF1T24uwAg8AAAAAAADYSWY2wszmVLuMqH6/c+4bSX+StETSCknfOudelpTnnFsRe8wKSbmJtsUKPAAAAAAAAITCjh6briE458ZKGltLy+6STpXUQdI6Sc+Y2Vl12RYr8AAAAAAAAICGd5Kkr5xzK51zpZL+I+loSREzayNJsf8vTvRCrMADAAAAAABAKAS5Am8HLJF0lJk1l7RF0omS5kjaJOnXku6I/f8LiV7I+xV4s2a+rkH9+2hA394aP67GVYm00JLSlv1yW2jKVcdVXebf2Ue/6dFBowYdpGnXnaCXrjle9w/rrl2bBT9nzvtDCy3hafGlgxZaaAlXiy8dtNBCS7hafOmgBanknHtH0rOS5kqar+g83FhFJ+56m9kXknrHrtfK6wm88vJy3T76Vt035gFNmDhZU6dM0qKFC2mhxbuWL4s3qd8fZ6rfH2dqwJ9mamtJuf47r0hvfLZSJ9/xmk6583V9VbxRF51UGEhPJd4fWmgJT4svHbTQQku4WnzpoIUWWsLV4ksHLfCBc+4m59yBzrkuzrlfOee2OedWO+dOdM51jP3/mkSv4/UE3oL581RQ0F7tCgqUnZOjvv36a8b0abTQ4nXLMZ320terNuubtVs087NVKq9wkqT3v16n/N2aBdriy5jQQgst4emghRZawtXiSwcttNASrhZfOmhpnMwssEuQdmoCz8yONbPLzezkZAVVVxyJKL9NftX13Lw8RSKRIDZNCy11NvDQtpo4d/kPbj/9yALN+CThcSkblC9jQgsttISngxZaaAlXiy8dtNBCS7hafOmgBWFS6wSemb1b7evzJP1D0i6SbjKza2t53ggzm2Nmc+qzT7eTi/fadX69+qAlPlq+LzvTdFKXfE354PsTeBf3LlR5hdPzc74JtMeHMalES3y0xEeLvx0SLTWhJT5a4vOlxZcOiZaa0BIfLfH50uJLh0RLYxTWFXiJjqifXe3rEZJ6O+dWmtmfJL2tGg6y55wbq+hB+bS1LM4ndAfl5eWraEVR1fXiSES5ubl1fbl6oYWWHXHCQblasOxbrdpQUnXb0MPb6cTOeTrz3rcCbZH8GBNaaKElXB200EJLuFp86aCFFlrC1eJLBy0Ik0S70GaY2e5mtqckc86tlCTn3CZJZcmO69ylq5YsWaxly5aqtKREU6dMVo+evZK9WVpoqbNBh7XVi3O/W2XX48DWuuCk/TV83GxtLa0ItEXyY0xooYWWcHXQQgst4WrxpYMWWmgJV4svHbQ0UhbgJUCJVuC1kvSeolnOzPKdc0Vm1lIBpGZlZWnU9TfqwhHDVVFRrsFDhqqwsGOyN0sLLXXSNDtDxx7QWtc9Nb/qtltO66KcrAw9etGRkqInsrj+6fk1vUSDS/WY0EILLeHroIUWWsLV4ksHLbTQEq4WXzpoQZiYczu/h6uZNZeU55z7KtFj67MLLZBKB14xKdUJkqRP7x6Q6gQAAAAAgGeaZgW9Biw97HXOk4HNQ6166IzA3oNEK/Dics5tlpRw8g4AAAAAAABA/dRpAg8AAAAAAADwTVjP7JvoJBYAAAAAAAAAUogVeEANfDn23K8enZvqhCqPnHVoqhMAAEAc17/0WaoTJEmjTzkg1QkAgEaOFXgAAAAAAAAAAscKPAAAAAAAAIRDOBfgsQIPAAAAAAAA8Bkr8AAAAAAAABAKHAMvRWbNfF2D+vfRgL69NX7cWFpoSYuWVHfce1pn3X3qQfrjoAN1x4DvH0x6YOdcPXPOodqlSWbgXakeF1poSfcWXzpooYWWcLSYpMuPb69hR+xdddux++6ma3p20FUn7KsBB7UOvCnVY0ILLbSEr4MWhIXXE3jl5eW6ffStum/MA5owcbKmTpmkRQsX0kKL1y2+dNw89XNdNfFTXTvpu7PS7dk8Wz9qu6tWbtwWeI8v40ILLena4ksHLbTQEp6W4/bbXZENJVXX99+zmTrnt9SfXlusP85YrBmL1gTa48OY0EILLeHqoKVxMrPALkHyegJvwfx5Kihor3YFBcrOyVHffv01Y/o0WmjxusWXjnjOOaKdHp3zjVwKtu3TuNBCSzq2+NJBCy20hKOlVdMsHZzbQu8s+bbqtqP33U2vLlyj8orobwobS8oD65FSPya00EJL+DpoQZjUOoFnZkea2a6xr5uZ2S1m9qKZ3WlmrZIdVxyJKL9NftX13Lw8RSKRZG+WFlrSv8NJN5zcUXcOOFAnddpTktS9oJXWbC7V12u3BNsS48W40EJLGrf40kELLbSEo+XUzrma9MlKuWr/rNe6RY7226OZRh67jy46ukAFrZoG1iOlfkxooYWW8HXQgjBJtALvX5I2x76+R1IrSXfGbnuwpieZ2Qgzm2Nmc+qzT7eLs04oVQcjpCU+WvzsuGHK57rmxU81+pWF6nNgax2U11I//VG+nnp/eaAd1fkwLpVoiY+W+Hxp8aVDoqUmtMRHS3ypbDkot4U2lpRp2bffP6RGhpmaZWfqb28s0Ysfr9SvurcJpKcS7098tMRHS3y+tPjSIdHSGIV1F9pEZ6HNcM6Vxb7u7pw7NPb1G2b2QU1Pcs6NlTRWkraW1X1vvby8fBWtKKq6XhyJKDc3t64vVy+00JJOHWu3lEqS1m8t07tLvtXBeS2V2zJHfzz1IEnSns1zdNfAgzRq8qdat6WstpdqMD6MCy20pHOLLx200EJL+rd02KOZOue11EG5LZWVYWqanaEzf9xG324t0/yiDZKkpeu2yjmpRU6mNgW0Ky3vDy20hKfFlw5aECaJVuAtMLNzY19/aGbdJcnMOkkqTWqZpM5dumrJksVatmypSktKNHXKZPXo2SvZm6WFlrTuaJKVoaZZGVVfd2u7ixat3qzhT83Xxc9+pIuf/UirN5fo6hc/CWzyTkr9uNBCS7q3+NJBCy20pH/LlE9X6bZXvtToaV/q0bnLtXDVZj3+/gotKNqgwr2aS5L2apGtrAwLbPJO4v2hhZYwtfjSQUvj1FhX4A2XdI+Z3SBplaS3zGyppKWx+5Ibl5WlUdffqAtHDFdFRbkGDxmqwsKOyd4sLbSkdUerplm6qtd+kqRMM73x1Vp98M36wLZfk1SPCy20pHuLLx200EJL+FoqvbvkW/38kDa6sse+KndOT7xflPhJDcinMaGFFlrC0UELwsScS7yHq5ntImk/RSf8ljnndvgoi/XZhRaA9KtH56Y6ocojZx2a+EEAACBw17/0WaoTJEmjTzkg1QkA0Gg0zRIH0Iuj7QX/CWweavmYnwb2HiRagSdJcs5tkPRhklsAAAAAAAAAbGeHJvAAAAAAAAAA34X1zL6JTmIBAAAAAAAAIIV26Bh49cEx8AAAqVaR5P/W7YyMkP6LIMKt9S8fTnVClZWP/TrVCQAAeIFj4MXX7qLnA/vlf9l9gwN7D1iBBwAAAAAAAHiMY+ABAAAAAAAgFDgGHgAAAAAAAIDAsQIPAAAAAAAA4RDOBXj+r8CbNfN1DerfRwP69tb4cWNpoSUtWnzpoIUWWurv5huuU6/jj9ZpgwemrKGSL2NCCy074uJ+B+vdP52qd/40SP8aebyaZGdo8FHt9e6fTtW3T5ytH++3Z+BNUurHxccWXzpooYWWcLX40kELwsLrCbzy8nLdPvpW3TfmAU2YOFlTp0zSooULaaHF6xZfOmihhZaGMXDwEN07ZlxKtl2dT2NCCy2JtNm9uS445UAdP2qSjrxyojIzTKcd3UGfLF2nX949XbM+iQTWUl2qx8XHFl86aKGFlnC1+NJBS+NkZoFdguT1BN6C+fNUUNBe7QoKlJ2To779+mvG9Gm00OJ1iy8dtNBCS8M4rPvhatWqVUq2XZ1PY0ILLTsiKyNDzXIylZlhap6TqRVrt+izb77VFyvWB9pRnQ/j4luLLx200EJLuFp86aAFYVLrBJ6ZjTSzgqBitlcciSi/TX7V9dy8PEUiqfkXW1poSbcOWmihJVx8GhNaaElkxdrN+tukj/Txfadp4f0/07dbSvXqvOWBbb8mqR4XH1t86aCFFlrC1eJLBy0Ik0Qr8G6T9I6ZzTSzi8ys9Y68qJmNMLM5ZjanPvt0O7l4r13n16sPWuKjxd8OiZaa0BIfLX7zaUxoiY+W7+zWIkf9uxeo62+fU8cLnlaLJln6+bH7Bbb9mqR6XKrzpcWXDomWmtASHy3x+dLiS4dES2PUWHeh/VJSO0Un8g6T9LGZTTWzX5vZLjU9yTk31jnX3TnXfdh5I+ocl5eXr6IVRVXXiyMR5ebm1vn16oMWWtKtgxZaaAkXn8aEFloSOaFrG31dvFGrNmxTWbnTxHe/1pEH7NC/AydVqsfFxxZfOmihhZZwtfjSQQvCJNEEnnPOVTjnXnbODZPUVtJ9kvoqOrmXVJ27dNWSJYu1bNlSlZaUaOqUyerRs1eyN0sLLaHooIUWWsLFpzGhhZZElq3apMM7tlaznExJ0gld2uizb74NbPs1SfW4+NjiSwcttNASrhZfOmhpnMK6Ai8rwf3fq3HOlUqaKGmimTVLWlVMVlaWRl1/oy4cMVwVFeUaPGSoCgs7JnuztNASig5aaKGlYVx71eV6b/ZsrVu3Vn1O7KELLrpEQ4aeFniHT2NCCy2JzFm4Ss+/s1hv3DFQZRUV+vCrNXrwlc818PB99Mdzj9BeuzbVs9ecqHlfr9GQ218JrCvV4+Jjiy8dtNBCS7hafOmgBWFizv1wH+yqO806Oec+r88GtpbF2ckbAIAAVdTy37qgZXCcE6Sh1r98ONUJVVY+9utUJwAA4IWmWeIXyzg6/G5yYL/8f/XX/oG9B7XuQlvfyTsAAAAAAAAA9ZNoF1oAAAAAAAAgPYR0XWKik1gAAAAAAAAASCFW4AFIS/te+GyqE6os/mfwJzTAzqmoSHXBdzIyU10A7DyOOwcAANJF0GeHDQor8AAAAAAAAACPsQIPAAAAAAAAocAKPAAAAAAAAACBYwUeAAAAAAAAQiGkC/D8X4E3a+brGtS/jwb07a3x48bSQktatPjSQct39s9rqVduPKnq8sXfTtV5JxZKkob12l9v3NZHr93SW78f2jXQLon3yPeWoqIVGjHsbA09tZ9OHzJAjz/675S1+DImtNBCS7hafOmghRZawtXiSwctCAuvJ/DKy8t1++hbdd+YBzRh4mRNnTJJixYupIUWr1t86aDl+xZFNuqkW1/RSbe+opNve0VbSsr10vvLdcwBrdWnW1v1uuV/6nHT//TPlz8PrElK/bjQklhmZqYuu+IaPffCFD306JN65qnH9OUi/myhhRZawtHiSwcttNASrhZfOmhpnMwssEuQvJ7AWzB/ngoK2qtdQYGyc3LUt19/zZg+jRZavG7xpYOWmh13UJ4Wr9yoZWs269cn7Ke/T/1MJWUVkqRVG7YF2uLTuNASX+vWuTro4M6SpBYtWqpDh/1VXBwJvMOnMaGFFlrC0+JLBy200BKuFl86aEGY1DqBZ2Y5Zna2mZ0Uu36mmf3DzC42s+xkxxVHIspvk191PTcvT5FI8H9pooWWdOygpWaDD2+n599dKknaL28XHdVxL00Z1UsTruyhQ/bdPdAWn8aFlsSWf7NMn376ibp07Rb4tn0aE1pooSU8Lb500EILLeFq8aWDFoRJohV4D0rqL+lSM3tE0umS3pF0uKQHanqSmY0wszlmNqc++3Q7uXivXefXqw9a4qPF3w6JlniyM00nd2uriXOWSZKyMkytmmer3x9e1a3PztPY848KtMeXcZFoSWTz5k266vKRuvLqUWrZsmXg2/dpTGiJj5b4aInPlxZfOiRaakJLfLTE50uLLx0SLY2RWXCXICU6C21X59yPzCxL0jeS2jrnys3sUUkf1vQk59xYSWMlaWtZnE/oDsrLy1fRiqKq68WRiHJzc+v6cvVCCy3p1kFLfL265Gv+knVVu8ouX7tFU+YulyS9v3itKiqc9myZo9UbSwLp8WVcaKldaWmprrp8pE7pP1C9Tjo5JQ0+jQkttNASnhZfOmihhZZwtfjSQQvCJNEKvAwzy5G0i6TmklrFbm8iKem70Hbu0lVLlizWsmVLVVpSoqlTJqtHz17J3iwttISig5b4hhyxj55/d0nV9akfLNexB7aWJO2X11LZWRmBTd5J/owLLTVzzum2m25Qhw7766yzz01Jg+TXmNBCCy3hafGlgxZaaAlXiy8dtDROYT2JRaIVeOMlfSopU9L1kp4xsy8lHSXpySS3KSsrS6Ouv1EXjhiuiopyDR4yVIWFHZO9WVpoCUUHLT/ULCdTxx+cq6sefa/qtife+Ep/Oae7ZtzcWyVlFRr54OxAm3wYF1pq98H7czV50gsq7NhJvzh9sCTp4pGX6djjegTa4dOY0EILLeFp8aWDFlpoCVeLLx20IEzMudr3cDWztpLknFtuZrtJOknSEufcuzuygfrsQgsANdn3wmdTnVBl8T9PS3UCEigr9+c/RVmZHOcEAAAA9dc0S/xiGceB1/43sF/+P72jT2DvQaIVeHLOLa/29TpJ/vytGQAAAAAAAAi5hBN4AAAAAAAAQDrIyAjnwsREJ7EAAAAAAAAAkEKswAOQlnw67hzH4/NfRYLjvQYrnP8iCAAAAPgg4JPDBoYVeAAAAAAAAIDHWIEHAAAAAACAULCQLsFjBR4AAAAAAADgMVbgAQAAAAAAIBRCugDP/xV4s2a+rkH9+2hA394aP24sLbSkRYsvHbT42bJ/Xku9cuNJVZcv/naqzjuxUJI0rNf+euO2Pnrtlt76/dCugXZJvEfxbNu2Tb8+82c68/TB+tmQAbr/vr+nrMWXMaGFFlrC1eJLBy200BKuFl86aEFYeD2BV15erttH36r7xjygCRMna+qUSVq0cCEttHjd4ksHLf62LIps1Em3vqKTbn1FJ9/2iraUlOul95frmANaq0+3tup1y//U46b/6Z8vfx5Yk5T6cfG1JScnR/984EE9/szzevzpCXpr1huaP++DwDt8GhNaaKElPC2+dNBCCy3havGlg5bGycwCuwTJ6wm8BfPnqaCgvdoVFCg7J0d9+/XXjOnTaKHF6xZfOmhJj5bjDsrT4pUbtWzNZv36hP3096mfqaSsQpK0asO2QFt8GhefWsxMzZu3kCSVlZWprKxUpuDX5fs0JrTQQkt4WnzpoIUWWsLV4ksHLQiThBN4Zra/mV1pZveY2d1mdoGZtQoirjgSUX6b/KrruXl5ikQiQWyaFlrSvoOW9GgZfHg7Pf/uUknSfnm76KiOe2nKqF6acGUPHbLv7oG2+DQuPrVI0X8tPfNnQ3Ryz2N15FFHq8uPugXe4NOY0EILLeFp8aWDFlpoCVeLLx20IExqncAzs5GSxkhqKulwSc0kFUh6y8xOqOV5I8xsjpnNqc8+3U4u3mvX+fXqg5b4aPG3Q6KlJr60ZGeaTu7WVhPnLJMkZWWYWjXPVr8/vKpbn52nsecfFWiPL+Mi+dUiSZmZmXr86Qma/PJ0fbRgvhZ+EezuzZJfY0JLfLTER0t8vrT40iHRUhNa4qMlPl9afOmQaGmMwroLbaKz0J4n6RDnXLmZ/VnSFOfcCWZ2v6QXJP043pOcc2MljZWkrWVxPqE7KC8vX0UriqquF0ciys3NrevL1QsttKRbBy3+t/Tqkq/5S9ZV7Sq7fO0WTZm7XJL0/uK1qqhw2rNljlZvLAmkx5dx8a2lul123VWHHX6E3nrzDRV27BTotn0aE1pooSU8Lb500EILLeFq8aWDFoTJjhwDr3KSr4mkXSTJObdEUnayoip17tJVS5Ys1rJlS1VaUqKpUyarR89eyd4sLbSEooMW/1uGHLGPnn93SdX1qR8s17EHtpYk7ZfXUtlZGYFN3kn+jItvLWvXrNGG9eslSVu3btW7b7+lffftEHiHT2NCCy20hKfFlw5aaKElXC2+dNDSOJkFdwlSohV4D0iabWZvSzpe0p2SZGatJa1JcpuysrI06vobdeGI4aqoKNfgIUNVWNgx2ZulhZZQdNDid0uznEwdf3Curnr0varbnnjjK/3lnO6acXNvlZRVaOSDswNt8mFcfGxZtWqlbr5hlCoqylVRUaGTTu6r43r0DLzDpzGhhRZawtPiSwcttNASrhZfOmhBmJhzte/hamadJR0kaYFz7tOd3UB9dqEFgHSw74XPpjqhyuJ/npbqBC9VntnXBzlZXp8AHgAAAGmiaZY4gF4cP77l1cDmod6/qVdg70GiFXhyzn0k6aMAWgAAAAAAAABsJ+EEHgAAAAAAAJAOwnpiX/bjAQAAAAAAADzGCjwAqCefjjvXddTUVCdUmf+HvqlOqMJx5wAAAIDGwUK6BI+/0QAAAAAAAAAeYwUeAAAAAAAAQiGkC/BYgQcAAAAAAAD4jBV4AAAAAAAACAWOgZcis2a+rkH9+2hA394aP24sLbSkRYsvHbTQkkiH1i008bKjqy7v33aSzjm2vVo1y9ZD53XX/64+Tg+d1127Ngv+33t4j/ztoIUWWsLV4ksHLbTQEq4WXzpoQVh4PYFXXl6u20ffqvvGPKAJEydr6pRJWrRwIS20eN3iSwcttOyIr1Zu0qC/vKlBf3lTg//6praUluvlBRGd36uD3ly4Wr3vmqk3F67W+T33C6xJSv24+NjiSwcttNASrhZfOmihhZZwtfjSQUvjZBbcJUi1TuCZWSszu8PMPjWz1bHLJ7Hbdkt23IL581RQ0F7tCgqUnZOjvv36a8b0acneLC20hKKDFlp21tEd99SS1Zu1fN1WnXhwnibMWS5JmjBnuU7qnBdoi0/j4kuLLx200EJLuFp86aCFFlrC1eJLBy0Ik0Qr8J6WtFbSCc65PZ1ze0rqGbvtmWTHFUciym+TX3U9Ny9PkUgk2ZulhZZQdNBCy87q362NJr2/QpK01y45WrlhmyRp5YZt2rNlTqAtPo2LLy2+dNBCCy3havGlgxZaaAlXiy8dtCBMEk3g7eucu9M5V1R5g3OuyDl3p6R9anqSmY0wszlmNqc++3Q7uXivXefXqw9a4qPF3w6JlprQ8kPZmaZenXP10ryixA8OgC/jIvnT4kuHREtNaImPlvh8afGlQ6KlJrTER0t8vrT40iHR0hiZWWCXICU6KvnXZna1pIedcxFJMrM8SedIWlrTk5xzYyWNlaStZXE+oTsoLy9fRSu++8tkcSSi3Nzcur5cvdBCS7p10ELLzjj+wNb6+Jv1Wr2xRJK0akOJWu/SRCs3bFPrXZpU3R4UX8bFpxZfOmihhZZwtfjSQQsttISrxZcOWhAmiVbg/VzSnpJeM7M1ZrZG0gxJe0g6Pclt6tylq5YsWaxly5aqtKREU6dMVo+evZK9WVpoCUUHLbTsjAGHfLf7rCS9+nGxhnRvK0ka0r2tpn0c7NJ+X8bFpxZfOmihhZZwtfjSQQsttISrxZcOWhqnsJ7EotYVeM65tZKuiV2+x8zOlfRgkrokSVlZWRp1/Y26cMRwVVSUa/CQoSos7JjMTdJCS2g6aKFlRzXNztAxHffU75/7qOq2+6d/qXvOOkSnH95Oy9dt1chHPgi0yYdx8a3Flw5aaKElXC2+dNBCCy3havGlgxaEiTlXtz1czWyJc67G4+BVqs8utACAndN11NRUJ1SZ/4e+qU4AAAAAQqtpljiAXhw/ufP1wOah3rrm+MDeg1pX4JnZvJrukpTX8DkAAAAAAAAAqkt0Eos8SX0krd3udpP0ZlKKAAAAAAAAgDoI64l9E03gTZLU0jn3wfZ3mNmMZAQBAAAAAAAA+E6ik1gMq+W+Mxs+BwBQHz4dd26/i/+T6oQqC/8xJNUJVTLC+k+CAAAAgAcspL9vZ6Q6AAAAAAAAAEDNEu1CCwAAAAAAAKSFkC7AYwUeAAAAAAAA4DNW4AEAAAAAACAUOAZeisya+boG9e+jAX17a/y4sbTQkhYtvnTQQks6teyf11L/u6FX1eWzvw7U8BP31xUDDtJ7d5xSdXuvLnmBdt18w3XqdfzROm3wwEC3Gw+fFVpooSXMHbTQQku4WnzpoAVh4fUEXnl5uW4ffavuG/OAJkycrKlTJmnRwoW00OJ1iy8dtNCSbi2LIhvV+/9eVe//e1V9Rr+qLSXleun95ZKkcdMWVt336oJIYE2SNHDwEN07Zlyg24wn1e8PLbTQEs4WXzpooYWWcLX40kFL42RmgV2CVOcJPDN7qSFD4lkwf54KCtqrXUGBsnNy1Ldff82YPi3Zm6WFllB00EJLOrccd2Cuvl65Sd+s2ZKS7Vd3WPfD1apVq1RnePX+0EILLeFp8aWDFlpoCVeLLx20IExqncAzs0NruBwm6ZBkxxVHIspvk191PTcvT5FIsCsvaKElXTtooSWdW049vJ2en7206vq5J+ynV35/ov589qFq1Tw7JU2p5tP7QwsttISnxZcOWmihJVwtvnTQgjBJdBKL2ZJekxRvXeBuNT3JzEZIGiFJ/7jvfg07b0Sd4pxcvNeu02vVFy3x0eJvh0RLTWiJz5eW7EzTyd3a6PYJH0mSHn7tS/1l8idykq4edLBuOq2rLv/33MC7Us2X90eipSa0xEdLfL60+NIh0VITWuKjJT5fWnzpkGhpjMI6pIkm8D6RdL5z7ovt7zCzpXEeL0lyzo2VNFaStpbF+YTuoLy8fBWtKKq6XhyJKDc3t64vVy+00JJuHbTQkq4tvbrka/6SdVq1YZskVf2/JD32xmL9++KfBN7kA1/eH1pooSVcLb500EILLeFq8aWDFvjAzHaT9ICkLpKcpN9I+kzSU5L2lbRY0s+cc2tre51Ex8C7uZbHXLKjsXXVuUtXLVmyWMuWLVVpSYmmTpmsHj17JXuztNASig5aaEnXlsGHt9Pzs5dVXc/dtWnV16cc0lafLV8feJMPfHl/aKGFlnC1+NJBCy20hKvFlw5aGicPT2Jxj6SpzrkDJXVTdLHctZKmOec6SpoWu16rWlfgOeeereXu3Xe0tK6ysrI06vobdeGI4aqoKNfgIUNVWNgx2ZulhZZQdNBCSzq2NMvO1HEH5erqR9+vuu2GoV3UuaCVnJOWrd78vfuCcO1Vl+u92bO1bt1a9Tmxhy646BINGXpaoA2SH+8PLbTQEr4WXzpooYWWcLX40kELUs3MdpV0vKRzJMk5VyKpxMxOlXRC7GEPS5oh6ZpaX8u5uu3hamZLnHP7JHpcfXahBQCkr/0u/k+qE6os/MeQVCdUyQjrQTkAAAAQqKZZcc9X0Oj1vOfNwOahZvzumPMVOwdEzNjYYeUkSWZ2iKKHmPtY0dV370m6VNI3zrndqj1urXOu1oVyta7AM7N5Nd0lKa+25wIAAAAAAABhVf0cEDXIknSopEucc++Y2T3agd1la3qh2uRJ6iNp+wPpmaQ367JBAAAAAAAAIBk8O7PvMknLnHPvxK4/q+gEXsTM2jjnVphZG0nFiV4o0UksJklq6Zz7ervLYkX3zwUAAAAAAACwHedckaSlZnZA7KYTFd2ddqKkX8du+7WkFxK9VqKTWAyr5b4zdyR2a2n5jjwsEE2zM1OdgDRSUcfjQ4YZx+7y3/otpalOqPLlvT9NdUKVk/82K9UJVV4eeUyqE7xTUlaR6oQqOVmJ/m2zcSor9+e/iT59Xpo34XdL7Biffq+s8OdHSBke/ZHL77nx+fLZ5f3BzvDw43KJpMfMLEfSl5LOVXRB3dNmNkzSEkmnJ3qRRLvQAgAAAAAAAKgD59wHkrrHuevEnXkdJvAAAAAAAAAQCmFdsenRomUAAAAAAAAA22MFHgAAAAAAAEIhpAvw0mMFXnl5uX7185/q8ksuTGnHrJmva1D/PhrQt7fGjxtLCy01uvmG69Tr+KN12uCBKWvwscWX94eW+JYs/krnnjm06tKnx5F6+vFHUtaT6nFp2SRTtw44QI+c82M98usfq3ObXXRCxz318Nk/1ozLjtYBeS0Db0r1mPjYsm3bNv36zJ/pzNMH62dDBuj++/6eshbJn3HxqaWoaIVGDDtbQ0/tp9OHDNDjj/47ZS2SNKT/Sfrlz07V2WcM0bm/THi86KTy5T3ypYOWmvny+5xPP8++jEklnz4vvrT49B75Mia+tSC9pMUE3lOPP6J9O+yf0oby8nLdPvpW3TfmAU2YOFlTp0zSooULaaElroGDh+jeMeNSsu3t+dLi0/tDS3z77NtBDz7+nB58/Dk98MjTatq0qY7vuVPHVW0wPozLyBP20zuL1+lXD72vcx/5QF+v2ayvVm/WDS9+qg+XrQ+0RfJjTHxsycnJ0T8feFCPP/O8Hn96gt6a9Ybmz/sgJS0+jYtPLZmZmbrsimv03AtT9NCjT+qZpx7Tl4tS01Lp3vsf0r+fnKAHH3smZQ2+vEe+dNBSO19+n/Pp59mXMZH8+rz41OLLe+TTmPjUEmZmFtglSLVO4JnZrmb2BzN7xMzO3O6++5KbFhWJFGnWzNd06k+HBrG5Gi2YP08FBe3VrqBA2Tk56tuvv2ZMn0YLLXEd1v1wtWrVKiXb3p4vLT69P7Qk9t7st9V27wLlt2mbku2nelya52SqW7tdNXlBRJJUVuG0cVu5vl6zRUvXbgmso7pUj4mvLWam5s1bSJLKyspUVlYqU2r2m/BpXHxqad06Vwcd3FmS1KJFS3XosL+KiyMpafGJL++RLx201M6X3+d8+nn2ZUwkvz4vPrX48h75NCY+tSD9JFqB96Akk/ScpDPM7DkzaxK776iklsX85Y936Le/u1JmqV0sWByJKL9NftX13Lw8RSKp+Y8VLf634Id8en9oSWzaf1/SSX36pWz7qR6Xtq2aat2WUo3qU6gHzuqmq3sXqmkW/x3ysUWK/mv2mT8bopN7HqsjjzpaXX7ULSUdPo2LTy3VLf9mmT799BN16Zqa90iKTvpeevFwnXPmaXr+uadT1uHLe+RLBy3px4efZ1/49HnxqcUXPo2JTy1IP4n+NrK/c+5a59zzzrlBkuZKetXM9qztSWY2wszmmNmch8bXfcnsG6/P0B6771H1rzyp5OR+cFvQyyUr0RKfTy34IZ/eH1pqV1paqlmvz1DPk05OWUOqxyUzw9Qxt6We/7BIwx/9UFtLy/XLI9oFtv14Uj0m1fnUIkV36Xr86Qma/PJ0fbRgvhZ+8XlKOnwaF59aKm3evElXXT5SV149Si1bBn8MyUr3P/iYHn78Of35H/fruaef0PvvzUlJhy/vkS8dEi3pxJefZ1/49HnxqcUXPo2JTy1hlmHBXYKU6Cy0TcwswzlXIUnOudFmtkzS65Jq/JPaOTdW0lhJWrel/Ief0B304Qdz9fpr0/XmG69rW8k2bdq0STddd7Vuuf2uur5kneXl5atoRVHV9eJIRLm5uYF30JIeLfghn94fWmr39qyZ6nTgQdpjz71S1pDqcVm5YZtWbtimT4o2SpJmfLFavzx878C2H0+qx8TXlup22XVXHXb4EXrrzTdU2LFT4Nv3aVx8apGi/zBw1eUjdUr/geqVwn8ckKK7AErSHnvsqR49T9THH83Tjw/rHniHL++RLx20pA+ffp594dPnxacWX/g0Jj61IP0kWoH3oqRe1W9wzj0s6QpJJcmKqnTxyMs16eXpev6lV/R/d9yt7ocfmZLJO0nq3KWrlixZrGXLlqq0pERTp0xWj569Ej+RlkbZgh/y6f2hpXav/HeKTkzh7rNS6sdlzeZSFW/YpoLdm0mSDtunlRavSc2x7yqlekx8bVm7Zo02rI+eVGTr1q169+23tO++HVLS4tO4+NTinNNtN92gDh3211lnn5uShkpbtmzWpk2bqr5+5+03td/+HVPS4st75EsHLenBp59nn/j0efGpxRc+jYlPLWEW1pNY1LoCzzl3dQ23TzWz25OT5KesrCyNuv5GXThiuCoqyjV4yFAVFqbmFz5a/G+59qrL9d7s2Vq3bq36nNhDF1x0iYYMPa1Rt/j0/tBSs61bt2jOu2/pqutvSlmD5Me43DP9K/3+lE7KzjQt/3ar/vDfL3Rc4R66tOd+2q1Ztu4cfJAWrtykK//zcSA9PoyJjy2rVq3UzTeMUkVFuSoqKnTSyX11XI+eKWnxaVx8avng/bmaPOkFFXbspF+cPliSdPHIy3TscT0Cb1mzerWuvWKkJKm8vEwn9+2vnxxzXOAdkj/vkS8dtNTOl9/nfPp59mVMJL8+Lz61+PIe+TQmPrUg/ZhzddvD1cyWOOf2SfS4+uxC29CaZmemOgFppKKOPxthlsHxGby3fktpqhOq7NosO9UJVU7+26xUJ1R5eeQxqU7wTklZRaoTquSk+GQlvirz59c5rz4vzZvwuyV2jE+/V1b48yOkDI/+yOX33Ph8+ezy/sTXNEsMTBz97383sA/u5POPCOw9qHUFnpnNq+kuSXkNnwMAAAAAAACgukQnsciT1EfS2u1uN0lvJqUIAAAAAAAAqAML6cLERBN4kyS1dM59sP0dZjYjGUEAAAAAAAAAvlPnY+DtqK1l8mOneQAAPLD7yaNTnSBJWvvy9alOAAAAQD1wDLz4Bo2dHdg81MQRhwf2Hnh02FAAAAAAAAAA20u0Cy0AAAAAAACQFiykZy1mBR4AAAAAAADgMVbgAQAAAAAAIBRCugDP/xV4s2a+rkH9+2hA394aP24sLbSkRYsvHbTQQkv6t1xy2hF6718jNGf8eXr4hsFqkp2prvvlasbff63ZD5ynZ0f/TLs0zwm0SeL9oYWWMLX40kELLbSEq8WXDloQFl5P4JWXl+v20bfqvjEPaMLEyZo6ZZIWLVxICy1et/jSQQsttKR/S9u9dtFFQw7XMRf8S92HjVNmhun0Xp31zyv764Zx03X48HGaOPMzXfbznwTSU4n3hxZawtPiSwcttNASrhZfOmhpnDLMArsE+n3VdqeZ5ZvZP83sXjPb08xuNrP5Zva0mbVJdtyC+fNUUNBe7QoKlJ2To779+mvG9GnJ3iwttISigxZaaAlHS1Zmhpo1yVJmhqlZk2ytWL1BHQv21BvzlkiSXn3vSw0+7oDAeqTUjwkttNASvg5aaKElXC2+dNCCMEm0Au8hSR9LWippuqQtkvpLmilpTFLLJBVHIspvk191PTcvT5FIJNmbpYWWUHTQQgst6d+yfNUG/fXpt/X5k5foq2cv1fpN2zRtzlf6ePFKDTi6kyTppz0OUrvcXQPpqcT7Qwst4WnxpYMWWmgJV4svHbQgTBJN4OU55/7unLtD0m7OuTudc0ucc3+X1L6mJ5nZCDObY2Zz6rNPt5OL99p1fr36oCU+WvztkGipCS3x0RJfKlt2a9lUA47ppIPOvFf7nf43tWiarTNO6qLz75qk8wcfplljfqOWzZuopLQ8kJ5KvD/x0RIfLfH50uJLh0RLTWiJj5b4fGnxpUOipTEyC+4SpERnoa0+wffv7e7LrOlJzrmxksZK0tayOJ/QHZSXl6+iFUVV14sjEeXm5tb15eqFFlrSrYMWWmhJ/5Zeh+2rxSvWadW3myVJz8/8TEd1bqcnX1mggVc/IUkqbLeHTjmqMJCeSrw/tNASnhZfOmihhZZwtfjSQQvCJNEKvBfMrKUkOeduqLzRzAolfZbMMEnq3KWrlixZrGXLlqq0pERTp0xWj569kr1ZWmgJRQcttNCS/i1LI+t1xMF7q1mT6L+39Tx0X322ZJVa79ZcUvRf/a496xiNmzg3kJ5KvD+00BKeFl86aKGFlnC1+NJBS+NkZoFdglTrCjzn3I013L7QzCYnJ+k7WVlZGnX9jbpwxHBVVJRr8JChKizsmOzN0kJLKDpooYWW9G+Z/elyTXjtU711/zCVlVfow4URjZ/0vs4beKjOP/UwSdILb3ymf0/9MJCeSrw/tNASnhZfOmihhZZwtfjSQQvCxJyr2x6uZrbEObdPosfVZxdaAADCZveTR6c6QZK09uXrU50AAACAemiaJQ6gF8fpD80NbB7qmXMODew9qHUFnpnNq+kuSXkNnwMAAAAAAACgukQnsciT1EfS2u1uN0lvJqUIAAAAAAAAqIOMkJ7ZN9EE3iRJLZ1zH2x/h5nNSEYQAAAAAAAAgO8kOonFsFruO7PhcwAAaHgVdTzeazL4cuy5TpdNTHVClc//MijVCQAAAAiJcK6/kzJSHQAAAAAAAACgZol2oQUAAAAAAADSgoX0GHiswAMAAAAAAAA8xgo8AAAAAAAAhEJGOBfg+b8Cb9bM1zWofx8N6Ntb48eNpYWWtGjxpYMWWmipv5tvuE69jj9apw0emLKGSqkck/1yW+ila3pUXT666xQNO2E/XdH/AP332hP00jU99OhFRylv1yaBdkn+fFZooSVdW3zpoIUWWsLV4ksHLQiLnZ7AM7PcZITEU15erttH36r7xjygCRMna+qUSVq0cGFQm6eFlrTuoIUWWhrGwMFDdO+YcSnZdnWpHpMvizfplDtf0yl3vqb+d72mLaXlmvrhCt0/bZH63DFDp9z5mqZ9FNGlpxwQWJOU+nGhhZZ0b/GlgxZaaAlXiy8dtDROZhbYJUi1TuCZ2R7bXfaU9K6Z7W5meyQ7bsH8eSooaK92BQXKzslR3379NWP6tGRvlhZaQtFBCy20NIzDuh+uVq1apWTb1fk0Jscc0FpLVm3WN2u3aOPWsqrbm+dkyrlgW3waF1poSccWXzpooYWWcLX40kELwiTRCrxVkt6rdpkjaW9Jc2NfJ1VxJKL8NvlV13Pz8hSJRJK9WVpoCUUHLbTQEi4+jcmgQ/fWC+8tq7p+1YAD9fatvTW4ezvdPeXTQFt8GhdaaEnHFl86aKGFlnC1+NJBC8Ik0QTe1ZI+kzTIOdfBOddB0rLY1/vV9CQzG2Fmc8xsTn326Xb64T/jp+p0wLTER4u/HRItNaElPlr85suYZGeaenfN0+T3V1Td9sdJn+qoG/+n5+cs0znHdwi0x5dxkWipCS3x+dLiS4dES01oiY+W+Hxp8aVDoqUxMgvuEqRaJ/Ccc3+SNFzSjWb2ZzPbRYrzifvh88Y657o757oPO29EnePy8vJVtKKo6npxJKLc3MAOwUcLLWndQQsttISLL2NywsF5WrD0W63asO0H9z0/5xud0q1NoD2+jAsttKRriy8dtNBCS7hafOmgBWGS8CQWzrllzrnTJU2X9D9JzZNeFdO5S1ctWbJYy5YtVWlJiaZOmawePXsFtXlaaEnrDlpooSVcfBmTUw/bWy+8903V9X1bt6j6unfXfC2KbAy0x5dxoYWWdG3xpYMWWmgJV4svHbQ0TmE9iUXWjj7QOfeimb0iaX9JMrNznXMPJq1MUlZWlkZdf6MuHDFcFRXlGjxkqAoLOyZzk7TQEpoOWmihpWFce9Xlem/2bK1bt1Z9TuyhCy66REOGnhZ4hw9j0jQ7U8cd2Fqjnvyw6rZrBx2k/XNbqsJJ36zZrFFPzQu0yYdxoYWWdG7xpYMWWmgJV4svHbQgTMzV8XRxZrbEObdPosdtLUu8yy0AAMlUEfSpUWuR4clxTjpdNjHVCVU+/8ugVCcAAACknaZZ8uMXS8+c88S8wH75f+gXPwrsPah1BZ6Z1fTP6CYpr+FzAAAAAAAAAFSXaBfaPEl9JK3d7naT9GZSigAAAAAAAIA6COuZfRNN4E2S1NI598H2d5jZjGQEAQAAAAAAAPhOrRN4zrlhtdx3ZsPnAADQ8Hw57pxPfDru3O6D/5HqhCprn/9tqhMAAABQD2H9zT8j1QEAAAAAAAAAapZoF1oAAAAAAAAgLYR17xtW4AEAAAAAAAAeYwUeAAAAAAAAQiGkC/D8X4E3a+brGtS/jwb07a3x48bSQktatPjSQQsttISrxZcOH1ouObWb3rv3F5pz7y/08FUnq0l2pq4/8wgtevgcvf23n+vtv/1cfbq3D7wr1eNCCy3p3EELLbSEq8WXDloQFl5P4JWXl+v20bfqvjEPaMLEyZo6ZZIWLVxICy1et/jSQQsttISrxZcOH1ra7tlCFw3spmMue1rdL35CmRmm04/vKEn6+/Mf6qiRT+mokU/pv3O+DqxJSv240EJLOnfQQgst4WrxpYOWxsnMArsEqdYJPDPrW+3rVmY23szmmdnjZpaX7LgF8+epoKC92hUUKDsnR3379deM6dOSvVlaaAlFBy200BKuFl86fGnJyjQ1y8lSZoapWZNsrVizKdDtx+PDuNBCS7p20EILLeFq8aWDFoRJohV4t1f7+m5JKyQNlDRb0v3JiqpUHIkov01+1fXcvDxFIpFkb5YWWkLRQQsttISrxZcOH1qWr96kv054X58/+Gt99chvtH7zNk17f6kk6YIBXfXu38/QmEt7abcWTQJrklI/LrTQks4dtNBCS7hafOmgBWGyM7vQdnfO3eCc+9o59xdJ+9b0QDMbYWZzzGxOffbpdnLxXrvOr1cftMRHi78dEi01oSU+WuLzpcWXDin1Lbu1aKIBR+6ng4b9W/ud/aBaNMnWGSd00rgp83XweY/oyJFPqmjNZt0x/JjAmqTUj0t1tMRHi78dEi01oSU+WuLzpcWXDomWxsgsuEuQEp2FNtfMLpdkknY1M3POVX7iapz8c86NlTRWkraWxfmE7qC8vHwVrSiqul4ciSg3N7euL1cvtNCSbh200EJLuFp86fChpdch7bQ4sl6r1m+VJD3/1iIddVAbPTnj86rH/Ou/H+k/Nw0IrElK/bjQQks6d9BCCy3havGlgxaESaIVeOMk7SKppaSHJe0lSWaWL+mDpJZJ6tylq5YsWaxly5aqtKREU6dMVo+evZK9WVpoCUUHLbTQEq4WXzp8aFm6cqOOOCBPzZpE/x2yZ7cCfbZ0rfJ3b171mFN/sp8+/np1YE1S6seFFlrSuYMWWmgJV4svHbQ0ThlmgV2CVOsKPOfcLTXcXmRm05OT9J2srCyNuv5GXThiuCoqyjV4yFAVFnZM9mZpoSUUHbTQQku4Wnzp8KFl9ucRTZi1SG/99ecqq6jQh4tWavzUBfrnyF760X6t5ZzT18UbdMk/kv6ryvekelxooSWdO2ihhZZwtfjSQQvCxL7bI3Ynn2i2xDm3T6LH1WcXWgAAEH67D/5HqhOqrH3+t6lOAAAA2CFNs8QB9OK46D8fBzYPdd9PDw7sPah1BZ6ZzavpLkl5DZ8DAAAAAAAAoLpEJ7HIk9RH0trtbjdJbyalCAAAAAAAAKiDsJ7ZN9EE3iRJLZ1zH2x/h5nNSEYQAAAAAAAAgO8kOonFsFruO7PhcwAAaHhl5f4cjjUrM5z/IlgfPh137uCrp6Q6ocrHd/VLdQIAAEDayUh1QJKE9fsCAAAAAAAAQiHRLrQAAAAAAABAWgjrMfBYgQcAAAAAAAB4zPsJvFkzX9eg/n00oG9vjR83lhZa0qLFlw5aaKGl/oqKVmjEsLM19NR+On3IAD3+6L9T1uLLmNDynQ6tW2jSFcdWXT68vbfOPX5fndItX1OvPk4L/3SKurZrFWhTJd4jWtKtgxZaaAlXiy8dtDQ+GRbcJdDvK9jN7Zzy8nLdPvpW3TfmAU2YOFlTp0zSooULaaHF6xZfOmihhZaGkZmZqcuuuEbPvTBFDz36pJ556jF9uYg/W2iJ+mrlJg24+w0NuPsNDfrzG9paUqH/zi/S5ys26MIH5+rdL9cE1lJdqseFlvRp8aWDFlpoCVeLLx20IEx2egLPzPZMRkg8C+bPU0FBe7UrKFB2To769uuvGdOnBbV5WmhJ6w5aaKGlYbRunauDDu4sSWrRoqU6dNhfxcWRwDt8GhNa4ju64176evUmLV+7VYuKN+mrlZtS0iH5NS60+N3iSwcttNASrhZfOmhpnBrlCjwzu8PM9op93d3MvpT0jpl9bWY9kh1XHIkov01+1fXcvDxFIsH/pYkWWtKxgxZaaGl4y79Zpk8//URdunYLfNs+jQkt8Q38cRu9+P6KlGx7ez6NCy1+t/jSQQsttISrxZcOWhAmiVbg9XfOrYp9/UdJP3fOFUrqLenump5kZiPMbI6ZzanPPt1OLt5r1/n16oOW+Gjxt0OipSa0xEdL7TZv3qSrLh+pK68epZYtWwa+fZ/GhJYfys40ndg5Ty994McEni/jItFSE19afOmQaKkJLfHREp8vLb50SLQ0RmYW2CVIWQnuzzazLOdcmaRmzrnZkuSc+9zMmtT0JOfcWEljJWlrWZxP6A7Ky8tX0YqiquvFkYhyc3Pr+nL1Qgst6dZBCy20NJzS0lJddflIndJ/oHqddHJKGnwaE1p+qMeBrfXRN99q1caSwLcdjy/jQov/Lb500EILLeFq8aWDFoRJohV490qaYma9JE01s7+a2fFmdoukD5Id17lLVy1ZsljLli1VaUmJpk6ZrB49eyV7s7TQEooOWmihpWE453TbTTeoQ4f9ddbZ56akQfJrTGj5oYGHttWLc/1YfSf5My60+N/iSwcttNASrhZfOmhBmNS6As8593czmy/pQkmdYo/vJOl5SbclPS4rS6Ouv1EXjhiuiopyDR4yVIWFHZO9WVpoCUUHLbTQ0jA+eH+uJk96QYUdO+kXpw+WJF088jIde1zSDwX7PT6NCS3f1zQ7Q8d22ks3PLOg6raTu+bppiEHa4+WORp/Xnd9/M16nTN2dmBNPowLLenR4ksHLbTQEq4WXzpoaZyCPrlEUMy5uu3hambnOuceTPS4+uxCCwBAQygr9+c/RVmZIf2NIiQOvnpKqhOqfHxXv1QnAAAAjzXNEr9YxnHVpM8C++X/jwMOCOw9SLQLbW1uabAKAAAAAAAAoJ7MgrsEqdZdaM1sXk13Scpr+BwAAAAAAAAA1SU6C22epD6S1m53u0l6MylFAAAAAAAAQB1kBL00LiCJJvAmSWrpnPtg+zvMbEYyggAAAAAAAAB8J9FZaIfVct+ZDZ8DAOmnoo4nA0qGsP5rExAUn04cwQk14uOkNEB48DsUgGSoz8kefBbW7wsAAAAAAAAIhUS70AIAAAAAAABpIawLalmBBwAAAAAAAHjM+wm8WTNf16D+fTSgb2+NHzeWFlrSosWXDlr8b7n5huvU6/ijddrggSlrqM6XcfGppahohUYMO1tDT+2n04cM0OOP/jtlLb6MCS1+tnRo3UKTrji26vLh7b117vH76pRu+Zp69XFa+KdT1LVdq0CbKvnyHvn08yz5My6+dNBCy87gdyj/W3zpoKXxyTAL7BLo9xXo1nZSeXm5bh99q+4b84AmTJysqVMmadHChbTQ4nWLLx20pEfLwMFDdO+YcSnZ9vZ8GhefWjIzM3XZFdfouRem6KFHn9QzTz2mLxfxZwst/rV8tXKTBtz9hgbc/YYG/fkNbS2p0H/nF+nzFRt04YNz9e6XawJrqS7V41KdLz/Pkj/j4ksHLbTsLH6H8rvFlw5aECZeT+AtmD9PBQXt1a6gQNk5Oerbr79mTJ9GCy1et/jSQUt6tBzW/XC1apWaFTHb82lcfGpp3TpXBx3cWZLUokVLdeiwv4qLI4F3+DQmtPjfcnTHvfT16k1avnarFhVv0lcrN6WkQ/JrXHz5eZb8GRdfOmihZWfxO5TfLb500NI4mQV3CVKtE3hmNtfMbjCz/YMKqq44ElF+m/yq67l5eYpEUvNLFi20pFsHLenR4hOfxsWnluqWf7NMn376ibp07Rb4tn0aE1r8bxn44zZ68f0VKdn29nwal+pS+fMs+TMuvnTQQks682lcfGnxpYMWhEmiFXi7S9pN0nQze9fMLjOztole1MxGmNkcM5tTn326nVy8167z69UHLfHR4m+HREtNfGrxiU/j4lNLpc2bN+mqy0fqyqtHqWXLloFv36cxoSU+X1qyM00nds7TSx/4MYHny7hUl+qfZ8mfcfGlQ6KlJrT4z6dx8aXFlw6JlsYow4K7BCkrwf1rnXNXSrrSzI6T9AtJc83sE0lPOOfizs7Fbh8rSVvL4nxCd1BeXr6KVhRVXS+ORJSbm1vXl6sXWmhJtw5a0qPFJz6Ni08tklRaWqqrLh+pU/oPVK+TTk5Jg09jQovfLT0ObK2PvvlWqzaWBL7teHwZl0o+/DxL/oyLLx200JLOfBoXX1p86aAFYbLDx8Bzzs10zl0kaW9Jd0r6SdKqYjp36aolSxZr2bKlKi0p0dQpk9WjZ69kb5YWWkLRQUt6tPjEp3HxqcU5p9tuukEdOuyvs84+NyUNkl9jQovfLQMPbasX5/qx+k7yZ1wkf36eJX/GxZcOWmhJZz6Niy8tvnTQgjBJtALv8+1vcM6VS5oauyRVVlaWRl1/oy4cMVwVFeUaPGSoCgs7JnuztNASig5a0qPl2qsu13uzZ2vdurXqc2IPXXDRJRoy9LSUtPg0Lj61fPD+XE2e9IIKO3bSL04fLEm6eORlOva4HoF2+DQmtPjb0jQ7Q8d22ks3PLOg6raTu+bppiEHa4+WORp/Xnd9/M16nTN2dmBNPoxLJV9+niV/xsWXDlpo2Vn8DuV3iy8dtDROGSHdLdmcq9sermZ2rnPuwUSPq88utACQDirq+OdoMoT1P1b1VVbuz3uUlcl7hB1z8NVTUp1Q5eO7+qU6oQo/z0B48DsUUD9Ns8QHN45b/7cwsD9cbuxdGNh7sMO70MZxS4NVAAAAAAAAAPVkFtwlSLXuQmtm82q6S1Jew+cAAAAAAAAAqC7RMfDyJPWRtHa7203Sm0kpAgAAAAAAAOogI6Q7FieawJskqaVz7oPt7zCzGckIAgAAAAAAAPCdWifwnHPDarnvzIbPAYD0w0GP/ceB5pGOfDpxxJ6/SHjessCsfuLcVCcAaCD8DgUgGSyk5/aoz0ksAAAAAAAAACRZol1oAQAAAAAAgLQQ1mPgsQIPAAAAAAAA8Jj3E3izZr6uQf37aEDf3ho/biwttKRFiy8dtNBCS7hafOmghZYd8dv+B2v2nwdr9t2D9dClPdQkO1Ojf9Vdc/86RO/86VQ9cVUvtWqeE3hXqsfFxxZfOmihhZZwtfjSQUvjk2HBXQL9voLd3M4pLy/X7aNv1X1jHtCEiZM1dcokLVq4kBZavG7xpYMWWmgJV4svHbTQsiPa7NFcF/Y7WMdd+6IOv+J5ZWSYTj+mg179cLkOv/x5HXnlC1q4fL2uHPKjwJqk1I+Ljy2+dNBCCy3havGlgxaEidcTeAvmz1NBQXu1KyhQdk6O+vbrrxnTp9FCi9ctvnTQQgst4WrxpYMWWnZUVkaGmuVkKjPD1LxJllas2axp85arvMJJkt79olh779k80CYfxsW3Fl86aKGFlnC1+NJBS+NkZoFddqIp08zeN7NJset7mNn/zOyL2P/vnug1ap3AM7PuZjbdzB41s4LYi35rZrPN7Mc7XFpHxZGI8tvkV13PzctTJBJJ9mZpoSUUHbTQQku4WnzpoIWWHbFizWbd8+ICffrPn2nRuDO0fnOJps1b/r3HnN2zo15+f1lgTVLqx8XHFl86aKGFlnC1+NJBCzxyqaRPql2/VtI051xHSdNi12uVaAXefZLukjRZ0puS7nfOtYq98H01PcnMRpjZHDObU599up1cvNeu8+vVBy3x0eJvh0RLTWiJj5b4fGnxpUOipSa0fGe3FjkacPg+6nzxMyoc8aSaN8nSGcftV3X/VT/9kcoqnJ6c+WVgTVLqx6U6X1p86ZBoqQkt8dESny8tvnRItDRGvh0Dz8zaSeov6YFqN58q6eHY1w9LGpzw+0pwf7Zz7iXn3BOSnHPuWUW/mCapaU1Pcs6Ndc51d851H3beiEQNNcrLy1fRiqKq68WRiHJzc+v8evVBCy3p1kELLbSEq8WXDlpo2RE9u7bV4uINWrV+m8rKnSa+87WOPCC6/V/2KNQphxXoN/e8FlhPpVSPi48tvnTQQgst4WrxpYMWJFv1BWyxS7xJsL9KulpSRbXb8pxzKyQp9v8JPwiJJvC2mtnJZna6JGdmg2OBPSSVJ/5W6qdzl65asmSxli1bqtKSEk2dMlk9evZK9mZpoSUUHbTQQku4WnzpoIWWHbF01UYd3rG1muVkSpJO6NpWny37Vr0P2VuXDe6qn935iraUJP1XyR9I9bj42OJLBy200BKuFl86aEGyVV/AFrt8bzdUMxsgqdg59159t5WV4P4LFN2FtkJSH0kXmtlDkr6RdF59N55IVlaWRl1/oy4cMVwVFeUaPGSoCgs7JnuztNASig5aaKElXC2+dNBCy46Ys3CVnn97sWbdNUjl5U4fLl6tf73ymeb8ZYiaZGXqxd/3kSS9+/lKXTrurcC6Uj0uPrb40kELLbSEq8WXDloaJ8/2Sj5G0iAz66fonqy7mtmjkiJm1sY5t8LM2kgqTvRC5twP98HeEWZ2rnPuwUSP21oWZydvAAAApI09f5HwV77ArH7i3FQnAADghaZZ8muqyhN/fv3LwOahLj9+vx1+D8zsBElXOucGmNkfJa12zt1hZtdK2sM5d3Vtz0+0Aq82t0jy57c5AAAAAAAANGoZni3Bq8Edkp42s2GSlkg6PdETap3AM7N5Nd0lKW+n8wAAAAAAAIBGxjk3Q9KM2NerJZ24M89PtAIvT9Fj363d7naT9ObObAgAAAAAAABIpoy0WIC38xJN4E2S1NI598H2d5jZjGQEAQAAAAAAAPhOrRN4zrlhtdx3ZsPnAADQ8MrKOZ/S9rIyQ/pPk0gKn04csfuge1KdUGXtxEtTnQAAALaTHofA23kZqQ4AAAAAAAAAULP6nIUWAAAAAAAA8EaGwrkEjxV4AAAAAAAAgMe8n8CbNfN1DerfRwP69tb4cWNpoSUtWnzpoIUWWuqvqGiFRgw7W0NP7afThwzQ44/+mxb58/7QQsuOuGTwj/XeP8/SnPt+qYev7qsm2ZmSpAsHdtOHY8/We/88S6N/c0zgXakeF986aKGFlnC1+NJBS+NjFtwlSF5P4JWXl+v20bfqvjEPaMLEyZo6ZZIWLVxICy1et/jSQQsttDSMzMxMXXbFNXruhSl66NEn9cxTj+nLRY27xaf3hxZaEmm7ZwtdNKibjrn0CXW/6DFlZppO79FJx/+onQYctZ8Ov+gxHXbho/rrc3MDa5JSPy6+ddBCCy3havGlgxaEidcTeAvmz1NBQXu1KyhQdk6O+vbrrxnTp9FCi9ctvnTQQgstDaN161wddHBnSVKLFi3VocP+Ki6ONOoWn94fWmjZEVmZGWqWk6XMDFOzJtlasXqTRvTvqj89M0clZeWSpJXfbgm0yYdx8amDFlpoCVeLLx20NE4ZFtwl0O+rtjvNrKWZ3WpmH5nZt2a20szeNrNzgogrjkSU3ya/6npuXp4ikdT8pYkWWtKtgxZaaGl4y79Zpk8//URdunZLdUpKW3x6f2ihJZHlqzfpr/+Zq88f/o2+emy41m/apmnvL1Fh2911TOe99fpffq6X7xyqwzrmBdYkpX5cfOughRZawtXiSwctCJNEK/Aek/SlpD6SbpH0N0m/ktTTzG6v6UlmNsLM5pjZnPrs0+3k4r12nV+vPmiJjxZ/OyRaakJLfLTUbvPmTbrq8pG68upRatmyZaNu8en9oSU+Wr6zW8smGnDUfjro3Ie031nj1aJpts7oeYCyMk27t2yi4y97SteNf0OPjjolsCYp9ePiW4dES01oiY+W+Hxp8aVDoqUxyjAL7BKkrAT37+uceyj29Z/NbLZz7jYzO1fSx5Kui/ck59xYSWMlaWtZnE/oDsrLy1fRiqKq68WRiHJzc+v6cvVCCy3p1kELLbQ0nNLSUl11+Uid0n+gep10cso6fGnx6f2hhZZEeh1SoMVF67VqfXQX2ednLdRRB7XVN6s26vk3o8cdmvN5RBXOaa9dm1U9LtlSPS6+ddBCCy3havGlgxaESaIVeJvM7FhJMrOBktZIknOuQlLSpxo7d+mqJUsWa9mypSotKdHUKZPVo2evZG+WFlpC0UELLbQ0DOecbrvpBnXosL/OOvvclDT41uLT+0MLLYksXblBRxyYr2ZNov9u3fOQAn22dI1efPtLndCtQJJUuPduysnKDGzyTkr9uPjWQQsttISrxZcOWhAmiVbgXSDpATPrJGmBpN9Ikpm1lnRvktuUlZWlUdffqAtHDFdFRbkGDxmqwsKOyd4sLbSEooMWWmhpGB+8P1eTJ72gwo6d9IvTB0uSLh55mY49rkejbfHp/aGFlkRmfxbRhDcW6q2//UJl5RX68MuVGv/SAjk53f+73ppz3y9VUlah4X9+ObAmKfXj4lsHLbTQEq4WXzpoaZzCuleyOVe3PVzN7Fzn3IOJHlefXWgBAGgIZeX8p2h7WZkh/c0Gobf7oHtSnVBl7cRLU50AAGjEmmYlf8/IdDTuna8D++X/vCPbB/YeJFqBV5tbJCWcwAMAAAAAAACCEPTJJYJS6wSemc2r6S5JeQ2fAwAAAAAAAKC6RCvw8iT1kbR2u9tN0ptJKQIAAAAAAADqIKQL8BJO4E2S1NI598H2d5jZjGQEAQAAAAAAAPhOnU9isaM4iQUAINUqkvzfup0R1mNyAI3RgVdMSnVClU/vHpDqBABAwDiJRXwPzV4S2C//5xy+T2DvQUZQGwIAAAAAAACw8+pzFloAAAAAAADAGxbSPV5YgQcAAAAAAAB4zPsJvFkzX9eg/n00oG9vjR83lhZa0qLFlw5aaKGl/m6+4Tr1Ov5onTZ4YMoaKvkyJrTQQkvd7JfbQlOuOq7qMv/OPvpNjw4aNeggTbvuBL10zfG6f1h37dos2J1keH9ooYWWMHfQ0vhYgJcgeT2BV15erttH36r7xjygCRMna+qUSVq0cCEttHjd4ksHLbTQ0jAGDh6ie8eMS8m2q/NpTGihhZa6+bJ4k/r9cab6/XGmBvxppraWlOu/84r0xmcrdfIdr+mUO1/XV8UbddFJhYE1pXpMaKGFlnC2+NJBC8Kk1gk8M2tlZneY2admtjp2+SR2227Jjlswf54KCtqrXUGBsnNy1Ldff82YPi3Zm6WFllB00EILLQ3jsO6Hq1WrVinZdnU+jQkttNBSf8d02ktfr9qsb9Zu0czPVqm8InrCvPe/Xqf83ZoF1uHTmNBCCy3hafGlg5bGKcMssEug31eC+5+WtFbSCc65PZ1ze0rqGbvtmWTHFUciym+TX3U9Ny9PkUgk2ZulhZZQdNBCCy3h4tOY0EILLfU38NC2mjh3+Q9uP/3IAs34pDiwDp/GhBZaaAlPiy8dtCBMEk3g7eucu9M5V1R5g3OuyDl3p6R9anqSmY0wszlmNqc++3Q7uXivXefXqw9a4qPF3w6JlprQEh8tfvNpTGiJj5b4aPmh7EzTSV3yNeWD70/gXdy7UOUVTs/P+SawFl/GRKKlJrTER0t8vrT40iHR0hiF9Rh4iY6Q+7WZXS3pYedcRJLMLE/SOZKW1vQk59xYSWMlaWtZnE/oDsrLy1fRiqq5QxVHIsrNza3ry9ULLbSkWwcttNASLj6NCS200FI/JxyUqwXLvtWqDSVVtw09vJ1O7JynM+99K9AWX8aEFlpoCVeLLx20IEwSrcD7uaQ9Jb1mZmvNbI2kGZL2kPSzJLepc5euWrJksZYtW6rSkhJNnTJZPXr2SvZmaaElFB200EJLuPg0JrTQQkv9DDqsrV6c+90qux4HttYFJ+2v4eNma2tpRaAtvowJLbTQEq4WXzpoQZjUugLPObfWzB6U9D9JbzvnNlbeZ2Z9JU1NalxWlkZdf6MuHDFcFRXlGjxkqAoLOyZzk7TQEpoOWmihpWFce9Xlem/2bK1bt1Z9TuyhCy66REOGnhZ4h09jQgsttNRd0+wMHXtAa1331Pyq2245rYtysjL06EVHSoqeyOL6p+fX9BINyocxoYUWWsLX4ksHLY1TWPdKNudq3sPVzEZKuljSJ5IOkXSpc+6F2H1znXOHJtpAfXahBQCgIVTU8t+6oAV9tioAyXPgFZNSnVDl07sHpDoBABCwplmBH4YtLTw+d1lgv/yfeWi7wN6DRMfAO0/SYc65jWa2r6RnzWxf59w9Cv54fQAAAAAAAECNwnpikEQTeJmVu8065xab2QmKTuK1FxN4AAAAAAAAQNIlOolFkZkdUnklNpk3QNJekromsQsAAAAAAADYKRkBXoKUaHtnSyqqfoNzrsw5d7ak45NWBQAAAAAAAEBS4rPQLqvlvlkNnwNge/fO+jLVCVUuPma/VCcAdcKJIwAkg08njnhxwfJUJ0iSBnZpm+oEAEAjF9Zj4AW94g8AAAAAAADATkh0EgsAAAAAAAAgLYRz/R0r8AAAAAAAAACveT+BN2vm6xrUv48G9O2t8ePG0kJLWrT40FFRUa7nbrtYU/9+kyRp66YNmvyX6/TkDcM0+S/XadumDYE3+TAutNCSzi2+dNBCCy3p3VJaUqJ/Xneh/nHVMP3tinM07ekHJUlTHx2jv152tv5+1TA99qffa8umjYE1VeL9oYWW8LT40kFL42NmgV2C5PUEXnl5uW4ffavuG/OAJkycrKlTJmnRwoW00OJ1iy8dC6a9oN3a7FN1/YOXntbeBx6iM/5vvPY+8BB9MPXpQHt8GRdaaEnXFl86aKGFlvRvycrO1m9u/LN++8fxuvjOB/TFh+9q6ecfa/+uh+mSPz2oS/44Xnu1aafXn38skJ5KvD+00BKeFl86aEGY1HkCz8xeasiQeBbMn6eCgvZqV1Cg7Jwc9e3XXzOmT0v2ZmmhJe07Nq5dqSXz39WBx/apuu3rD99Sp5+cJEnq9JOTtPiDtwJt8mFcaKElnVt86aCFFlrSv8XM1KRpM0lSeXmZysvKJZM6djtcmZmZkqSCjgfr29UrA+mpxPtDCy3hafGlg5bGKSPAS5Bq3Z6ZHVrD5TBJhyQ7rjgSUX6b/KrruXl5ikQiyd4sLbSkfcdbT92vI4cOk9l3P+Jb1q9T8932kCQ1320PbdnwbaBNPowLLbSkc4svHbTQQks4WioqyvWPq4frjvOGqPBHh6mg48Hfu/+96S+p04+PDKxHSv2Y0EILLeHroAVhkugstLMlvab4J/HYraYnmdkISSMk6R/33a9h542oU5yTi/fadXqt+qIlPlr86/h63jtqtstuat2+o5Z/Ni+w7SaS6nGpjpb4aInPlxZfOiRaakJLfLTEl+qWjIxM/fauB7Rl00Y9/qffK7LkK+Xt00GSNOM/jyojM1Pdjj0psB4p9WNSHS3x0RIfLf52SLQ0RmEd00QTeJ9IOt8598X2d5jZ0pqe5JwbK2msJG0ti/MJ3UF5efkqWlFUdb04ElFubm5dX65eaKElXToiCz/W1x++rSULZqu8tFQlWzbr1fF3qdmuu2nzujVqvtse2rxujZrt0iqwJin140ILLene4ksHLbTQEq6WZi1aqsPBh+iLD99V3j4dNPe1qfps7ls69/d3B/4XIF/GhBZaaAlPBy0Ik0S77N5cy2MuadiUH+rcpauWLFmsZcuWqrSkRFOnTFaPnr2SvVlaaEnrjiN+eq5+edejOvMPD+vE867V3gd2U69hV6t9t6P0+VuvSJI+f+sVte/2k8CapNSPCy20pHuLLx200EJL+rdsWr+u6gyzpSXbtGjBe9qr7T76/IN3NfOFJ3XW1aOV06RpIC3V8f7QQkt4WnzpoAVhUusKPOfcs2Z2oJmdKOkd51z1c8lvTW6alJWVpVHX36gLRwxXRUW5Bg8ZqsLCjsneLC20hKJje4f0/ZleGXu7Pp31X7Xco7VOOv/6QLfv07jQQks6tvjSQQsttKR/y4a1q/XcfXeooqJCrqJCXX5ygg487Cf688hfqqysVA/+35WSoieyOPW8ywNpknh/aKElTC2+dNDSOIVzB1rJnKt5D1czGynpYkV3pT1E0qXOuRdi9811zh2aaAP12YUWgHTvrC9TnVDl4mP2S3UCAACI48UFy1OdIEka2KVtqhMAoNFomhXauap6eX5eUWDzUIN/lB/Ye5DoGHjnSTrMObfRzPaV9KyZ7eucu0fhndQEAAAAAABAGgrpOSwSTuBlVu4265xbbGYnKDqJ115M4AEAAAAAAABJl+gkFkVmdkjlldhk3gBJe0nqmsQuAAAAAAAAYKdkyAK7BPt91e5sSUXVb3DOlTnnzpZ0fNKqAAAAAAAAAEhKcBKLhuDTSSxO/tusVCdUeXnkMalOAAAAAAAAaYqTWMQ3aUEksHmoAV3yAnsPEq3AAwAAAAAAAJBCiU5iAQAAAAAAAKQFC+nCRFbgAQAAAAAAAB7zfgJv1szXNah/Hw3o21vjx40NfPstm2Tq1gEH6JFzfqxHfv1jdW6zi07ouKcePvvHmnHZ0Togr2XgTVLqx4WW9OighRZawtXiSwcttNASrhZfOmihhZZwtfjSQUvjYxbcJUheT+CVl5fr9tG36r4xD2jCxMmaOmWSFi1cGGjDyBP20zuL1+lXD72vcx/5QF+v2ayvVm/WDS9+qg+XrQ+0pZIP40KL/x200EJLuFp86aCFFlrC1eJLBy200BKuFl86aEGY1DqBZ2a7mtkfzOwRMztzu/vuS26atGD+PBUUtFe7ggJl5+Sob7/+mjF9WrI3W6V5Tqa6tdtVkxdEJEllFU4bt5Xr6zVbtHTtlsA6tpfqcaElPTpooYWWcLX40kELLbSEq8WXDlpooSVcLb500NI4ZcgCuwT7fdXuQUkm6TlJZ5jZc2bWJHbfUUktk1QciSi/TX7V9dy8PEUikWRvtkrbVk21bkupRvUp1ANnddPVvQvVNCv1ixZTPS60pEcHLbTQEq4WXzpooYWWcLX40kELLbSEq8WXDloQJolmo/Z3zl3rnHveOTdI0lxJr5rZnrU9ycxGmNkcM5tTn326nVy8167z6+2szAxTx9yWev7DIg1/9ENtLS3XL49oF9j2a5LqcamOFn87JFpqQkt8tMTnS4svHRItNaElPlri86XFlw6JlprQEh8t8fnS4kuHREtjFNZj4GUluL+JmWU45yokyTk32syWSXpdUo1nb3DOjZU0VpK2lsX5hO6gvLx8Fa0oqrpeHIkoNze3ri+301Zu2KaVG7bpk6KNkqQZX6zWLw/fO7Dt1yTV40JLenTQQgst4WrxpYMWWmgJV4svHbTQQku4WnzpoAVhkmgF3ouSelW/wTn3sKQrJJUkK6pS5y5dtWTJYi1btlSlJSWaOmWyevTslfiJDWTN5lIVb9imgt2bSZIO26eVFq9J3bHvKqV6XGhJjw5aaKElXC2+dNBCCy3havGlgxZaaAlXiy8dtCBMal2B55y72swONLMTJb3jnNsYu32qmY1MelxWlkZdf6MuHDFcFRXlGjxkqAoLOyZ7s99zz/Sv9PtTOik707T82636w3+/0HGFe+jSnvtpt2bZunPwQVq4cpOu/M/HgTX5MC60+N9BCy20hKvFlw5aaKElXC2+dNBCCy3havGlg5bGKax7JZtzNe/hamaXSPqtpE8kHSLpUufcC7H75jrnDk20gfrsQtvQTv7brFQnVHl55DGpTgAAAAAAAGmqaVbAp0FNEy9/sjKweaiTD2od2HuQ6Bh4IyQd5pzbaGb7SnrWzPZ1zt0j8UEBAAAAAACAPyyk01WJJvAyq+02u9jMTlB0Eq+9mMADAAAAAAAAki7RSSyKzOyQyiuxybwBkvaS1DWJXQAAAAAAAMBOybDgLoF+XwnuP1tSUfUbnHNlzrmzJR2ftCoAAAAAAAAAkhKcxKIh+HQSCwAAAACNQ8+7X091QpXpV7D2AUDD4yQW8b366erA5qF6HbhnYO9BohV4AAAAAAAAAFIo0UksAAAAAAAAgLRgIV2XyAo8AAAAAAAAwGPeT+DNmvm6BvXvowF9e2v8uLG00JIWLb500EILLeFq8aWDFlpoCVeLLx0+tLRskqnRgw/Sk8O764nh3dWl7S4acVx7PXLuoXr4nEP115911V4tcwLvSvW40EJLOnfQ0vhYgP8LktcTeOXl5bp99K26b8wDmjBxsqZOmaRFCxfSQovXLb500EILLeFq8aWDFlpoCVeLLx2+tFx2YqHe/nKtznhgjn71r/e0ePVmPfrOMv3qwbn69UNzNWvRav3m6H0CbfJhXGihJV07aEGY1DqBZ2b5ZvZPM7vXzPY0s5vNbL6ZPW1mbZIdt2D+PBUUtFe7ggJl5+Sob7/+mjF9WrI3SwstoeighRZawtXiSwcttNASrhZfOnxoaZ6TqUMKWunFeUWSpLIKp43byrW5pLzqMc2yMxXYqQ1jUj0utNCSzh20NE4ZFtwl0O8rwf0PSfpY0lJJ0yVtkdRf0kxJY5JaJqk4ElF+m/yq67l5eYpEIsneLC20hKKDFlpoCVeLLx200EJLuFp86fChZe/dmmrd5hLd0K+THj7nUI3q21FNs6N/XTr/uH31/IVH6uSDczVu5teBNUmpHxdaaEnnDloQJokm8PKcc393zt0haTfn3J3OuSXOub9Lal/Tk8xshJnNMbM59dmn28X59y1L0elEaImPFn87JFpqQkt8tMTnS4svHRItNaElPlri86XFlw4p9S2ZGaZO+bvoP++v0K8fmqstpRU6+6gCSdL9Mxdr8D/f0csfF+u0w9oG1iSlflyqoyU+WvztkGhpjBrrMfCq3//v7e7LrOlJzrmxzrnuzrnuw84bUee4vLx8Fa0oqrpeHIkoNze3zq9XH7TQkm4dtNBCS7hafOmghRZawtXiS4cPLcUbtmnlhm36eMUGSdL0z1aqU17L7z3m5Y+LdUKnvQJrklI/LrTQks4dtCBMEk3gvWBmLSXJOXdD5Y1mVijps2SGSVLnLl21ZMliLVu2VKUlJZo6ZbJ69OyV7M3SQksoOmihhZZwtfjSQQsttISrxZcOH1rWbCpVZP027bNHM0lS9/a7a/GqzWq3e9OqxxxbuKe+XrM5sCYp9eNCCy3p3EELwiSrtjudczea2YFmtrekd5xzG2O3LzSzB5Iel5WlUdffqAtHDFdFRbkGDxmqwsKOyd4sLbSEooMWWmgJV4svHbTQQku4Wnzp8KXlz68s1M0DDlR2pumbdVs1esrnGnVKR+2zR3M551S0fpvu+u8XgTb5MC600JKuHbQ0TmHdK9mcq/k8SmZ2iaTfSvpE0iGSLnXOvRC7b65z7tBEG9haFviJmgAAAAA0cj3vfj3VCVWmX3F8qhMAhFDTrIAPwpYm3vhibWDzUMd23D2w96DWFXiSRkg6zDm30cz2lfSsme3rnLtH4oMCAAAAAAAAf4R1sirRBF5mtd1mF5vZCYpO4rVXeMcEAAAAAAAA8Eaik1gUmdkhlVdik3kDJO0lqWsSuwAAAAAAAICdkmEW2CXQ7yvB/WdLKqp+g3OuzDl3tiQO5AAAAAAAAAAkWa0nsWgInMQCAAAAQGM2/MkPU51Q5YEzuqU6AUAD4SQW8b29cF1g81BHFe4W2HuQaAUeAAAAAAAAgBRKdBILAAAAAAAAID2EdF0iK/AAAAAAAAAAj3k/gTdr5usa1L+PBvTtrfHjxtJCS1q0+NJBCy20hKvFlw5aaKElXC2+dNDyfX8ZfJD+0L+TRvfrpFtP6ShJ+sWhbXTXwAN0e/9O+t3x+6p5dvB/nUv1uNCSPi2+dNDS+FiA/wvSTv+Jb2a5yQiJp7y8XLePvlX3jXlAEyZO1tQpk7Ro4cKgNk8LLWndQQsttISrxZcOWmihJVwtvnTQEt/oVxbp+imf68aXvpAkzV+xQddO+kzXTf5cKzZs08AueYH2/H97dx9nZV3nf/z1YW4ckBtBmhmUEVTAO1BEtNZKBe8QCDGrdStRi+jnWmpbmayumaVpru3alquopatpW+YNCaJmkKbrDRIgijegCKPMGRQQkJu5+/z+OIdpwnMDA+e6vufi/eRxHpwzZ+ZcL79n/HLmO9d1rlDGRS3ht4TSoRZJkrwLeGbWZ5vL3sDzZtbbzPoUO27RSwupqxtA/7o6KiorGTN2HHNmP1HszapFLYnoUIta1JKsllA61KIWtSSrJZQOtWxn18oNtGXOrbj0vQ/p060i2u0HNC5qCbsllA617J7MortEqdAeeO8BL3a4zAX2BeZlrhdVYypFbb/a9tvVNTWkUqlib1YtaklEh1rUopZktYTSoRa1qCVZLaF0qOWjHOfSEw/gh6cNZtSgj+47cdyBfVj47rpIm0IYF7WURksoHWqRJCm0gHcJ8Bowwd33d/f9gfrM9QNyfZGZTTGzuWY2d2eO6XY822N3+vF2hlqyU0u4HaCWXNSSnVqyC6UllA5QSy5qyU4t2YXSEkoHqGVbVz26hMtnvsH1f3qLkw7qy0HVe7bfN2FoNW1t8PRbayNtCmFctlJLdqG0hNIBatkdWYSXKJXnu9Pd/93MfgP8h5mtAL4PWb7jPvp104BpAJtbCn9+LjU1tTSsbGi/3ZhKUV0d2VvwqUUtJd2hFrWoJVktoXSoRS1qSVZLKB1q+ai1m1oAWLelhRdXfMCBe3fjtcYP+fQBvTly3578+I9LI+2BMMZFLaXREkqHWiRJCp7Ewt3r3f3zwGzgcaBb0asyDhs6jOXLl1Ffv4LmpiZmzZzB8aNGR7V5tailpDvUoha1JKsllA61qEUtyWoJpUMtf2+Psi5UlXdpvz60Xw/q127m8H49GH9oNT+d8xZNrZ3eT6LT4h4XtZROSygdapEkybsHHoCZHUz6fe9mA38EDsx8fIy7zypqXHk5Uy+7gvOnTKatrZWJZ5zJoEGDi7lJtaglMR1qUYtaktUSSoda1KKWZLWE0qGWv9ezazkXHz8QgDIznlm2hoUr13PD6QdT3sW49MQDAVjy3of86vl3IuuKe1zUUjotoXSoZTeV0KOSzT33b27M7ELgAmAxMBy4yN0fytw3z91HFNrAzhxCKyIiIiIiUuom/2ZB3AntbjvriLgTRGQXqSpP6lLVznnhrQ8iW4c6ev9ekT0HhfbA+xpwlLtvMLOBwH1mNtDdbySxa5oiIiIiIiIiIlKKLKHLVYUW8MrcfQOAuy8zsxNIL+INQAt4IiIiIiIiIiIiRVfoJBYNZjZ8643MYt54oC8wrIhdIiIiIiIiIiIiO8QsukuUCi3gTQIaOn7A3VvcfRJwXNGqREREREREREREBChwEotdQSexEBERERERCcPZd8+LO6HdXV8ueE5EEclDJ7HIbt6ydZGtQ40Y2DOy56DQHngiIiIiIiIiIiKyg8yszsxmm9liM3vZzC7KfLyPmT1uZm9k/u5d6LG0gCciIiIiIiIiIslgEV4KawG+7e6HAJ8ALjCzQ4FLgSfcfTDwROZ2XlrAExERERERERER2cXcfaW7z8tcXw8sBvYFTgfuzHzancDEQo8V/ALe0089yYRxpzJ+zMncfus0tailJFpC6VCLWtSSrJZQOtSiFrUkqyWUDrWE2/KLzx3GDacfwvUTDuba8Qf93X2fOaya3507gh57lEXeFfe4qKU0OtSy+7Eo/5hNMbO5HS5TcnaZDQSOBJ4Datx9JaQX+YDqQv9dQS/gtba2cs3VV3HTzbfxwPQZzJr5MEuXLFGLWoJuCaVDLWpRS7JaQulQi1rUkqyWUDrUEn7LlbNe57vTX+XSh19r/9je3So4fJ+erNqwJfKeUMZFLWF3qEWKzd2nufvIDpesq7Jm1h34PXCxu6/rzLbyLuCZ2ZgO13uZ2e1mttDM7jGzms5scEcsemkhdXUD6F9XR0VlJWPGjmPO7CeKvVm1qCURHWpRi1qS1RJKh1rUopZktYTSoZbSaNnWucf05+657xDZ6R47CGlc1BJuh1p2T2bRXbavxypIL9792t3vz3w4ZWb9Mvf3AxoLPU6hPfCu6XD9BmAl8BngBeCW7UvtvMZUitp+te23q2tqSKVSxd6sWtSSiA61qEUtyWoJpUMtalFLslpC6VBL4C0Ol58ymOvGH8xJQ/YGYGRdL1ZvbObtNZuibckIYlzUEnyHWiRuZmbA7cBid/9ph7umA+dkrp8DPFToscp3YLsj3X145vp/mNk5uT4xc8zvFICf33QLX/1azkOA8/Isv8ux7V3i3MXUkp1awu0AteSiluzUkl0oLaF0gFpyUUt2askulJZQOkAtuYTQcvnM11mzqZmeVeX82ymDeOeDLXz28Fp+9NgbkXZ0FMK4bKWWcDtALbujwEb0k8DZwEtmNj/zsX8FrgV+a2ZfBZYDny/0QIUW8KrN7F9I//f3NDNz963fcTn33ssc8zsNYHNL5/eorqmppWFlQ/vtxlSK6uqC7+tXFGpRS6l1qEUtaklWSygdalGLWpLVEkqHWsJuWbOpGYB1m1t4fvkHHFrTnerulVx/+iEA7N2tkp985hCmzniVtZtaImkKYVzUEn6HWiRu7v4Xcq8pnrgjj1XoENpbgR5Ad9Knte0LYGa1wPwd2VBnHDZ0GMuXL6O+fgXNTU3MmjmD40eNLvZm1aKWRHSoRS1qSVZLKB1qUYtaktUSSodawm3Zo7wLVeVd2q8fsU8Plr6/kcn/+xIX3PcyF9z3Mu9vbOKSPyyObPEO4h8XtZRGh1okSfLugefuPzCzg4F9gefcfUPm4w1mdk/R48rLmXrZFZw/ZTJtba1MPONMBg0aXOzNqkUtiehQi1rUkqyWUDrUoha1JKsllA61hNvSq6qc744+AIAyM/7y1hrmv9OpEyjuUnGPi1pKo0Mtu6nAjqHdVexvR8RmudPsm8A3gMXAcOAid38oc988dx9RaAM7cwitiIiIiIiI7Dpn3z0v7oR2d3254I+TIpJHVXlSl6p2zoIV6yNbhzqirkdkz0Gh98CbAhzl7hvMbCBwn5kNdPcbSeyapoiIiIiIiIiIlCJL6HJVoQW8sg6HzS4zsxNIL+INQAt4IiIiIiIiIiIiRVfoJBYNZjZ8643MYt540iezGFbELhERERERERERkR1iFt0lSoUW8CYBDR0/4O4t7j4JOK5oVSIiIiIiIiIiIgIUOInFrqCTWIiIiIiIiMi2TvvFM3EntHvkgmPjThDZYTqJRXaL6jdEtg41tH/3yJ6DQnvgiYiIiIiIiIiISIwKncRCRERERERERESkNCR0v0TtgSciIiIiIiIiIhKw4Bfwnn7qSSaMO5XxY07m9lunqUUtJdESSoda1KKWZLWE0qEWtaglWS2hdKhFLdtjz8oyrhx7EHeePZw7zh7OobXd6bFHOdefcSh3nXMk159xKN33KIu8K+5xCbEllA617H4swj9R2uEFPDPbuxgh2bS2tnLN1Vdx08238cD0Gcya+TBLlyyJavNqUUtJd6hFLWpJVksoHWpRi1qS1RJKh1rUsr2+efz+PP/2Gs65az6Tf72At1dv4osj92Xeig84+86/Mm/FB3xxZP9Im0IYl9BaQulQiyRJ3gU8M7vWzPpmro80szeB58zsbTM7vthxi15aSF3dAPrX1VFRWcmYseOYM/uJYm9WLWpJRIda1KKWZLWE0qEWtaglWS2hdKhFLdujW2UZh+/bk5kvNwLQ0uZ82NTKsQf24dFX0h979JVGPnlgn8iaIP5xCbEllA617J7MortEqdAeeOPc/b3M9euBf3T3QcDJwA1FLQMaUylq+9W2366uqSGVShV7s2pRSyI61KIWtSSrJZQOtahFLclqCaVDLWrZHv167sHaTc187+RBTPunw/nOiQdSVd6FPt0qWL2xGYDVG5vp3bUisiaIf1xCbAmlQy2SJIUW8CrMbOuZaru6+wsA7v46sEeuLzKzKWY218zm7swx3Y5ne+xOP97OUEt2agm3A9SSi1qyU0t2obSE0gFqyUUt2aklu1BaQukAteSilr8p62IMqe7O9IUNTLl3IZubW/mnkftGtv1c4h6XjkJpCaUD1LI7sggvUSovcP8vgJlmdi0wy8z+E7gfOBGYn+uL3H0aMA1gc0uW79DtVFNTS8PKhvbbjakU1dXVnX24naIWtZRah1rUopZktYTSoRa1qCVZLaF0qEUt22PVhiZWbdjC4tQGAP685H2+OLI/qzc2t++F16dbBWs2NUfWBPGPS4gtoXSoRZIk7x547v5fwDXA14HTSS/cXQq8A3yl2HGHDR3G8uXLqK9fQXNTE7NmzuD4UaOLvVm1qCURHWpRi1qS1RJKh1rUopZktYTSoRa1bI81G5tpXN9E3V5VAIyo24tlqzfyzJurOfXQ9CLIqYdW88zS1ZE1QfzjEmJLKB1q2U0ldBe8QnvgATSQ3pvuOXffsPWDZjYGmFWsMIDy8nKmXnYF50+ZTFtbKxPPOJNBgwYXc5NqUUtiOtSiFrUkqyWUDrWoRS3JagmlQy1q2V4/m/Mml40ZQnmZsfKDzVz3+BK6mPH9sUMYe1g1jeu3cOWM1yNtCmFcQmsJpUMtkiTmnvsIVzO7ELgAWAwMBy5y94cy981z9xGFNrAzh9CKiIiIiIhIMp32i2fiTmj3yAXHxp0gssOqyiN/G7aSsHjlh5GtQx3Sb8/InoNCe+B9DTjK3TeY2UDgPjMb6O43Ev379YmIiIiIiIiIiORkCV2uKrSAV7b1sFl3X2ZmJ5BexBuAFvBERERERERERESKLu9JLIAGMxu+9UZmMW880BcYVsQuERERERERERGRHWIW3SVKhRbwJpE+iUU7d29x90nAcUWrEhEREREREREREaDASSx2BZ3EQkREREREREI26oYn405oN/vb2ldGto9OYpHd6w0bI1uHGlLbLbLnoNAeeCIiIiIiIiIiIhKjQiexEBERERERERERKQ0J3S9Re+CJiIiIiIiIiIgELPgFvKefepIJ405l/JiTuf3WaWpRS0m0hNKhFrWoJVktoXSoRS1qSVZLKB1qUUuptXTfo4yrJx7CbyaP5N7JIxm6Tw+mfHoAd503gjvPHcF/fmEYfbtXRt4V97iE1qGW3Y9F+CdKQS/gtba2cs3VV3HTzbfxwPQZzJr5MEuXLFGLWoJuCaVDLWpRS7JaQulQi1rUkqyWUDrUopZSbPnWiYN49s01nHXbXM7+5Ysse38jdz9Xz9m/msc5d8zj6aXv85Vj94u0KYRxCalDLZIkeRfwzGyemV1uZgdGFdTRopcWUlc3gP51dVRUVjJm7DjmzH4ijhS1qKXkOtSiFrUkqyWUDrWoRS3JagmlQy1qKbWWbpVlDK/rxR8WNgDQ0uZs2NLKxqbW9s/pWlFGZKfCzIh7XELrUMvuySy6S5QK7YHXG9gLmG1mz5vZt8xsn+JnpTWmUtT2q22/XV1TQyqVimrzalFLSXeoRS1qSVZLKB1qUYtaktUSSoda1FJqLfvuVcXajU1cPnYId547gqljBlNVkf7x+uufHsiD53+cUw6t5tan3o6sCeIfl9A61CJJUmgBb427f8fd9wO+DQwG5pnZbDObkuuLzGyKmc01s7k7c0y3Z/l9hUW9xJmhluzUEm4HqCUXtWSnluxCaQmlA9SSi1qyU0t2obSE0gFqyUUt2cXdUtbFGFLbg/v/upJz7pjHpuY2Jn2iDoBbnlrGxP9+jsdeaeRzR0W2/wsQ/7iE1gFq2R1ZhJcobfd74Ln7U+7+z8C+wHXAP+T53GnuPtLdR371aznX+QqqqamlYWVD++3GVIrq6upOP97OUItaSq1DLWpRS7JaQulQi1rUkqyWUDrUopZSa2lcv4VV67fwysr1AMx+bRVDarr/3ec89kojJwzpG1kTxD8uoXWoRZKk0ALe69t+wN1b3X2Wu59XpKZ2hw0dxvLly6ivX0FzUxOzZs7g+FGji71ZtaglER1qUYtaktUSSoda1KKWZLWE0qEWtZRay+oPm0mt28J+fboCMHJAb5a9t5H+vavaP+dTg/bm7dUbI2uC+McltA617KYSugteeb473f0sMzuY9F53z7n7hq33mdkYd59V1LjycqZedgXnT5lMW1srE884k0GDBhdzk2pRS2I61KIWtSSrJZQOtahFLclqCaVDLWopxZaf/nEJV44/mIoy4521m7l65utMPW0w+/XphrvTsG4LP3n0jUibQhiXkDrUIkli7rnPi2Nm3wS+ASwGhgMXuftDmfvmufuIQhvY3BL5iXdEREREREREttuoG56MO6Hd7G8fF3eClIiq8sjfhq0kLF21KbJ1qAM/1jWy5yDvHnjAFOAod99gZgOB+8xsoLvfSPTv1yciIiIiIiIiIpKTJXS5qtACXtnWw2bdfZmZnUB6EW8AWsATEREREREREREpukInsWgws+Fbb2QW88YDfYFhRewSERERERERERHZIWbRXaJUaAFvEtDQ8QPu3uLukwAdmC8iIiIiIiIiIlJkeU9isSvoJBYiIiIiIiIi2+faP0V75tp8Lh2tM6SGTCexyG7Ze5sjW4ca2Lcqsueg0B54IiIiIiIiIiIiEqNCJ7EQEREREREREREpDQndL1F74ImIiIiIiIiIiAQs+AW8p596kgnjTmX8mJO5/dZpalFLSbSE0qEWtaglWS2hdKhFLWpJVksoHWpRi1o6r62tlUeuu5A/3/wDABY+fBczf/wNHrn2m8z+xb+x8YP3I2+Ke0zUsvuyCP9EKegFvNbWVq65+ipuuvk2Hpg+g1kzH2bpkiVqUUvQLaF0qEUtaklWSygdalGLWpLVEkqHWtSilp3z+pzp9Kqpa799yIlnMnbqzznt0v9in8OO5uVH7o20J4QxUYskTd4FPDMbaWazzexuM6szs8fN7AMze8HMjix23KKXFlJXN4D+dXVUVFYyZuw45sx+otibVYtaEtGhFrWoJVktoXSoRS1qSVZLKB1qUYtaOm/jmvd49+UXOOAfTmn/WEXXbu3XW5o2g0W7p1DcY6KW3ZtZdJcoFdoD7ybgJ8AM4BngFnfvBVyaua+oGlMpavvVtt+urqkhlUoVe7NqUUsiOtSiFrUkqyWUDrWoRS3JagmlQy1qUUvnzbt/GsNP/wrW5e9XExb84X946N/O5e25cxg29suR9UD8Y6IWSaJCC3gV7v6Iu98LuLvfR/rKE0BVri8ysylmNtfM5u7MMd2OZ3vsTj/ezlBLdmoJtwPUkotaslNLdqG0hNIBaslFLdmpJbtQWkLpALXkopbs1JL2zqLn2aP7XvTZb9BH7jviM5M4/Yd3MGDkCbzx5MOR9Gyl5ye7kFqSzCK8RKm8wP2bzewUoBfgZjbR3R80s+OB1lxf5O7TgGkAm1uyfIdup5qaWhpWNrTfbkylqK6u7uzD7RS1qKXUOtSiFrUkqyWUDrWoRS3JagmlQy1qUUvnrHrzFd5Z9BwrX5lLa3MTzZs38cyd/86x53yn/XMGjjyBP998JcPGfSmSJtDzUwotUnoK7YH3/4BvA18BTgVGmdla0ofPXljcNDhs6DCWL19Gff0KmpuamDVzBsePGl3szapFLYnoUIta1JKsllA61KIWtSSrJZQOtahFLZ0zfMK5TPzhnUz4wS859rxLqBlyOMee8x3WN77T/jnvvPQcPWv6R9KzlZ6f8FuSLKnvgZd3Dzx3X2BmFwP7APXufhFwEYCZjSl6XHk5Uy+7gvOnTKatrZWJZ5zJoEGDi71ZtaglER1qUYtaktUSSoda1KKWZLWE0qEWtahl15o//U7WN9aDdWHPPh/j6H+8INLthzQmapGkMPfcR7ia2YXAPwOvAsOBi9z9ocx989x9RKEN7MwhtCIiIiIiIiK7k2v/9EbcCe0uHa3FpZBVlUf+NmwloX7NlsjWofr33iOy56DQe+B9DRjp7hvMbCBwn5kNdPcbif79+kRERERERERERPJI5nJVoQW8MnffAODuy8zsBNKLeANI6oiIiIiIiIiIiIgEpNBJLBrMbPjWG5nFvPFAX2BYEbtERERERERERER2SFJPYlFoAW8S0NDxA+7e4u6TgOOKViUiIiIiIiIiIiJAgZNY7Ao6iYWIiIiIiIhI6TnlZ0/HnQDAYxd+Mu6EIOkkFtm9u7YpsnWoffaqjOw5KLQHnoiIiIiIiIiIiMSo0EksRERERERERERESkLU700XFe2BJyIiIiIiIiIiErDgF/CefupJJow7lfFjTub2W6epRS0l0RJKh1rUopZktYTSoRa1qCVZLaF0qEUtain9lu57lHHV+IO469wjueucIzmsXw9OGLw3d046kjnfOpaDarpH2rOVnp/di0X4J0pBL+C1trZyzdVXcdPNt/HA9BnMmvkwS5csUYtagm4JpUMtalFLslpC6VCLWtSSrJZQOtSiFrUko+XCEw7guWVrOfuOv3LeXfN5e/VG3np/I5f/4VUW1K+LrKOjuMck1BYpPXkX8Mysu5ldZWYvm9kHZrbKzJ41s3OjiFv00kLq6gbQv66OispKxowdx5zZT0SxabWopeQ71KIWtSSrJZQOtahFLclqCaVDLWpRS+m3dKss44j+PZmxKAVAS5uzYUsrb6/exIo1myJpyEbPz27IIrxEqNAeeL8G3gROBX4A/Aw4GxhlZtcUuY3GVIrafrXtt6trakilUsXerFrUkogOtahFLclqCaVDLWpRS7JaQulQi1rUUvot+/SqYu2mZqaeOojbvnwEl5w8iKry+A/60/MjSVHo/6aB7n6Hu9e7+0+BCe7+BnAe8NlcX2RmU8xsrpnN3Zljuh3P9tidfrydoZbs1BJuB6glF7Vkp5bsQmkJpQPUkotaslNLdqG0hNIBaslFLdmpJbs4W8q6GIOru/PgggYm372Azc2tfOmY/pFsOx89P7ufhO6AR3mB+z80s0+5+1/M7DPAagB3b7M832XuPg2YBrC5Jct36HaqqamlYWVD++3GVIrq6urOPtxOUYtaSq1DLWpRS7JaQulQi1rUkqyWUDrUoha1lH7LqvVbWLV+C4sbNgAw5433+dLR+0ay7Xz0/EhSFNoD73zgp2a2FvgecCGAmX0M+EVx0+CwocNYvnwZ9fUraG5qYtbMGRw/anSxN6sWtSSiQy1qUUuyWkLpUIta1JKsllA61KIWtZR+y+qNzTSu30Jd764AHLVfL5atju+977bS87P7MYvuEqW8e+C5+wIzOwfYF3jW3TdkPr7KzF4velx5OVMvu4Lzp0ymra2ViWecyaBBg4u9WbWoJREdalGLWpLVEkqHWtSilmS1hNKhFrWoJRktN85+i387bQgVZca7H2zmx4++wacH9eGiUQewV9cKrpt4CEtWfch37n8lsqa4xyTUFik95p77CFczuxD4Z+BVYDhwkbs/lLlvnruPKLSBnTmEVkRERERERETiccrPno47AYDHLvxk3AlBqiqP/G3YSkLj+ubI1qGqe1RE9hwUeg+8rwEj3X2DmQ0E7jOzge5+I9G/X5+IiIiIiIiIiEhOltDlqkILeGUdDptdZmYnkF7EG4AW8ERERERERERERIqu0EksGsxs+NYbmcW88UBfYFgRu0RERERERERERHaMRXiJUKEFvElAQ8cPuHuLu08CjitalYiIiIiIiIiIiAAFTmKxK+gkFtmt39wSd0K7HlWFjqQWERERERERicev5y2PO6Hdl0bsF3dCO53EIrv3NrREtg7Vt3t5ZM9BoT3wREREREREREREJEba9UpERERERERERBLBErpfovbAExERERERERERCVjwC3hPP/UkE8adyvgxJ3P7rdPUkrF+/Touv+RivvjZ8XzpzM+waOH82FpCGpdQWkLpUIta1JKsllA61KIWtSSrJZQOtahFLclqibOjpamJ//n+N/jVv36d2y+dzF9+f2f7fS8+9iC3fvc8br90MnPuvTXSLgjn+Ukyi/BPlIJewGttbeWaq6/ipptv44HpM5g182GWLlmy27cA3Hj9j/n4P3yKe+5/mDt+83sG7H9ALB0hjUsoLaF0qEUtaklWSygdalGLWpLVEkqHWtSilmS1xN1RVlHBWVOv57xrbuHcH93MWwvn8u6SV3j7lfksmfcM511zC1+99jaOHvu5yJog/nGR0pZ3Ac/MepnZtWb2qpm9n7ksznxsr2LHLXppIXV1A+hfV0dFZSVjxo5jzuwnir3Z4Fs+3LCBBX99kfETzwSgoqKSHj16xtIS0riE0hJKh1rUopZktYTSoRa1qCVZLaF0qEUtaklWS9wdZkZlVVcA2lpbaG1tAYz5T/yBj48/i/KKSgD27NU7siaIf1x2F2bRXaJUaA+83wJrgBPcfW933xsYlfnY74od15hKUduvtv12dU0NqVSq2JsNvuXdd1awV+/eXHPlZZz3xTO59qor2LRpYywtIY1LKC2hdKhFLWpJVksoHWpRi1qS1RJKh1rUopZktYTQ0dbWyh2XfZ2fX/B5Bg4dwT6DDmFNQz31r73EXd//Jvf86F9Y+eZrkTaFMC5Sugot4A109+vcvWHrB9y9wd2vA/bL9UVmNsXM5prZ3J05ptvxbI/d6cfbGSG1tLa28vqri5n4ubP41T2/p6prV+7+1W2xtIQ0LqG0hNIBaslFLdmpJbtQWkLpALXkopbs1JJdKC2hdIBaclFLdmrJLpSWEDq6dCnj3Ktv4fwb72Xlm6+xasVbtLW2sfnDDXz5yp8x6p+mMP2/foT7R1uLJYRxkdJVXuD+t83sEuBOd08BmFkNcC6wItcXufs0YBrA5pYs36HbqaamloaV7WuHNKZSVFdXd/bhdkpILR+rruFj1TUcNuxwAEaddEpsC3ghjUsoLaF0qEUtaklWSygdalGLWpLVEkqHWtSilmS1hNIBULVnd/Y7+AjeWjiXHn36MuToT2Fm9DvwYKyLsWn9B3TruVckLSGNi5SeQnvg/SOwN/BnM1tjZquBOUAf4AtFbuOwocNYvnwZ9fUraG5qYtbMGRw/anSxNxt8y959P0Z1TS3Ll70FwNznn2XgAQfG0hLSuITSEkqHWtSilmS1hNKhFrWoJVktoXSoRS1qSVZL3B0b161l84cbAGhu2sLbL8+jzz51DDrqWN5+5a8ArF5ZT2tLC1179IqsK+5x2V0k9T3w8u6B5+5rzOz3wH3u/oKZHQaMARa7++qix5WXM/WyKzh/ymTa2lqZeMaZDBo0uNibDb4F4FuX/Cs/uPx7tDQ3s8++/Zl65Y9i6QhpXEJpCaVDLWpRS7JaQulQi1rUkqyWUDrUoha1JKsl7o4Na1czc9pP8LY2vM056OPHMejIT9Da0swjt97ALy/9Gl3Kyxk75buRHsIa97hIabN8x3ub2feB00gv9D0OHAP8GTgJeNTdry60gZ05hDbJ1m9uiTuhXY+qQkdSi4iIiIiIiMTj1/OWx53Q7ksjcp4OIHJV5egN9LJYu6k1snWovbqWRfYcFFq5+RwwHNgDaAD6u/s6M7seeA4ouIAnIiIiIiIiIiISBUvoumah98BrcfdWd98ILHX3dQDuvgloK3qdiIiIiIiIiIjIbq7QHnhNZtYts4B31NYPmlkvtIAnIiIiIiIiIiIBifrkElEptIB3nLtvAXD3jgt2FcA5RasSERERERERERERoMBJLHYFncRCRETi1tQSzk7jleWF3r1CREREREJ13j3z405od++k4Qnd12znrN/cFtk6VI+qLpE9B/opQkREREREREREJGCFDqEVEREREREREREpDQndL1F74ImIiIiIiIiIiAQs+AW8p596kgnjTmX8mJO5/dZpalFLSbSE0qEWtahl523ZsoVzvvgFvvj5iXzhjPHcctN/xdYSypioRS1qSVZLKB1qUYtaktUSSkcILT/77KFc95mD+PH4g7h67BAAPj+8tv1jU086gN5ddYDkrmIR/olS0At4ra2tXHP1Vdx08208MH0Gs2Y+zNIlS9SilqBbQulQi1rUsmtUVlby37f9int+9yD3/PYB/u/pv/DSwvmRd4Q0JmpRi1qS0xJKh1rUopZktYTSEVLLjx5bwtSHX+Oyma8D8PDLjXzvD68x9eHXmFe/js8eXht5k5SWTi/gmdkjuzIkm0UvLaSubgD96+qoqKxkzNhxzJn9RLE3qxa1JKJDLWpRy65hZnTrticALS0ttLQ0R/7bNghrTNSiFrUkpyWUDrWoRS3JagmlI7SWjjY1t7VfryrvQmSnTd0NmEV3iVLeBTwzG5HjchQwvNhxjakUtf3+tgpdXVNDKpUq9mbVopZEdKhFLWrZdVpbW/niF87glFGf4uOfOJahhx8ReUNIY6IWtaglOS2hdKhFLWpJVksoHaG0uDtTTzqQq8cNYfTgvds//oXhtfz8zEP55P69+d38lZE2SekpdJD1C8CfyX4Oj71yfZGZTQGmAPz8plv46temdCrOs6xBW9RLnBlqyU4t4XaAWnJRS3Zqya2srIx7fvsA69et47vf+iZL3nidQYOHRNoQ0pioJTu1ZKeW7EJpCaUD1JKLWrJTS3ahtITSAWG0XDnrDdZsaqFnVTn/etKBvPvBZl5t/JDfzm/gt/MbOH1oNace/DHuW9AQaVdSJfQktAUX8BYDX3f3N7a9w8xW5Poid58GTAPY3NL5PUFramppWPm3b+DGVIrq6urOPtxOUYtaSq1DLWpRy67Xo2dPjjr6GP7vmb9EvoAX0pioRS1qSU5LKB1qUYtaktUSSkcoLWs2tQCwbnMLL6z4gAP7duPVxg/b73/6rTVcMvoALeBJXoXeA+/KPJ/zzV2b8lGHDR3G8uXLqK9fQXNTE7NmzuD4UaOLvVm1qCURHWpRi1p2jTWrV7N+3ToANm/ezPPP/h8DB+4feUdIY6IWtaglOS2hdKhFLWpJVksoHSG07FHeharyLu3XD+/Xg/q1m6ntUdn+OUfV9eLddVsia0o8i/ASobx74Ln7fWZ2jJkd7e4vmNmhwBjgVXd/sOhx5eVMvewKzp8ymba2ViaecSaDBg0u9mbVopZEdKhFLWrZNd57bxVXXj6VtrZW2traOOmUMXz6+FGRd4Q0JmpRi1qS0xJKh1rUopZktYTSEUJLr6py/uWE9C9/y7rA02+tZcG767n4+IHs03MPHFi1oYnbn62PrElKk7nnPsLVzL4PnEZ6oe9x4OPAHOAk4FF3v7rQBnbmEFoREZFdoamlrfAnRaSyvNMngBcRERGRmJ13z/y4E9rdO2l4Ut/ubadsbM6z0LWLdauI7g0VC70H3udIn212D6AB6O/u68zseuA5oOACnoiIiIiIiIiISBQsoaexKLQbQIu7t7r7RmCpu68DcPdNQDi7M4iIiIiIiIiIiATGzMaY2WtmtsTMLu3s4xTaA6/JzLplFvCO6rDxXmgBT0REREREREREAhLdQa2FmVkZ8AvgZKAeeMHMprv7Kzv6WIX2wDsus3iHu3dcsKsAztnRjYmIiIiIiIiIiOwmjgGWuPub7t4E/AY4vTMPVOgstFnPY+zu7wHvbc8Gqsp3zcHHZjbF3aftisfaWaG0hNIBaslFLdmpJbtQWkLpgF3XUrULThyRxHHZFdSSnVrC7QC15KKW7NSSXSgtoXSAWnJJWsu9k4YH0yLZ7ap1qO1hZlOAKR0+NG2b53VfYEWH2/WkTxC7w0rpVHhTCn9KZEJpCaUD1JKLWrJTS3ahtITSAWrJRS3ZqSW7UFpC6QC15KKW7NSSXSgtoXSAWnJRS3YhtUgnufs0dx/Z4bLtomy2xcROnSW3lBbwRERERERERERESkU9UNfhdn/g3c48kBbwREREREREREREdr0XgMFmtr+ZVQJnAdM780CFzkIbkpCODQ+lJZQOUEsuaslOLdmF0hJKB6glF7Vkp5bsQmkJpQPUkotaslNLdqG0hNIBaslFLdmF1CJF4u4tZvYN4FGgDPilu7/cmccy904deisiIiIiIiIiIiIR0CG0IiIiIiIiIiIiAdMCnoiIiIiIiIiISMCCX8AzszFm9pqZLTGzS2Ps+KWZNZrZorgaOrTUmdlsM1tsZi+b2UUxtlSZ2fNmtiDT8oO4WjI9ZWb2VzN7OM6OTMsyM3vJzOab2dwYO/Yys/vM7NXM98w/xNRxUGYstl7WmdnFcbRker6V+Z5dZGb3mllVjC0XZTpejnpMss1tZtbHzB43szcyf/eOseXzmXFpM7ORUXTkabk+8//RQjN7wMz2irHlh5mO+Wb2mJntE1dLh/u+Y2ZuZn3jajGzK83snQ7zzNg4OjIf/2bm9cvLZvaTYnfkajGz/+0wHsvMbH6MLcPN7Nmt/y6a2TExthxhZv+X+Xf6D2bWM6KWrK/hop5383REPufmaYl8zs3TEvmcm6ulw/2Rzbl5xiWOOTfnuEQ97+YZl8jn3Twtkc67eToin3Mtx8+pUc+3BVpieZ0rJczdg72QfoO/pcABQCWwADg0ppbjgBHAogDGpR8wInO9B/B6jONiQPfM9QrgOeATMY7NvwD3AA8H8DwtA/oG0HEnMDlzvRLYK4CmMqABGBDT9vcF3gK6Zm7/Fjg3ppahwCKgG+kTC/0RGBzh9j8ytwE/AS7NXL8UuC7GlkOAg4A5wMiYx+UUoDxz/bqYx6Vnh+sXAjfH1ZL5eB3pN+Z9O6p5L8e4XAl8J6rvkzwdozL/L++RuV0d5/PT4f4bgCtiHJfHgNMy18cCc2JseQE4PnP9K8API2rJ+hou6nk3T0fkc26elsjn3Dwtkc+5uVoytyOdc/OMSxxzbq6WyOfdfM9Rh8+JZN7NMy6Rzrt5OiKfc8nxc2rU822Bllhe5+pSupfQ98A7Blji7m+6exPwG+D0OELc/UlgdRzb3pa7r3T3eZnr64HFpBck4mhxd9+QuVmRucRyZhQz6w+MA26LY/shyvx26zjgdgB3b3L3tbFGpZ0ILHX3t2NsKAe6mlk56cWzd2PqOAR41t03unsL8GfgjKg2nmNuO530wi+ZvyfG1eLui939tSi2vx0tj2WeI4Bngf4xtqzrcHNPIpp38/xb+B/AJVF1FGiJVI6O84Fr3X1L5nMaY2wBwMwM+AJwb4wtDmzd66IXEc27OVoOAp7MXH8cODOillyv4SKdd3N1xDHn5mmJfM7N0xL5nFvg9X6kc25gP3vkaol83i00LlHOu3laIp1383REPufm+Tk18te5uVriep0rpSv0Bbx9gRUdbtcT0z8WoTKzgcCRpFfx42ooy+wa3gg87u5xtfwn6RczbTFtf1sOPGZmL5rZlJgaDgBWAb+y9KHFt5nZnjG1dHQWEf0QmY27vwP8O7AcWAl84O6PxZSzCDjOzPY2s26kfztaF1PLVjXuvhLSL8SA6ph7QvQV4JE4A8zsajNbAXwJuCLGjgnAO+6+IK6GbXwjc6jbL6M4LCaHIcCnzew5M/uzmR0dU0dHnwZS7v5GjA0XA9dnvm//HZgaY8siYELm+ueJYd7d5jVcbPNuCK8lt8rTEvmcu21LnHNux5a459wsz1Fsc+42LbHOuzm+d2OZd7dpuZiY5t1tOmKZc3P8nBrLfBvQz8xSwkJfwLMsH4tl764QmVl34PfAxdv8ZjBS7t7q7sNJ/2b0GDMbGnWDmY0HGt39xai3nccn3X0EcBpwgZkdF0NDOenDhv7b3Y8EPiS9q3hszKyS9D/gv4uxoTfp377tD+wD7GlmX46jxd0Xkz406HFgFum3CmjJ+0USKzO7jPRz9Os4O9z9Mnevy3R8I46GzKLzZcS4gLiN/wYOBIaTXpy/IaaOcqA36cNjvgv8NrMnRpz+iRh/cZJxPvCtzPftt8jsHR6Tr5D+t/lF0od5NUW58VBew4XSka8ljjk3W0tcc27HFtLjENucm2VcYptzs7TENu/m+f8o8nk3S0ss826Wjljm3BB+Tg2xRUpX6At49fz96nx/4jvMLShmVkF6Uvy1u98fdw9A5tDMOcCYGDb/SWCCmS0jfaj1aDO7O4aOdu7+bubvRuAB0oeER60eqO/wG577SC/oxek0YJ67p2JsOAl4y91XuXszcD9wbFwx7n67u49w9+NIH+YV5x4yACkz6weQ+TuSw/9KgZmdA4wHvuTuofxC6R4iOvwviwNJL4QvyMy//YF5ZlYbR4y7pzIvkNuAW4ln3oX03Ht/5pCZ50nvGR7JyT2yybxVwGeB/42rIeMc0vMtpH+JE9fzg7u/6u6nuPtRpH/AXhrVtnO8hot83g3ptWSuljjm3O0Yl8jm3Cwtsc252cYlrjk3x3MUy7yb53s38nk3R0vk826O75XY5tzM9tfyt59TY32dG/PPzFLiQl/AewEYbGb7Z/baOQuYHnNT7DK/TbodWOzuP4255WOWOSuYmXUlvTDyatQd7j7V3fu7+0DS3yd/cvdY9qgCMLM9zazH1uuk34g58jMYu3sDsMLMDsp86ETglag7thHCXiDLgU+YWbfM/08nkn6PjliYWXXm7/1Iv9iLe3ymk37BR+bvh2JsCYaZjQG+B0xw940xtwzucHMCMcy7AO7+krtXu/vAzPxbT/rNqxvi6Nn6gjzjDGKYdzMeBEYDmNkQ0icQei+mFsj82+zu9TE2QPqXsMdnro8mxl9WdJh3uwCXAzdHtN1cr+EinXcDey2ZtSWOOTdPS+RzbraWuObcPOMS+Zyb53v3QSKedwv8fxTpvJunJdJ5N8/3SuRzbp6fUyN/nRvKz8ySAB7AmTTyXUi/H9TrpFfpL4ux417Su4Y3k/7H8qsxtnyK9KHEC4H5mcvYmFoOB/6aaVlERGe3K9B0AjGfhZb0e88tyFxejvl7dzgwN/McPQj0jrGlG/A+0CuA75MfkP6HcxFwF5mzlsXU8hTphdUFwIkRb/sjcxuwN/AE6Rd5TwB9Ymw5I3N9C5ACHo2xZQnp92XdOu9GdebXbC2/z3zvLgT+QPpN1mNp2eb+ZUR3Ftps43IX8FJmXKYD/WLqqATuzjxH84DRcT4/wB3A/4uiocC4fAp4MTPXPQccFWPLRaRfX74OXAtYRC1ZX8NFPe/m6Yh8zs3TEvmcm6cl8jk3V8s2nxPJnJtnXOKYc3O1RD7v5nuOiHjezTMukc67eToin3PJ8XMqMbzOzdMSy+tcXUr3Yu6hHAEkIiIiIiIiIiIi2wr9EFoREREREREREZHdmhbwREREREREREREAqYFPBERERERERERkYBpAU9ERERERERERCRgWsATEREREREREREJmBbwREREREREREREAqYFPBERERERERERkYD9f7vayOvdH+YoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_array_eva = pkl.load(open( f'./data/class_array_{EVA_CLASS}.pkl', 'rb'))\n",
    "\n",
    "parmas_eval = {\n",
    "  'num_classes':  EVA_MODEL_CLASS,\n",
    "  'input_shape': (SIZE_IMG, SIZE_IMG, 3),\n",
    "  'type_extractor': EVA_TYPE,\n",
    "  'units': EVA_UNITS,\n",
    "  'inner_layers': EVA_INNER\n",
    "}\n",
    "model_eva = AnimeClassifier(**parmas_eval)\n",
    "model_eva.build(input_shape=(None, *parmas_eval['input_shape']))\n",
    "PATH_BEST_EVA = f'./models/{EVA_TYPE}_{EVA_MODEL_CLASS}class_{EVA_UNITS}_units_{EVA_INNER}.h5'\n",
    "model_eva.load_weights(PATH_BEST_EVA)\n",
    "\n",
    "TFRECORD_PATH_EVA = f'./data/anime_data_{EVA_CLASS}.tfrecord'\n",
    "tf_record_eva = load_tfrecord_dataset(TFRECORD_PATH_EVA, SIZE_IMG)\n",
    "\n",
    "all_ds_len = sum(1 for _ in tf_record_eva)\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_test = int(all_ds_len * 0.2)\n",
    "\n",
    "tf_record_eva = tf_record_eva.shuffle(n_train + n_test, seed=SEED)\n",
    "tf_record_eva = tf_record_eva.skip(n_train).take(n_test)\n",
    "print(f'Total number of images or test: {n_test}')\n",
    "tf_record_eva = tf_record_eva.batch(32)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for images, label in tf_record_eva:\n",
    "  preds = model_eva.predict(images)\n",
    "  all_labels.extend(label)\n",
    "  all_preds.extend(np.argmax(preds, axis=1))\n",
    "del tf_record_eva\n",
    "\n",
    "confusion_matrix= tf.math.confusion_matrix(all_labels, all_preds, num_classes=EVA_CLASS)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title(f'Confusion matrix - {EVA_CLASS} classes - {EVA_TYPE} - {EVA_UNITS} units - {EVA_INNER} inner layers')\n",
    "sns.heatmap(confusion_matrix.numpy(), annot=True, cmap='Blues')\n",
    "plt.savefig(f'./metrics/confusion_matrix_{EVA_CLASS}_{EVA_TYPE}_{EVA_UNITS}_{EVA_INNER}_inner.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search vectors similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_cpu(a, b):\n",
    "  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def cosine_similarity_cpum(u, v):\n",
    "  u_dot_v = np.sum(u*v,axis = 1)\n",
    "\n",
    "  mod_u = np.sqrt(np.sum(u*u))\n",
    "  mod_v = np.sqrt(np.sum(v*v,axis = 1))\n",
    "  return 1 - u_dot_v/(mod_u*mod_v)\n",
    "\n",
    "@tf.function\n",
    "def cosine_similarity_tf(a, b):\n",
    "  return tf.tensordot(a, b, axes=1) / (tf.norm(a) * tf.norm(b))\n",
    "\n",
    "@tf.function\n",
    "def cosine_similarity_tfm(u, v):\n",
    "  u_dot_v = tf.reduce_sum(u*v,axis = 1)\n",
    "\n",
    "  mod_u = tf.sqrt(tf.reduce_sum(u*u))\n",
    "  mod_v = tf.sqrt(tf.reduce_sum(v*v,axis = 1))\n",
    "  return 1 - u_dot_v/(mod_u*mod_v)\n",
    "\n",
    "@numba.guvectorize([\"void(float64[:], float64[:], float64[:])\"], \"(n),(n)->()\", target='parallel', fastmath =True)\n",
    "def fast_cosine_gufunc(u, v, result):\n",
    "    m = u.shape[0]\n",
    "    udotv = 0\n",
    "    u_norm = 0\n",
    "    v_norm = 0\n",
    "    for i in range(m):\n",
    "        if (np.isnan(u[i])) or (np.isnan(v[i])):\n",
    "            continue\n",
    "\n",
    "        udotv += u[i] * v[i]\n",
    "        u_norm += u[i] * u[i]\n",
    "        v_norm += v[i] * v[i]\n",
    "\n",
    "    u_norm = np.sqrt(u_norm)\n",
    "    v_norm = np.sqrt(v_norm)\n",
    "\n",
    "    if (u_norm == 0) or (v_norm == 0):\n",
    "        ratio = 1.0\n",
    "    else:\n",
    "        ratio = udotv / (u_norm * v_norm)\n",
    "    result[:] = ratio\n",
    "\n",
    "@numba.jit(nopython=False, parallel=True)\n",
    "def cosine_similarity_numba(u, v):\n",
    "  uv = 0\n",
    "  uu = 0\n",
    "  vv = 0\n",
    "  \n",
    "  for i in range(u.shape[0]):\n",
    "    uv += u[i]*v[i]\n",
    "    uu += u[i]*u[i]\n",
    "    vv += v[i]*v[i]\n",
    "  cos_theta = 1\n",
    "  \n",
    "  if uu != 0 and vv != 0:\n",
    "    cos_theta = uv / np.sqrt(uu*vv)\n",
    "  return cos_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build and get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images or test: 587\n"
     ]
    }
   ],
   "source": [
    "def parse_tfrecord_vec(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'class_name': tf.io.FixedLenFeature([], tf.string),\n",
    "  })\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  y_train = x['class_name']\n",
    "  if y_train is None:\n",
    "    y_train = ''\n",
    "\n",
    "  return x_train, y_train\n",
    "\n",
    "def load_tfrecord_dataset_vec(file_pattern, size):\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  return dataset.map(lambda x: parse_tfrecord_vec(x, size))\n",
    "\n",
    "def parse_record_vec(combination):\n",
    "  item_1, item_2 = combination\n",
    "  img_1, label_1 = item_1\n",
    "  img_2, label_2 = item_2\n",
    "  return (img_1, img_2, label_1 == label_2)\n",
    "\n",
    "TFRECORD_PATH_VEC = './data/anime_data_32.tfrecord'\n",
    "tf_record_vec = load_tfrecord_dataset_vec(TFRECORD_PATH_VEC, SIZE_IMG)\n",
    "\n",
    "all_ds_len = sum(1 for _ in tf_record_vec)\n",
    "\n",
    "n_train = int(all_ds_len * 0.95)\n",
    "n_test = int(all_ds_len * 0.05)\n",
    "\n",
    "tf_record_vec = tf_record_vec.shuffle(n_train + n_test, seed=SEED)\n",
    "tf_record_vec = tf_record_vec.skip(n_train).take(n_test)\n",
    "print(f'Total number of images or test: {n_test}')\n",
    "\n",
    "all_combinations = list(itertools.combinations(tf_record_vec, 2))\n",
    "\n",
    "all_combinations = list(map(parse_record_vec, all_combinations))\n",
    "rd.shuffle(all_combinations)\n",
    "del tf_record_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(combinations, model):\n",
    "  result = []\n",
    "  for idx, item in enumerate(combinations):\n",
    "    img_1, img_2, label = item\n",
    "    pred_1, pred_2 = model.vectorize(np.array([img_1, img_2]))\n",
    "    #cos_sim = cosine_similarity_cpu(pred_1, pred_2)\n",
    "    pred_1 = np.array(pred_1)\n",
    "    pred_2 = np.array(pred_2)\n",
    "    cos_sim = cosine_similarity_numba(pred_1, pred_2)\n",
    "    result.append((cos_sim, label))\n",
    "    #print(f'{idx + 1}/{len(combinations)} - {round(((idx + 1) / len(combinations)) * 100, 2)}%')\n",
    "  return result\n",
    "\n",
    "MAX_VEC_LEN = 1024 * 6\n",
    "result = calculate_cosine_similarity(all_combinations[:MAX_VEC_LEN], model_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.70625, 'recall': 0.601063829787234, 'f1': 0.6494252873563219, 'threshold': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = ['cos_sim', 'label']\n",
    "df.label = df.label.astype(bool)\n",
    "\n",
    "current_f1 = -1\n",
    "metrics = {}\n",
    "for threshold in range(0, 100, 1):\n",
    "  pred_label = df.apply(lambda x: True if x.cos_sim > (threshold/100) else False, axis=1)\n",
    "  precision_result = sk_metrics.precision_score(df.label, pred_label) # Impact when the model predict to lot False positives\n",
    "  recall_result = sk_metrics.recall_score(df.label, pred_label) # Impact when the model predict to lot False negatives\n",
    "  f1_result = sk_metrics.f1_score(df.label, pred_label) # Impact when the model predict to lot False positives and False negatives\n",
    "  if f1_result > current_f1:\n",
    "    current_f1 = f1_result\n",
    "    metrics['precision'] = precision_result\n",
    "    metrics['recall'] = recall_result\n",
    "    metrics['f1'] = f1_result\n",
    "    metrics['threshold'] = threshold / 100\n",
    "\n",
    "print(metrics)\n",
    "json.dump(metrics, open(f'./metrics/metrics_{EVA_CLASS}_{EVA_TYPE}_{EVA_UNITS}_{EVA_INNER}_inner.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evalaute time TF vs Numba vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = load_img(\"./images/db1.jpg\", target_size=(224, 224))\n",
    "db2 = load_img(\"./images/db2.jpeg\", target_size=(224, 224))\n",
    "nr1 = load_img(\"./images/nr1.webp\", target_size=(224, 224))\n",
    "db1 = np.array(db1)\n",
    "db2 = np.array(db2)\n",
    "nr1 = np.array(nr1)\n",
    "\n",
    "images = preprocess_input(np.array([db1, db2, nr1]), mode='tf')\n",
    "\n",
    "results = model_16.predict(images)\n",
    "iterations = 1000\n",
    "\n",
    "cpu_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = results[0]\n",
    "  cpu_r.append(cosine_similarity_cpum(tg_vector, results))\n",
    "  #for reuslt in results:\n",
    "  #  cpu_r.append(cosine_similarity_cpu(reuslt, reuslt))\n",
    "end = time.time()\n",
    "print(f'Time to compute on CPU: {end - start}')\n",
    "\n",
    "numba_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = results[0]\n",
    "  numba_r.append(fast_cosine_gufunc(results, tg_vector))\n",
    "end = time.time()\n",
    "print(f'Time to compute on Numba: {end - start}')\n",
    "\n",
    "images_gpu = [tf.convert_to_tensor(result) for result in results]\n",
    "tf_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = images_gpu[0]\n",
    "  tf_r.append(cosine_similarity_tfm(tg_vector, results))\n",
    "  #for reuslt in images_gpu:\n",
    "  #  tf_r.append(cosine_similarity_tf(result, images_gpu[0]))\n",
    "end = time.time()\n",
    "print(f'Time to compute on TF: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnimeClassifier(\n",
    "  num_classes=len(class_array),\n",
    "  input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "  type_extractor='vgg',\n",
    "  units=UNITS,\n",
    "  inner_layers=1\n",
    ")\n",
    "model.build(input_shape=(None, SIZE_IMG, SIZE_IMG, 3))\n",
    "PATH_BEST = './models/vgg_16class_1024_units_aqr.h5'\n",
    "model.load_weights(PATH_BEST)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate vector and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = load_img(\"./images/db1.jpg\", target_size=(224, 224))\n",
    "db2 = load_img(\"./images/db2.jpeg\", target_size=(224, 224))\n",
    "nr1 = load_img(\"./images/nr1.webp\", target_size=(224, 224))\n",
    "db1 = np.array(db1)\n",
    "db2 = np.array(db2)\n",
    "nr1 = np.array(nr1)\n",
    "\n",
    "images = preprocess_input(np.array([db1, db2, nr1]), mode='tf')\n",
    "\n",
    "db1_v, db2_v, nr1_v = model_eva.vectorize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28875878120702914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_numba(np.array(db1_v), np.array(nr1_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6586562579012494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_numba(np.array(db1_v), np.array(db2_v))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852bc408046ca7dfc5c8f91ce764d8630d2287ca09c7fe9d1b4d9cd156705bcb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
