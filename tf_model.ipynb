{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, input_shape, type_extractor = 'vgg') -> tf.keras.Model:\n",
    "  if type_extractor == 'vgg':\n",
    "    feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'inception':\n",
    "    feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'resnet':\n",
    "    feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  else:\n",
    "    raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(feature_extractor)\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\", input_dim=1000))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\"))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "image = load_img('./images/db1.jpg', target_size=(224, 224))\n",
    "image = np.array(image)\n",
    "images = np.array([image])\n",
    "images = preprocess_input(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi modal loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model = create_model(num_classes=2, input_shape=images[0].shape, type_extractor='vgg')\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852bc408046ca7dfc5c8f91ce764d8630d2287ca09c7fe9d1b4d9cd156705bcb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tfenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
