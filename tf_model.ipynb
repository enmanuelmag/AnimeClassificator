{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import numba\n",
    "import faiss\n",
    "import hashlib\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from absl import logging\n",
    "from numba import vectorize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics as sk_metrics\n",
    "from alive_progress import alive_bar\n",
    "from notifier import Notifier, notify\n",
    "from tensorflow.keras import mixed_precision\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from utils.tf_functions import AnimeClassifier\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import visualkeras\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import pickle as pkl\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SIZE_IMG = 224 #224#224#416\n",
    "UNITS = 2048 #2048 1024 128 256 512-seq\n",
    "MAX_CLASS = 32 #1024 32 16 8\n",
    "\n",
    "DATASET_PATH = './data/animes'\n",
    "DATASET_FACES_PATH = './data/faces'\n",
    "DATASET_FACE_FOLDER = './data/moeimouto-faces'\n",
    "CLASS_ARRAY_PATH = f'./data/class_array_{MAX_CLASS}.pkl'\n",
    "CLASS_ARRAY_FACES_PATH = f'./data/class_array_faces_{MAX_CLASS}.pkl'\n",
    "CLASS_ARRAY_VEC_PATH = f'./data/class_array_vec_{MAX_CLASS}.pkl'\n",
    "\n",
    "DATASET_JSON_PATH = './data/anime_data.json'\n",
    "\n",
    "AMOUNT_TABLE_PATH = './data/anime_amount.pkl'\n",
    "AMOUNT_FACES_TABLE_PATH = './data/faces_amount.pkl'\n",
    "\n",
    "DATASET_JSON_RANK = './data/anime_rank.json'\n",
    "\n",
    "TFRECORD_PATH = f'./data/anime_data_{MAX_CLASS}.tfrecord'\n",
    "TFRECORD_FACES_PATH = f'./data/anime_faces_data_{MAX_CLASS}.tfrecord'\n",
    "\n",
    "TG_ID = \"293701727\"\n",
    "TG_TOKEN = \"1878628343:AAEFVRsqDz63ycmaLOFS7gvsG969wdAsJ0w\"\n",
    "WEBHOOK_URL = \"https://discord.com/api/webhooks/796406472459288616/PAkiGGwqe0_PwtBxXYQvOzbk78B4RQP6VWRkvpBtw6Av0sc_mDa3saaIlwVPFjOIeIbt\"\n",
    "\n",
    "#seed random seed to 42 for reproducibility\n",
    "rd.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if False:\n",
    "  #DATASET_PATH = DATASET_FACES_PATH\n",
    "  CLASS_ARRAY_PATH = CLASS_ARRAY_FACES_PATH\n",
    "  TFRECORD_PATH = TFRECORD_FACES_PATH\n",
    "  AMOUNT_TABLE_PATH = AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowload_image(url, anime_name, idx):\n",
    "  #download image from url\n",
    "  file_path = f'./data/animes/{anime_name}____{idx}.jpg' \n",
    "  if os.path.exists(file_path):\n",
    "    return\n",
    "\n",
    "  img_data = requests.get(url).content\n",
    "  with open(file_path, 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Anime images',\n",
    "  msg='Finished downloading anime images'\n",
    ")\n",
    "def get_images(data):\n",
    "  #with alive_bar(len(data)) as bar:\n",
    "  for idx_a, anime_name in enumerate(data):\n",
    "    urls = data[anime_name]\n",
    "    for idx, url in enumerate(urls):\n",
    "      if idx >= 400:\n",
    "        break\n",
    "      name_clean = re.sub(r'_+', r'_', re.sub(r'[\\W\\s]', r'_', anime_name))\n",
    "      try:\n",
    "        dowload_image(url['image'], name_clean, idx)\n",
    "      except Exception as e:\n",
    "        print(f'Error on download image {idx + 1} of {anime_name}')\n",
    "        pass\n",
    "    #bar()\n",
    "    print(f'Progress: {idx_a + 1}/{len(data)} - {round((idx_a + 1)/len(data)*100, 2)}%')\n",
    "\n",
    "def get_classes_anime(path):\n",
    "  classes = set()\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    classes.add(class_name)\n",
    "  return list(classes)\n",
    "\n",
    "def wait_for_it(driver, xpath, timeout=3):\n",
    "  try:\n",
    "    return WebDriverWait(driver, timeout).until(\n",
    "        EC.presence_of_element_located((By.XPATH, xpath))\n",
    "    )\n",
    "  except Exception as e:\n",
    "    return None\n",
    "\n",
    "def iter_post(driver):\n",
    "  anime_data = []\n",
    "\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = True\n",
    "\n",
    "  while next_button is not None:\n",
    "    if len(anime_data) > 400:\n",
    "      break\n",
    "    ul_element = wait_for_it(driver, '//ul[@id=\"post-list-posts\"]')\n",
    "    if ul_element is None:\n",
    "      next_button = wait_for_it(driver, xpath_next)\n",
    "      if next_button is not None:\n",
    "        next_button.click()\n",
    "        time.sleep(1)\n",
    "      continue\n",
    "    for i, li_element in enumerate(ul_element.find_elements(By.TAG_NAME, 'li')):\n",
    "      a_video = li_element.find_element(By.XPATH, './a').get_attribute('href')\n",
    "      a_image = li_element.find_element(By.XPATH, './div/a/img').get_attribute('src')\n",
    "      anime_data.append({\n",
    "        'video': a_video,\n",
    "        'image': a_image\n",
    "      })\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "    if next_button is not None:\n",
    "      next_button.click()\n",
    "      time.sleep(rd.randint(1, 2))\n",
    "  return anime_data\n",
    "\n",
    "def get_images_links(url, driver, anime_name):\n",
    "  url_search = url + anime_name\n",
    "  driver.get(url_search)\n",
    "  return iter_post(driver)\n",
    "\n",
    "def get_names(driver):\n",
    "  names = []\n",
    "  xpath_next = '//a[@class=\"next_page\"]'\n",
    "  next_button = wait_for_it(driver, xpath_next)\n",
    "  \n",
    "  while next_button is not None:\n",
    "    for tr_element in driver.find_elements(By.XPATH, '//table[@class=\"highlightable\"]/tbody/tr'):\n",
    "      try:\n",
    "        amount_post = tr_element.find_element(By.XPATH, './td[1]').text\n",
    "        amount_post = int(amount_post)\n",
    "        if amount_post >= 10:\n",
    "          a_name = tr_element.find_element(By.XPATH, './td[2]/a[2]' ).text\n",
    "          names.append(a_name)\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    next_button.click()\n",
    "    time.sleep(rd.randint(1, 2))\n",
    "    next_button = wait_for_it(driver, xpath_next)\n",
    "  return names\n",
    "\n",
    "def get_score(anime_name, driver):\n",
    "  url_search = f'https://myanimelist.net/anime.php?cat=anime&q={anime_name}'\n",
    "  driver.get(url_search)\n",
    "  score = 0\n",
    "  for filename in os.listdir(path):\n",
    "    class_name, _ = filename.split('____')\n",
    "    score += 1\n",
    "  return score\n",
    "\n",
    "def relevant_anime(anime_name, df_anime, amount_table, threshold=350, rank=True):\n",
    "  \n",
    "  if amount_table.get(anime_name, 0) <= threshold:\n",
    "    return False\n",
    "\n",
    "  if not rank:\n",
    "    return True\n",
    "\n",
    "  anime_name = re.sub(r'_', r' ', anime_name)\n",
    "  df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "\n",
    "  if df_result.empty:\n",
    "    anime_name = ' '.join(anime_name.split(' ')[:3])\n",
    "    df_result = df_anime[df_anime['name'].str.contains(anime_name)]\n",
    "  return not df_result.empty\n",
    "\n",
    "def amount_anime_table(datapath):\n",
    "  dic = {}\n",
    "  for filename in os.listdir(datapath):\n",
    "    class_name, _ = filename.split('____')\n",
    "    dic[class_name] = dic.get(class_name, 0) + 1\n",
    "  return dic\n",
    "\n",
    "def detect(filename, cascade_file):\n",
    "  if not os.path.isfile(cascade_file):\n",
    "    raise RuntimeError(\"%s: not found\" % cascade_file)\n",
    "\n",
    "  cascade = cv2.CascadeClassifier(cascade_file)\n",
    "  image = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "  #src = cv2.cuda_GpuMat()\n",
    "  #src.upload(image)\n",
    "\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.equalizeHist(gray)\n",
    "\n",
    "  faces = cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor = 1.1,\n",
    "    minNeighbors = 5,\n",
    "    minSize = (24, 24)\n",
    "  )\n",
    "\n",
    "  new_images = []\n",
    "  for (x, y, w, h) in faces:\n",
    "    new_images.append(image[y:y+h, x:x+w])\n",
    "  #clahe = cv2.cuda.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "  #dst = clahe.apply(src, cv2.cuda_Stream.Null())\n",
    "  #result = dst.download()\n",
    "  return new_images\n",
    "\n",
    "def extract_faces(datapath):\n",
    "  faces_amount = 0\n",
    "  for filename in os.listdir(datapath):\n",
    "    class_name, _ = filename.split('____')\n",
    "    new_images = []\n",
    "    try:\n",
    "      new_images = detect(datapath + '/' + filename, './data/haar/lbpcascade_animeface.xml')\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      pass\n",
    "    if len(new_images) > 0:\n",
    "      for idx, img in enumerate(new_images):\n",
    "        new_face_name = f'./data/faces/{class_name}____{idx}.jpg'\n",
    "        try:\n",
    "          if not os.path.exists(new_face_name):\n",
    "            cv2.imwrite(new_face_name, img)\n",
    "            faces_amount += 1\n",
    "        except:\n",
    "          pass\n",
    "  print(f'Faces amount: {faces_amount}')\n",
    "\n",
    "def parse_face_dataset(face_path, out_path):\n",
    "  for char_name in os.listdir(face_path):\n",
    "    if char_name == '.DS_Store':\n",
    "      continue\n",
    "    for idx, filename in enumerate(os.listdir(face_path + '/' + char_name)):\n",
    "      if filename == '.DS_Store':\n",
    "        continue\n",
    "      ext = os.path.splitext(filename)[1]\n",
    "      if ext == '.csv':\n",
    "        continue\n",
    "      clean_char_name = char_name.split('_')[1]\n",
    "      new_filename = f'{clean_char_name}____{idx}.{ext}'\n",
    "      shutil.copy(face_path + '/' + char_name + '/' + filename, out_path + '/' + new_filename)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anime images\n",
    "anime_data = json.load(open(DATASET_JSON_PATH))\n",
    "get_images(anime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only faces with OpenCV\n",
    "extract_faces(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse dataset faces\n",
    "parse_face_dataset(DATASET_FACE_FOLDER, DATASET_FACES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amount of images per anime\n",
    "amount = amount_anime_table(DATASET_PATH) #DATASET_PATH #DATASET_FACES_PATH\n",
    "pkl.dump(amount, open(AMOUNT_TABLE_PATH, 'wb')) #AMOUNT_TABLE_PATH #AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FACES Calculate the amount of images per anime\n",
    "amount = amount_anime_table(DATASET_FACES_PATH) #DATASET_PATH #DATASET_FACES_PATH\n",
    "pkl.dump(amount, open(AMOUNT_TABLE_PATH, 'wb')) #AMOUNT_TABLE_PATH #AMOUNT_FACES_TABLE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/df_anime_rank.pkl')\n",
    "\n",
    "amount_table = pkl.load(open(AMOUNT_TABLE_PATH, 'rb'))\n",
    "all_class_array = get_classes_anime(DATASET_PATH)\n",
    "\n",
    "class_array = set()\n",
    "for anime_name in all_class_array:\n",
    "  if relevant_anime(anime_name, df, amount_table, threshold=100, rank=True):\n",
    "    class_array.add((anime_name, amount_table[anime_name]))\n",
    "\n",
    "class_array = list(class_array)\n",
    "class_array.sort(key=lambda x: x[1], reverse=True)\n",
    "class_array = class_array[:MAX_CLASS]\n",
    "class_array = [x[0] for x in class_array]\n",
    "\n",
    "mean_keyframes = np.mean([amount_table[x] for x in class_array])\n",
    "print(f'All classes: {len(all_class_array)} - Filtered {len(class_array)} - Mean keyframes: {int(mean_keyframes)}')\n",
    "#pkl.dump(class_array, open(CLASS_ARRAY_PATH, 'wb'))\n",
    "del all_class_array\n",
    "del mean_keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for faces\n",
    "all_class_array = get_classes_anime(DATASET_FACES_PATH)\n",
    "amount_table = pkl.load(open(AMOUNT_TABLE_PATH, 'rb'))\n",
    "\n",
    "class_array = set()\n",
    "for name in all_class_array:\n",
    "  class_array.add((name, amount_table[name]))\n",
    "\n",
    "class_array = list(class_array)\n",
    "class_array.sort(key=lambda x: x[1], reverse=True)\n",
    "class_array = class_array[:MAX_CLASS]\n",
    "class_array = [x[0] for x in class_array]\n",
    "\n",
    "mean_keyframes = np.mean([amount_table[x] for x in class_array])\n",
    "print(f'All classes: {len(all_class_array)} - Filtered {len(class_array)} - Mean keyframes: {int(mean_keyframes)}')\n",
    "#pkl.dump(class_array, open(CLASS_ARRAY_PATH, 'wb'))\n",
    "del all_class_array\n",
    "del mean_keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CLASS_ARRAY_PATH)\n",
    "class_array = pkl.load(open(CLASS_ARRAY_PATH, 'rb'))\n",
    "class_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_id(class_name):\n",
    "  return class_array.index(class_name)\n",
    "\n",
    "def build_example(path_file, class_name):\n",
    "  img_array = open(path_file, 'rb').read()\n",
    "  \n",
    "  #img = load_img(path_file, target_size=(SIZE_IMG, SIZE_IMG))\n",
    "  #img_array = np.array(img)\n",
    "  #img_array = preprocess_input(img_array, mode='tf')\n",
    "  #key = hashlib.sha256(img_array).hexdigest()\n",
    "  example = tf.train.Example(\n",
    "    features=tf.train.Features(feature={\n",
    "    #'key': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf-8')])),\n",
    "    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array])),\n",
    "    #'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_array.tobytes()])),\n",
    "    'class_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[get_class_id(class_name)])),\n",
    "    'class_name': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_name.encode('utf-8')])),\n",
    "    'filepath': tf.train.Feature(bytes_list=tf.train.BytesList(value=[path_file.encode('utf-8')]))\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "def create_tfrecord(data_path, withe_list, path_tfrecord):\n",
    "  files = os.listdir(data_path)\n",
    "  writer = tf.io.TFRecordWriter(path_tfrecord)\n",
    "  \n",
    "  print('Started creating tfrecord')\n",
    "  for idx, filename in enumerate(files):\n",
    "    class_name, _ = filename.split('____')\n",
    "  \n",
    "    if class_name in withe_list:\n",
    "      path_file = os.path.join(data_path, filename)\n",
    "      tf_example = build_example(path_file, class_name)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "  print('Finished creating tfrecord')\n",
    "  writer.close()\n",
    "\n",
    "def parse_tfrecord(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  #class_id = tf.sparse.to_dense(x['class_id'], default_value=-1)\n",
    "  class_id = x['class_id']\n",
    "  if class_id is None:\n",
    "    class_id = -1\n",
    "\n",
    "  labels = tf.cast(class_id, tf.int64)\n",
    "  y_train = labels\n",
    "  #y_train = tf.stack([ labels ], axis=1)\n",
    "  return x_train, y_train\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, size):\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  return dataset.map(lambda x: parse_tfrecord(x, size))\n",
    "\n",
    "def create_model(num_classes, input_shape, units, type_extractor = 'vgg') -> tf.keras.Model:\n",
    "  if type_extractor == 'vgg':\n",
    "    feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'inception':\n",
    "    feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  elif type_extractor == 'resnet':\n",
    "    feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  else:\n",
    "    raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  #model.add(tf.keras.layers.Input(input_shape, name='input'))\n",
    "  model.add(feature_extractor)\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  #new\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
    "  return model\n",
    "\n",
    "\n",
    "class AnimeClassifier(tf.keras.Model):\n",
    "  def __init__(self, num_classes, input_shape, units=1024, inner_layers=12, type_extractor='vgg'):\n",
    "    assert type_extractor in ['vgg', 'inception', 'resnet']\n",
    "    assert inner_layers >= 1\n",
    "    assert num_classes >= 8\n",
    "    assert len(input_shape) == 3\n",
    "    assert units >= 64\n",
    "\n",
    "    super(AnimeClassifier, self).__init__(name='AnimeClassifier')\n",
    "\n",
    "    self.units = units\n",
    "    self.in_layer = tf.keras.layers.Input(input_shape, name='input')\n",
    "\n",
    "    if type_extractor == 'vgg':\n",
    "      feature_extractor = VGG19(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    elif type_extractor == 'inception':\n",
    "      feature_extractor = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    elif type_extractor == 'resnet':\n",
    "      feature_extractor = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape, input_tensor=self.in_layer)\n",
    "    else:\n",
    "      raise ValueError('type_extractor must be vgg, inception or resnet')\n",
    "\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.global_average_pooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.hidden_mlp = []\n",
    "    for i in range(inner_layers):\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dense(units,activation=tf.nn.relu))\n",
    "      self.hidden_mlp.append(tf.keras.layers.Dropout(0.5, seed=SEED))\n",
    "\n",
    "    self.out_layer = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs, training=None, mask=None):\n",
    "    x = self.feature_extractor(inputs, training=training)\n",
    "    x = self.global_average_pooling(x)\n",
    "    x = self.flatten(x, training=training)\n",
    "    for layer in self.hidden_mlp:\n",
    "      x = layer(x, training=training)\n",
    "    return self.out_layer(x, training=training)\n",
    "\n",
    "  def predict_classes(self, x):\n",
    "    return tf.argmax(self(x), axis=1)\n",
    "\n",
    "  def vectorize(self, x, flatten=True):\n",
    "    x = self.feature_extractor(x)\n",
    "    x = self.global_average_pooling(x)\n",
    "    if flatten:\n",
    "      return self.flatten(x)\n",
    "    return x\n",
    "\n",
    "@notify(\n",
    "  chat_id=TG_ID,\n",
    "  api_token=TG_TOKEN,\n",
    "  title='Train model',\n",
    "  msg='Training has finished'\n",
    ")\n",
    "def train(model, train_ds, val_ds, units, epochs=15, mode='fit', type_model='vgg', save_weights_only=False, inner_ly=1):\n",
    "  logdir = \"logs/scalars/\" + time.strftime(\"%Y%m%d_%H-%M-%S\")\n",
    "  if mode == 'eager_tf':\n",
    "    avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "    avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "      for batch, (images, labels) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "          outputs = model(images, training=True)\n",
    "          regularization_loss = tf.reduce_sum(model.losses)\n",
    "          pred_loss = []\n",
    "          for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "          total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        print(\"{}_train_{}, {}, {}\".format(\n",
    "          epoch, batch, total_loss.numpy(),\n",
    "          list(map(lambda x: np.sum(x.numpy()), pred_loss))\n",
    "        ))\n",
    "        avg_loss.update_state(total_loss)\n",
    "  elif mode == 'fit':\n",
    "    callbacks = [\n",
    "      ReduceLROnPlateau(verbose=1),\n",
    "      EarlyStopping(patience=10, verbose=1),\n",
    "      ModelCheckpoint(\n",
    "        f'checkpoints/{type_model}_{MAX_CLASS}class_{units}_units_{inner_ly}_faces_checkpoint.h5', \n",
    "        verbose=1,\n",
    "        monitor='accuracy',\n",
    "        save_freq='epoch',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=save_weights_only,\n",
    "      ),\n",
    "      TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(\n",
    "      train_ds,\n",
    "      epochs=epochs,\n",
    "      callbacks=callbacks,\n",
    "      validation_data=val_ds\n",
    "    )\n",
    "    end_time = time.time() - start_time\n",
    "    print(f'Total Training Time: {end_time} seconds')\n",
    "\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "  'image': tf.io.FixedLenFeature([], tf.string),\n",
    "  'class_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "if False:\n",
    "  class_array = pkl.load(open(CLASS_ARRAY_PATH, 'rb'))\n",
    "  if os.path.exists(TFRECORD_PATH):\n",
    "    os.remove(TFRECORD_PATH)\n",
    "  #DATASET_PATH DATASET_FACES_PATH\n",
    "  create_tfrecord(DATASET_FACES_PATH, class_array, TFRECORD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_record = load_tfrecord_dataset(TFRECORD_PATH, SIZE_IMG) #TFRECORD_PATH\n",
    "# 32: 11753\n",
    "all_ds_len = sum(1 for _ in tf_record)\n",
    "print(f'Total number of images: {all_ds_len}')\n",
    "\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_valid = int(all_ds_len * 0.1)\n",
    "n_test = all_ds_len - n_train - n_valid\n",
    "\n",
    "tf_record = tf_record.shuffle(n_train + n_valid + n_test, seed=SEED)\n",
    "train_ds = tf_record.take(n_train)\n",
    "valid_ds = tf_record.skip(n_train).take(n_valid)\n",
    "test_ds = tf_record.skip(n_train + n_valid).take(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000050, clipnorm=1.0) #0.000025 0.00001\n",
    "\n",
    "model = None\n",
    "vanilla_model = False\n",
    "INNER_LY = 3\n",
    "EXTRACTOR_MODEL = 'resnet' #vgg inception resnet\n",
    "class_array = pkl.load(open(CLASS_ARRAY_PATH, 'rb'))\n",
    "\n",
    "if vanilla_model:\n",
    "  model = create_model(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor='vgg',\n",
    "    units=UNITS\n",
    "  )\n",
    "else:\n",
    "  model = AnimeClassifier(\n",
    "    num_classes=len(class_array),\n",
    "    input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "    type_extractor=EXTRACTOR_MODEL,\n",
    "    units=UNITS,\n",
    "    inner_layers=INNER_LY\n",
    "  )\n",
    "  model.build(input_shape=(None, SIZE_IMG, SIZE_IMG, 3))\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "train(\n",
    "  model=model,\n",
    "  epochs=200,\n",
    "  units=UNITS,\n",
    "  val_ds=valid_ds.batch(32),\n",
    "  train_ds=train_ds.batch(32),\n",
    "  save_weights_only=False if vanilla_model else True,\n",
    "  mode='fit', type_model=EXTRACTOR_MODEL, inner_ly=INNER_LY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVA_INNER = 3\n",
    "EVA_CLASS = 32\n",
    "EVA_UNITS = 1024 #2048 1024\n",
    "EVA_TYPE  = 'resnet'\n",
    "EVA_MODEL_CLASS = 32\n",
    "MAX_VEC_LEN = 1024 * 8\n",
    "#Shape of vector result: (2048,)\n",
    "USE_FACES = False\n",
    "SUFIX = '_faces' if USE_FACES else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_eva_path = f'./data/class_array{\"_faces\" if USE_FACES else \"\"}_{EVA_CLASS}.pkl'\n",
    "class_array_eva = pkl.load(open(class_eva_path, 'rb'))\n",
    "\n",
    "parmas_eval = {\n",
    "  'num_classes':  EVA_MODEL_CLASS,\n",
    "  'input_shape': (SIZE_IMG, SIZE_IMG, 3),\n",
    "  'type_extractor': EVA_TYPE,\n",
    "  'units': EVA_UNITS,\n",
    "  'inner_layers': EVA_INNER\n",
    "}\n",
    "model_eva = AnimeClassifier(**parmas_eval)\n",
    "model_eva.build(input_shape=(None, *parmas_eval['input_shape']))\n",
    "PATH_BEST_EVA = f'./models/{EVA_TYPE}_{EVA_MODEL_CLASS}class_{EVA_UNITS}_units_{EVA_INNER}{SUFIX}.h5'\n",
    "model_eva.load_weights(PATH_BEST_EVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f'Model_{EVA_CLASS}_{EVA_TYPE}_{EVA_UNITS}_{EVA_INNER}_inner{SUFIX}.png'\n",
    "visualkeras.graph_view(model_eva, to_file=f'./images/{MODEL_NAME}').show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORD_PATH_EVA = f'./data/anime{\"_faces\" if USE_FACES else \"\"}_data_{EVA_CLASS}.tfrecord'\n",
    "tf_record_eva = load_tfrecord_dataset(TFRECORD_PATH_EVA, SIZE_IMG)\n",
    "\n",
    "all_ds_len = sum(1 for _ in tf_record_eva)\n",
    "n_train = int(all_ds_len * 0.8)\n",
    "n_test = int(all_ds_len * 0.2)\n",
    "\n",
    "tf_record_eva = tf_record_eva.shuffle(n_train + n_test, seed=SEED)\n",
    "tf_record_eva = tf_record_eva.skip(n_train).take(n_test)\n",
    "print(f'Total number of images or test: {n_test}')\n",
    "tf_record_eva = tf_record_eva.batch(32)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for images, label in tf_record_eva:\n",
    "  preds = model_eva.predict(images)\n",
    "  all_labels.extend(label)\n",
    "  all_preds.extend(np.argmax(preds, axis=1))\n",
    "del tf_record_eva\n",
    "\n",
    "confusion_matrix= tf.math.confusion_matrix(all_labels, all_preds, num_classes=EVA_CLASS)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title(f'Confusion matrix - {EVA_CLASS} classes - {EVA_TYPE} - {EVA_UNITS} units - {EVA_INNER} inner layers - {\"Faces\" if USE_FACES else \"\"}')\n",
    "sns.heatmap(confusion_matrix.numpy(), annot=True, cmap='Blues')\n",
    "plt.savefig(f'./metrics/confusion_matrix_{EVA_CLASS}_{EVA_TYPE}_{EVA_UNITS}_{EVA_INNER}_inner{SUFIX}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Search vectors similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_cpu(a, b):\n",
    "  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def cosine_similarity_cpum(u, v):\n",
    "  u_dot_v = np.sum(u*v,axis = 1)\n",
    "\n",
    "  mod_u = np.sqrt(np.sum(u*u))\n",
    "  mod_v = np.sqrt(np.sum(v*v,axis = 1))\n",
    "  return 1 - u_dot_v/(mod_u*mod_v)\n",
    "\n",
    "@tf.function\n",
    "def cosine_similarity_tf(a, b):\n",
    "  return tf.tensordot(a, b, axes=1) / (tf.norm(a) * tf.norm(b))\n",
    "\n",
    "@tf.function\n",
    "def cosine_similarity_tfm(u, v):\n",
    "  u_dot_v = tf.reduce_sum(u*v,axis = 1)\n",
    "\n",
    "  mod_u = tf.sqrt(tf.reduce_sum(u*u))\n",
    "  mod_v = tf.sqrt(tf.reduce_sum(v*v,axis = 1))\n",
    "  return 1 - u_dot_v/(mod_u*mod_v)\n",
    "\n",
    "@numba.guvectorize([\"void(float64[:], float64[:], float64[:])\"], \"(n),(n)->()\", target='parallel', fastmath =True)\n",
    "def fast_cosine_gufunc(u, v, result):\n",
    "    m = u.shape[0]\n",
    "    udotv = 0\n",
    "    u_norm = 0\n",
    "    v_norm = 0\n",
    "    for i in range(m):\n",
    "        if (np.isnan(u[i])) or (np.isnan(v[i])):\n",
    "            continue\n",
    "\n",
    "        udotv += u[i] * v[i]\n",
    "        u_norm += u[i] * u[i]\n",
    "        v_norm += v[i] * v[i]\n",
    "\n",
    "    u_norm = np.sqrt(u_norm)\n",
    "    v_norm = np.sqrt(v_norm)\n",
    "\n",
    "    if (u_norm == 0) or (v_norm == 0):\n",
    "        ratio = 1.0\n",
    "    else:\n",
    "        ratio = udotv / (u_norm * v_norm)\n",
    "    result[:] = ratio\n",
    "\n",
    "@numba.jit(nopython=False, parallel=True)\n",
    "def cosine_similarity_numba(u, v):\n",
    "  uv = 0\n",
    "  uu = 0\n",
    "  vv = 0\n",
    "  \n",
    "  for i in range(u.shape[0]):\n",
    "    uv += u[i]*v[i]\n",
    "    uu += u[i]*u[i]\n",
    "    vv += v[i]*v[i]\n",
    "  cos_theta = 1\n",
    "  \n",
    "  if uu != 0 and vv != 0:\n",
    "    cos_theta = uv / np.sqrt(uu*vv)\n",
    "  return cos_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build and get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_vec(tfrecord, size):\n",
    "  x = tf.io.parse_single_example(tfrecord, {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'class_name': tf.io.FixedLenFeature([], tf.string),\n",
    "  })\n",
    "  x_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "  x_train = tf.image.resize(x_train, (size, size))\n",
    "  x_train = preprocess_input(x_train, mode='tf')\n",
    "\n",
    "  y_train = x['class_name']\n",
    "  if y_train is None:\n",
    "    y_train = ''\n",
    "\n",
    "  return x_train, y_train\n",
    "\n",
    "def load_tfrecord_dataset_vec(file_pattern, size):\n",
    "  files = tf.data.Dataset.list_files(file_pattern)\n",
    "  dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "  return dataset.map(lambda x: parse_tfrecord_vec(x, size))\n",
    "\n",
    "def parse_record_vec(combination):\n",
    "  item_1, item_2 = combination\n",
    "  img_1, label_1 = item_1\n",
    "  img_2, label_2 = item_2\n",
    "  return (img_1, img_2, label_1 == label_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFRECORD_PATH_VEC = './data/anime_data_32.tfrecord'\n",
    "TFRECORD_PATH_VEC = './data/anime_faces_data_32.tfrecord'\n",
    "tf_record_vec = load_tfrecord_dataset_vec(TFRECORD_PATH_VEC, SIZE_IMG)\n",
    "\n",
    "all_ds_len = sum(1 for _ in tf_record_vec)\n",
    "\n",
    "n_train = int(all_ds_len * 0.95)\n",
    "n_test = int(all_ds_len * 0.05)\n",
    "\n",
    "tf_record_vec = tf_record_vec.shuffle(n_train + n_test, seed=SEED)\n",
    "tf_record_vec = tf_record_vec.skip(n_train).take(n_test)\n",
    "print(f'Total number of images or test: {n_test}')\n",
    "\n",
    "all_combinations = list(itertools.combinations(tf_record_vec, 2))\n",
    "\n",
    "all_combinations = list(map(parse_record_vec, all_combinations))\n",
    "rd.shuffle(all_combinations)\n",
    "del tf_record_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(combinations, model):\n",
    "  result = []\n",
    "  for idx, item in enumerate(combinations):\n",
    "    img_1, img_2, label = item\n",
    "    pred_1, pred_2 = model.vectorize(np.array([img_1, img_2]))\n",
    "    #cos_sim = cosine_similarity_cpu(pred_1, pred_2)\n",
    "    pred_1 = np.array(pred_1)\n",
    "    pred_2 = np.array(pred_2)\n",
    "    cos_sim = cosine_similarity_numba(pred_1, pred_2)\n",
    "    result.append((cos_sim, label))\n",
    "    #print(f'{idx + 1}/{len(combinations)} - {round(((idx + 1) / len(combinations)) * 100, 2)}%')\n",
    "  return result\n",
    "\n",
    "result = calculate_cosine_similarity(all_combinations[:MAX_VEC_LEN], model_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = ['cos_sim', 'label']\n",
    "df.label = df.label.astype(bool)\n",
    "\n",
    "current_f1 = -1\n",
    "metrics = {}\n",
    "for threshold in range(0, 100, 1):\n",
    "  pred_label = df.apply(lambda x: True if x.cos_sim > (threshold/100) else False, axis=1)\n",
    "  precision_result = sk_metrics.precision_score(df.label, pred_label) # Impact when the model predict to lot False positives\n",
    "  recall_result = sk_metrics.recall_score(df.label, pred_label) # Impact when the model predict to lot False negatives\n",
    "  f1_result = sk_metrics.f1_score(df.label, pred_label) # Impact when the model predict to lot False positives and False negatives\n",
    "  if f1_result > current_f1:\n",
    "    current_f1 = f1_result\n",
    "    metrics['precision'] = precision_result\n",
    "    metrics['recall'] = recall_result\n",
    "    metrics['f1'] = f1_result\n",
    "    metrics['threshold'] = threshold / 100\n",
    "\n",
    "print(metrics)\n",
    "json.dump(metrics, open(f'./metrics/metrics_{EVA_CLASS}_{EVA_TYPE}_{EVA_UNITS}_{EVA_INNER}_inner{SUFIX}.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create embeddings with Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFRECORD_PATH_VEC = './data/anime_data_32.tfrecord'\n",
    "TFRECORD_PATH_VEC = './data/anime_faces_data_32.tfrecord'\n",
    "tf_record_vec = load_tfrecord_dataset_vec(TFRECORD_PATH_VEC, SIZE_IMG)\n",
    "\n",
    "all_ds_len = tf_record_vec.reduce(0, lambda x,_: x+1).numpy()\n",
    "LEN_TF_RECORD = all_ds_len if True else MAX_VEC_LEN\n",
    "print(LEN_TF_RECORD)\n",
    "\n",
    "tf_record_vec = tf_record_vec.take(LEN_TF_RECORD)\n",
    "#tf_record_vec = tf_record_vec.shuffle(LEN_TF_RECORD, seed=SEED)\n",
    "\n",
    "data_image = []\n",
    "BATCH = 64\n",
    "for idx, batch in enumerate(tf_record_vec.batch(BATCH)):\n",
    "  imgs, class_names = batch\n",
    "  pred_vecs = model_eva.vectorize(imgs)\n",
    "  pred_vecs = pred_vecs.numpy().astype('float32')\n",
    "  class_names = class_names.numpy().astype('str')\n",
    "  data_image.extend(list(zip(pred_vecs, class_names)))\n",
    "  print(f'{idx + 1}/{LEN_TF_RECORD // BATCH} - {round(((idx + 1) / (LEN_TF_RECORD // BATCH)) * 100, 2)}%')\n",
    "  #img, class_name = item\n",
    "  #pred_vec = model_eva.vectorize(np.array([img]))[0]\n",
    "  #data_item = (\n",
    "  #  pred_vec.numpy().astype('float32'),\n",
    "  #  class_name.numpy().decode('utf-8')\n",
    "  #)\n",
    "  #data_image.append(data_item)\n",
    "  #print(f'{idx + 1}/{LEN_TF_RECORD} - {round(((idx + 1) / LEN_TF_RECORD) * 100, 2)}%')\n",
    "\n",
    "pkl.dump(np.array(data_image), open(f'./data/data_image_{all_ds_len}{SUFIX}.pkl', 'wb'))\n",
    "del data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = pkl.load(open(f'./data/data_image_{4007}{SUFIX}.pkl', 'rb'))\n",
    "vector_images = np.array(list(data_image[:, 0])) \n",
    "\n",
    "d = 2048 #Shape of vector result: (2048,)\n",
    "nb = 4007\n",
    "res = faiss.StandardGpuResources()  # use a single GPU\n",
    "\n",
    "# build a flat (CPU) index\n",
    "index_flat = faiss.IndexFlatL2(d)\n",
    "# make it into a gpu index\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
    "gpu_index_flat.add(vector_images)\n",
    "print(f'Vectors {gpu_index_flat.ntotal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20 # we want to see 4 nearest neighbors\n",
    "idx_search = 670\n",
    "print(f'Target: ', data_image[idx_search][1])\n",
    "\n",
    "dimension_vec, ids_result = gpu_index_flat.search(vector_images[idx_search: idx_search + 1], k) # actual search\n",
    "\n",
    "current_id = 1\n",
    "result = {}\n",
    "for idx, id_v in enumerate(ids_result[0]):\n",
    "  class_name = data_image[id_v][1]\n",
    "  if class_name not in result:\n",
    "    result[class_name] = 0\n",
    "  result[class_name] += 1\n",
    "\n",
    "print(f'\\nResult: {result}')\n",
    "print(f'\\nOnly name: {\", \".join(list(result.keys()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20 # we want to see 4 nearest neighbors\n",
    "idx_search = 670\n",
    "izumi = load_img(\"./images/unnamed.jpg\", target_size=(224, 224))\n",
    "izumi_2 = load_img(\"./images/izumi____98..png\", target_size=(224, 224))\n",
    "miyamura = load_img(\"./images/miyamura____127..png\", target_size=(224, 224))\n",
    "aika = load_img(\"./images/aika____10..png\", target_size=(224, 224))\n",
    "\n",
    "aika = np.array(aika)\n",
    "izumi = np.array(izumi)\n",
    "miyamura = np.array(miyamura)\n",
    "izumi_2 = np.array(izumi_2)\n",
    "\n",
    "images = preprocess_input(np.array([izumi, izumi_2, miyamura, aika]), mode='tf')\n",
    "\n",
    "result = model_eva.vectorize(images)\n",
    "result = result.numpy().astype('float32')\n",
    "\n",
    "dimension_vec, ids_result = gpu_index_flat.search(result[0:1], k) # actual search\n",
    "\n",
    "current_id = 1\n",
    "result = {}\n",
    "for idx, id_v in enumerate(ids_result[0]):\n",
    "  class_name = data_image[id_v][1]\n",
    "  if class_name not in result:\n",
    "    result[class_name] = 0\n",
    "  result[class_name] += 1\n",
    "\n",
    "print(f'\\nResult: {result}')\n",
    "print(f'\\nOnly name: {\", \".join(list(result.keys()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evalaute time TF vs Numba vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = load_img(\"./images/db1.jpg\", target_size=(224, 224))\n",
    "db2 = load_img(\"./images/db2.jpeg\", target_size=(224, 224))\n",
    "nr1 = load_img(\"./images/nr1.webp\", target_size=(224, 224))\n",
    "db1 = np.array(db1)\n",
    "db2 = np.array(db2)\n",
    "nr1 = np.array(nr1)\n",
    "\n",
    "images = preprocess_input(np.array([db1, db2, nr1]), mode='tf')\n",
    "\n",
    "results = model_16.predict(images)\n",
    "iterations = 1000\n",
    "\n",
    "cpu_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = results[0]\n",
    "  cpu_r.append(cosine_similarity_cpum(tg_vector, results))\n",
    "  #for reuslt in results:\n",
    "  #  cpu_r.append(cosine_similarity_cpu(reuslt, reuslt))\n",
    "end = time.time()\n",
    "print(f'Time to compute on CPU: {end - start}')\n",
    "\n",
    "numba_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = results[0]\n",
    "  numba_r.append(fast_cosine_gufunc(results, tg_vector))\n",
    "end = time.time()\n",
    "print(f'Time to compute on Numba: {end - start}')\n",
    "\n",
    "images_gpu = [tf.convert_to_tensor(result) for result in results]\n",
    "tf_r = []\n",
    "start = time.time()\n",
    "for i in range(iterations):\n",
    "  tg_vector = images_gpu[0]\n",
    "  tf_r.append(cosine_similarity_tfm(tg_vector, results))\n",
    "  #for reuslt in images_gpu:\n",
    "  #  tf_r.append(cosine_similarity_tf(result, images_gpu[0]))\n",
    "end = time.time()\n",
    "print(f'Time to compute on TF: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnimeClassifier(\n",
    "  num_classes=len(class_array),\n",
    "  input_shape=(SIZE_IMG, SIZE_IMG, 3),\n",
    "  type_extractor='vgg',\n",
    "  units=UNITS,\n",
    "  inner_layers=1\n",
    ")\n",
    "model.build(input_shape=(None, SIZE_IMG, SIZE_IMG, 3))\n",
    "PATH_BEST = './models/vgg_16class_1024_units_aqr.h5'\n",
    "model.load_weights(PATH_BEST)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate vector and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = load_img(\"./images/db1.jpg\", target_size=(224, 224))\n",
    "db2 = load_img(\"./images/db2.jpeg\", target_size=(224, 224))\n",
    "nr1 = load_img(\"./images/nr1.webp\", target_size=(224, 224))\n",
    "izumi = load_img(\"./images/izumi____110..png\", target_size=(224, 224))\n",
    "izumi_2 = load_img(\"./images/izumi____98..png\", target_size=(224, 224))\n",
    "miyamura = load_img(\"./images/miyamura____127..png\", target_size=(224, 224))\n",
    "aika = load_img(\"./images/aika____10..png\", target_size=(224, 224))\n",
    "aika_ext = load_img(\"./images/Aika_Teen.webp\", target_size=(224, 224))\n",
    "\n",
    "aika = np.array(aika)\n",
    "izumi = np.array(izumi)\n",
    "miyamura = np.array(miyamura)\n",
    "izumi_2 = np.array(izumi_2)\n",
    "aika_ext = np.array(aika_ext)\n",
    "\n",
    "images = preprocess_input(np.array([izumi, izumi_2, miyamura, aika, aika_ext]), mode='tf')\n",
    "\n",
    "izumi_v, izumi_2_v, miyamura_v, aika_v, aika_ext_v= model_eva.vectorize(images)\n",
    "print(f'Shape of vectors: {izumi_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_numba(np.array(aika_ext_v), np.array(aika_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_numba(np.array(db1_v), np.array(db2_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgg = pd.read_csv('./data/run-scalars_best_32_class_1024_train-tag-epoch_accuracy.csv')\n",
    "df_res = pd.read_csv('./data/run-scalars_besT_32_class_1024_resnet_train-tag-epoch_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgg.columns = ['Wall time', 'Step', 'Accuracy']\n",
    "df_res.columns = ['Wall time', 'Step', 'Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wall time', 'Step', 'Accuracy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plor line with legent\n",
    "#smooth line 0.6\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x='Step', y='Accuracy', data=df_vgg, label='VGG', ci=None)\n",
    "sns.lineplot(x='Step', y='Accuracy', data=df_res, label='ResNet', ci=None)\n",
    "plt.legend()\n",
    "#font szie 18 x y\n",
    "plt.xlabel('Step', fontsize=18)\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "#font legend size 18\n",
    "plt.legend(fontsize=16)\n",
    "#Save\n",
    "plt.savefig('./images/accuracy_plot.png', dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852bc408046ca7dfc5c8f91ce764d8630d2287ca09c7fe9d1b4d9cd156705bcb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
